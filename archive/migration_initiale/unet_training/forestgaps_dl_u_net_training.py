# -*- coding: utf-8 -*-
"""forestgaps_U-NET_training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16OaBmbduNdcSK8f2ndo-AMnN_JIGeYfe

# Implémentation du modèle U-Net avec PyTorch pour la détection des trouées forestières

Ce script définit l'architecture du modèle U-Net en utilisant PyTorch pour la
détection des trouées forestières à partir de modèles numériques de surface (DSM).

**Auteur :** VANDER LINDEN Arthur
**Date :** 28-02-2025

# PARTIE 1: CONFIGURATION
"""

import time
import threading
from google.colab import output

def keep_alive():
    while True:
        output.eval_js('google.colab.kernel.invokeFunction("notebook", "ExecuteTime", {})')
        time.sleep(60)  # Attendre 60 secondes avant de renvoyer une requête

# Démarrer dans un thread séparé pour ne pas bloquer l'exécution
keep_alive_thread = threading.Thread(target=keep_alive)
keep_alive_thread.daemon = True  # Le thread s'arrêtera quand le programme principal se termine
keep_alive_thread.start()

print("Session keep-alive activé. Votre session Colab restera active.")

"""## SECTION 1: IMPORTATIONS ET CONFIGURATION"""

# =====================================================================
# SECTION 1: IMPORTATIONS ET CONFIGURATION
# =====================================================================

!pip install rasterio geopandas

import os
import glob
import time
import copy
import sys
import json
import pickle
import random
import datetime
import warnings
import traceback
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from pathlib import Path
from scipy import ndimage
import cv2

# Importation des bibliothèques pour le traitement de données géospatiales
import rasterio
from rasterio.windows import Window
import geopandas as gpd

# Importations PyTorch
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
from torch.utils.data import Dataset, DataLoader, random_split
from torch.optim.lr_scheduler import ReduceLROnPlateau

import torchvision.transforms as T
import torchvision.transforms.functional as TF

from torch.amp import GradScaler, autocast

# Ignorer les avertissements de FutureWarning de torch.load
import warnings
warnings.filterwarnings("ignore", category=FutureWarning, module="torch.serialization")

# Configuration PyTorch
# Fixer le seed pour la reproductibilité
torch.manual_seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(42)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

# Déterminer le périphérique à utiliser (CPU ou GPU)
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Utilisation de: {DEVICE}")
print(f"PyTorch version: {torch.__version__}")

# Optimisation des opérations CUDA
def optimize_cuda_operations():
    """
    Configure les opérations CUDA pour de meilleures performances.
    À appeler au début du script.
    """
    if torch.cuda.is_available():
        # Activer l'auto-tuning pour trouver les algorithmes CUDA les plus rapides
        torch.backends.cudnn.benchmark = True

        # Si votre batch size et tailles d'entrée sont fixes, ceci peut améliorer les performances
        # torch.backends.cudnn.deterministic = False

        # Permet à PyTorch d'allouer plus de mémoire si nécessaire
        torch.cuda.empty_cache()

        # Configurer les allocateurs de mémoire CUDA pour de meilleures performances
        # avec les GPUs récents
        # torch.cuda.set_per_process_memory_fraction(0.95)  # Utiliser 95% de la mémoire GPU

        print(f"GPU disponible: {torch.cuda.get_device_name(0)}")
        print(f"Mémoire GPU totale: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")

    else:
        print("CUDA n'est pas disponible. Utilisation du CPU.")

# Appeler la fonction d'optimisation CUDA
optimize_cuda_operations()

# Montage de Google Drive
from google.colab import drive
drive.mount('/content/drive')

"""## SECTION 2: DÉFINITIONS DES CHEMINS ET CONFIGURATION

"""

# =====================================================================
# SECTION 2: DÉFINITIONS DES CHEMINS ET CONFIGURATION
# =====================================================================

class Config:
    """Classe de configuration centralisée pour le projet"""

    def __init__(self):
        # Répertoire de base
        self.BASE_DIR = '/content/drive/MyDrive/ForestGaps_DeepLearning_Workflow'

        # Sous-répertoires principaux
        self.DATA_DIR = os.path.join(self.BASE_DIR, 'data')
        self.DATA_EXTERNAL_TEST_DIR = os.path.join(self.BASE_DIR, 'data_external_test')
        self.PROCESSED_DIR = os.path.join(self.BASE_DIR, 'processed')
        self.TILES_DIR = os.path.join(self.PROCESSED_DIR, 'tiles')

        # Sous-répertoires pour les tuiles
        self.TRAIN_TILES_DIR = os.path.join(self.TILES_DIR, 'train')
        self.VAL_TILES_DIR = os.path.join(self.TILES_DIR, 'val')
        self.TEST_TILES_DIR = os.path.join(self.TILES_DIR, 'test')

        # Dossiers spécifiques au modèle U-Net
        self.MODELS_DIR = os.path.join(self.BASE_DIR, 'models')
        self.UNET_DIR = os.path.join(self.MODELS_DIR, 'unet')

        # Sous-répertoires pour les résultats et les checkpoints
        self.CHECKPOINTS_DIR = os.path.join(self.UNET_DIR, 'checkpoints')
        self.LOGS_DIR = os.path.join(self.UNET_DIR, 'logs')
        self.RESULTS_DIR = os.path.join(self.UNET_DIR, 'results')
        self.VISUALIZATIONS_DIR = os.path.join(self.UNET_DIR, 'visualizations')

        # Type de modèle ('basic', 'film', 'cbam', 'droppath', 'film_cbam', 'all')
        self.MODEL_TYPE = 'film_cbam'

        # Paramètres spécifiques aux modèles avancés
        self.IN_CHANNELS = 1
        self.DROP_PATH_RATE = 0.1  # Taux de DropPath (pour 'droppath' et 'all')

        # Création des répertoires s'ils n'existent pas
        for dir_path in [
            self.CHECKPOINTS_DIR, self.LOGS_DIR,
            self.RESULTS_DIR, self.VISUALIZATIONS_DIR
        ]:
            os.makedirs(dir_path, exist_ok=True)

        # Paramètres du modèle et de l'entraînement
        self.TILE_SIZE = 256  # Taille des tuiles en pixels
        self.BATCH_SIZE = 64  # Taille des batchs pour l'entraînement
        self.THRESHOLDS = [10, 15, 20, 25, 30]  # Seuils de hauteur en mètres
        self.EPOCHS = 50  # Nombre maximal d'époques
        self.LEARNING_RATE = 0.001  # Taux d'apprentissage initial
        self.DROPOUT_RATE = 0.2  # Taux de dropout pour la régularisation
        self.TEST_SPLIT = 0.15  # Proportion de données pour le test
        self.VAL_SPLIT = 0.15  # Proportion de données pour la validation

        # Paramètres pour l'optimisation de l'entraînement
        self.NUM_WORKERS = 8  # Nombre de workers pour le DataLoader
        self.PIN_MEMORY = True  # Utiliser pin_memory pour accélérer le transfert vers GPU
        self.PREFETCH_FACTOR = 50

        # Paramètres pour le mixup et l'augmentation des données
        self.AUGMENTATION = True  # Activer l'augmentation des données
        self.MIXUP_ALPHA = 0.2  # Paramètre alpha pour mixup (0 = désactivé)

        # Optimisations pour le modèle
        self.USE_AMP = True  # Utiliser la précision mixte automatique
        self.USE_GRADIENT_CHECKPOINTING = False  # Économiser de la mémoire GPU

    def save_config(self, filepath=None):
        """Sauvegarde la configuration actuelle dans un fichier JSON"""
        if filepath is None:
            filepath = os.path.join(self.LOGS_DIR, 'config.json')

        # Création d'un dictionnaire de configuration
        config_dict = {k: v for k, v in self.__dict__.items() if not k.startswith('__') and not callable(v)}

        # Conversion des chemins en chaînes de caractères
        for k, v in config_dict.items():
            if isinstance(v, Path):
                config_dict[k] = str(v)

        # Sauvegarde dans un fichier JSON
        with open(filepath, 'w') as f:
            json.dump(config_dict, f, indent=4)

        print(f"Configuration sauvegardée dans {filepath}")

    def load_config(self, filepath):
        """Charge une configuration à partir d'un fichier JSON"""
        with open(filepath, 'r') as f:
            config_dict = json.load(f)

        # Mise à jour des attributs
        for k, v in config_dict.items():
            setattr(self, k, v)

        print(f"Configuration chargée depuis {filepath}")

# Initialisation de la configuration
config = Config()

"""## SECTION 3: DÉFINITION DES MÉTRIQUES ET UTILITAIRES"""

# =====================================================================
# SECTION 3: DÉFINITION DES MÉTRIQUES ET UTILITAIRES
# =====================================================================

class SegmentationMetrics:
    """
    Classe pour calculer diverses métriques d'évaluation pour la segmentation sémantique.
    Inclut: Accuracy, Precision, Recall, F1-score, IoU, mIoU, Kappa, etc.
    """
    def __init__(self, device=None):
        """
        Initialise l'objet de métriques.

        Args:
            device: Périphérique (CPU ou GPU) pour les calculs
        """
        self.device = device
        self.reset()

    def reset(self):
        """Réinitialise tous les compteurs."""
        self.tp = 0  # True Positives
        self.fp = 0  # False Positives
        self.tn = 0  # True Negatives
        self.fn = 0  # False Negatives

        # Pour les moyennes par image
        self.precision_sum = 0.0
        self.recall_sum = 0.0
        self.f1_sum = 0.0
        self.iou_sum = 0.0
        self.image_count = 0

        # Pour les métriques par seuil
        self.metrics_by_threshold = {}

    def update(self, pred, target, threshold=0.5):
        """
        Met à jour les compteurs avec les nouvelles prédictions.

        Args:
            pred: Prédictions du modèle (après sigmoid) (B, 1, H, W)
            target: Vérité terrain (0 ou 1) (B, 1, H, W)
            threshold: Seuil pour binariser les prédictions
        """
        # S'assurer que les tenseurs sont au bon format
        if pred.dim() == 3:
            pred = pred.unsqueeze(1)
        if target.dim() == 3:
            target = target.unsqueeze(1)

        # Binariser les prédictions
        pred_binary = (torch.sigmoid(pred) > threshold).float()

        # Calculer les métriques pour le batch actuel
        batch_tp = (pred_binary * target).sum().item()
        batch_fp = (pred_binary * (1 - target)).sum().item()
        batch_tn = ((1 - pred_binary) * (1 - target)).sum().item()
        batch_fn = ((1 - pred_binary) * target).sum().item()

        # Mettre à jour les compteurs globaux
        self.tp += batch_tp
        self.fp += batch_fp
        self.tn += batch_tn
        self.fn += batch_fn

        # Calculer les métriques pour chaque image du batch
        for i in range(pred.size(0)):
            img_pred = pred_binary[i]
            img_target = target[i]

            img_tp = (img_pred * img_target).sum().item()
            img_fp = (img_pred * (1 - img_target)).sum().item()
            img_tn = ((1 - img_pred) * (1 - img_target)).sum().item()
            img_fn = ((1 - img_pred) * img_target).sum().item()

            # Calculer precision, recall, F1, IoU pour cette image
            img_precision = img_tp / (img_tp + img_fp + 1e-7)
            img_recall = img_tp / (img_tp + img_fn + 1e-7)
            img_f1 = 2 * img_precision * img_recall / (img_precision + img_recall + 1e-7)
            img_iou = img_tp / (img_tp + img_fp + img_fn + 1e-7)

            # Ajouter aux sommes pour calculer les moyennes plus tard
            self.precision_sum += img_precision
            self.recall_sum += img_recall
            self.f1_sum += img_f1
            self.iou_sum += img_iou
            self.image_count += 1

    def update_by_threshold(self, pred, target, threshold_value):
        """
        Met à jour les métriques spécifiques à un seuil de hauteur.

        Args:
            pred: Prédictions du modèle
            target: Vérité terrain
            threshold_value: Valeur du seuil de hauteur (en mètres)
        """
        # Initialiser les compteurs pour ce seuil s'ils n'existent pas
        if threshold_value not in self.metrics_by_threshold:
            self.metrics_by_threshold[threshold_value] = {
                'tp': 0, 'fp': 0, 'tn': 0, 'fn': 0,
                'precision_sum': 0, 'recall_sum': 0,
                'f1_sum': 0, 'iou_sum': 0, 'image_count': 0
            }

        # Binariser les prédictions
        pred_binary = (torch.sigmoid(pred) > 0.5).float()

        # Calculer les métriques
        batch_tp = (pred_binary * target).sum().item()
        batch_fp = (pred_binary * (1 - target)).sum().item()
        batch_tn = ((1 - pred_binary) * (1 - target)).sum().item()
        batch_fn = ((1 - pred_binary) * target).sum().item()

        # Mettre à jour les compteurs pour ce seuil
        metrics = self.metrics_by_threshold[threshold_value]
        metrics['tp'] += batch_tp
        metrics['fp'] += batch_fp
        metrics['tn'] += batch_tn
        metrics['fn'] += batch_fn

        # Calculer les métriques pour chaque image du batch
        for i in range(pred.size(0)):
            img_pred = pred_binary[i]
            img_target = target[i]

            img_tp = (img_pred * img_target).sum().item()
            img_fp = (img_pred * (1 - img_target)).sum().item()
            img_tn = ((1 - img_pred) * (1 - img_target)).sum().item()
            img_fn = ((1 - img_pred) * img_target).sum().item()

            # Calculer precision, recall, F1, IoU pour cette image
            img_precision = img_tp / (img_tp + img_fp + 1e-7)
            img_recall = img_tp / (img_tp + img_fn + 1e-7)
            img_f1 = 2 * img_precision * img_recall / (img_precision + img_recall + 1e-7)
            img_iou = img_tp / (img_tp + img_fp + img_fn + 1e-7)

            # Ajouter aux sommes
            metrics['precision_sum'] += img_precision
            metrics['recall_sum'] += img_recall
            metrics['f1_sum'] += img_f1
            metrics['iou_sum'] += img_iou
            metrics['image_count'] += 1

    def compute(self):
        """
        Calcule toutes les métriques à partir des compteurs.

        Returns:
            Dictionnaire de métriques
        """
        # Éviter division par zéro
        smooth = 1e-7

        # Métriques globales
        accuracy = (self.tp + self.tn) / (self.tp + self.fp + self.tn + self.fn + smooth)
        precision = self.tp / (self.tp + self.fp + smooth)
        recall = self.tp / (self.tp + self.fn + smooth)
        f1_score = 2 * precision * recall / (precision + recall + smooth)
        iou = self.tp / (self.tp + self.fp + self.fn + smooth)

        # Balanced Accuracy (moyenne de la sensibilité et spécificité)
        sensitivity = recall  # TPR = TP / (TP + FN)
        specificity = self.tn / (self.tn + self.fp + smooth)
        balanced_accuracy = (sensitivity + specificity) / 2

        # Coefficient Kappa
        p_o = accuracy
        p_e = (((self.tp + self.fn) * (self.tp + self.fp)) +
               ((self.tn + self.fp) * (self.tn + self.fn))) / ((self.tp + self.fp + self.tn + self.fn) ** 2 + smooth)
        kappa = (p_o - p_e) / (1 - p_e + smooth)

        # Moyennes par image
        precision_mean = self.precision_sum / (self.image_count + smooth)
        recall_mean = self.recall_sum / (self.image_count + smooth)
        f1_mean = self.f1_sum / (self.image_count + smooth)
        iou_mean = self.iou_sum / (self.image_count + smooth)

        # Métriques par seuil
        threshold_metrics = {}
        for threshold, metrics in self.metrics_by_threshold.items():
            tp, fp, tn, fn = metrics['tp'], metrics['fp'], metrics['tn'], metrics['fn']
            total = tp + fp + tn + fn + smooth

            t_accuracy = (tp + tn) / total
            t_precision = tp / (tp + fp + smooth)
            t_recall = tp / (tp + fn + smooth)
            t_f1_score = 2 * t_precision * t_recall / (t_precision + t_recall + smooth)
            t_iou = tp / (tp + fp + fn + smooth)

            # Moyennes par image pour ce seuil
            img_count = metrics['image_count'] + smooth
            t_precision_mean = metrics['precision_sum'] / img_count
            t_recall_mean = metrics['recall_sum'] / img_count
            t_f1_mean = metrics['f1_sum'] / img_count
            t_iou_mean = metrics['iou_sum'] / img_count

            threshold_metrics[threshold] = {
                'accuracy': t_accuracy,
                'precision': t_precision,
                'recall': t_recall,
                'f1_score': t_f1_score,
                'iou': t_iou,
                'precision_mean': t_precision_mean,
                'recall_mean': t_recall_mean,
                'f1_mean': t_f1_mean,
                'iou_mean': t_iou_mean
            }

        # Résultats finaux
        return {
            # Métriques globales
            'accuracy': accuracy,
            'balanced_accuracy': balanced_accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1_score,
            'iou': iou,
            'kappa': kappa,

            # Moyennes par image
            'precision_mean': precision_mean,
            'recall_mean': recall_mean,
            'f1_mean': f1_mean,
            'iou_mean': iou_mean,

            # Métriques par seuil
            'threshold_metrics': threshold_metrics
        }

    def compute_confusion_matrix(self):
        """
        Construit la matrice de confusion.

        Returns:
            Dictionnaire avec la matrice de confusion et les métriques dérivées
        """
        confusion_matrix = {
            'tp': self.tp,
            'fp': self.fp,
            'tn': self.tn,
            'fn': self.fn
        }

        # Totaliser les pixels
        total_pixels = self.tp + self.fp + self.tn + self.fn

        # Calculer les pourcentages
        confusion_percentages = {
            'tp_percent': self.tp / total_pixels * 100 if total_pixels > 0 else 0,
            'fp_percent': self.fp / total_pixels * 100 if total_pixels > 0 else 0,
            'tn_percent': self.tn / total_pixels * 100 if total_pixels > 0 else 0,
            'fn_percent': self.fn / total_pixels * 100 if total_pixels > 0 else 0
        }

        return {
            'matrix': confusion_matrix,
            'percentages': confusion_percentages,
            'total_pixels': total_pixels
        }


def add_metrics_to_tensorboard(writer, metrics, epoch, prefix=''):
    """
    Ajoute toutes les métriques à TensorBoard.

    Args:
        writer: SummaryWriter de TensorBoard
        metrics: Dictionnaire de métriques retourné par SegmentationMetrics.compute()
        epoch: Époque courante
        prefix: Préfixe pour les noms des métriques (ex: 'val/')
    """
    # Métriques globales
    for metric_name in ['accuracy', 'balanced_accuracy', 'precision', 'recall',
                        'f1_score', 'iou', 'kappa']:
        if metric_name in metrics:
            writer.add_scalar(f'{prefix}{metric_name}', metrics[metric_name], epoch)

    # Moyennes par image
    for metric_name in ['precision_mean', 'recall_mean', 'f1_mean', 'iou_mean']:
        if metric_name in metrics:
            writer.add_scalar(f'{prefix}{metric_name}', metrics[metric_name], epoch)

    # Métriques par seuil
    if 'threshold_metrics' in metrics:
        for threshold, t_metrics in metrics['threshold_metrics'].items():
            for t_metric_name, t_metric_value in t_metrics.items():
                writer.add_scalar(
                    f'{prefix}threshold_{threshold}/{t_metric_name}',
                    t_metric_value,
                    epoch
                )

def iou_metric(pred, target, smooth=1e-6):
    """
    Calcule l'Intersection over Union (IoU) entre deux masques binaires.
    Version robuste qui gère différentes dimensions de tenseurs.

    Args:
        pred: Tensor des prédictions (B, 1, H, W) ou (1, H, W)
        target: Tensor des cibles (B, 1, H, W) ou (1, H, W)
        smooth: Valeur pour éviter la division par zéro

    Returns:
        Valeur IoU moyenne sur le batch
    """
    # Vérifier les dimensions et les adapter si nécessaire
    if pred.dim() == 3:
        pred = pred.unsqueeze(0)  # Ajouter dimension batch
    if target.dim() == 3:
        target = target.unsqueeze(0)  # Ajouter dimension batch

    # Assurons-nous que les deux tenseurs ont la même forme
    if pred.shape != target.shape:
        print(f"Avertissement: Les formes des tenseurs ne correspondent pas: pred {pred.shape}, target {target.shape}")

        # Tentative d'adaptation des dimensions
        if pred.dim() == 4 and target.dim() == 4:
            if pred.shape[0] != target.shape[0]:
                # Si les tailles de batch diffèrent, utiliser la plus petite
                min_batch_size = min(pred.shape[0], target.shape[0])
                pred = pred[:min_batch_size]
                target = target[:min_batch_size]

    # Binariser les prédictions
    pred_binary = (torch.sigmoid(pred) > 0.5).float()

    # Calculer l'intersection et l'union en fonction du nombre de dimensions
    if pred.dim() == 4:
        # Pour tenseurs 4D (avec batch)
        # Déterminer les dimensions sur lesquelles sommer
        sum_dims = tuple(range(1, pred.dim()))

        intersection = (pred_binary * target).sum(dim=sum_dims)
        union = pred_binary.sum(dim=sum_dims) + target.sum(dim=sum_dims) - intersection
    else:
        # Pour tenseurs 3D (sans batch)
        intersection = (pred_binary * target).sum()
        union = pred_binary.sum() + target.sum() - intersection

    # Calculer IoU pour chaque élément du batch
    iou = (intersection + smooth) / (union + smooth)

    # Moyenne sur le batch
    return iou.mean()

class CombinedFocalDiceLoss(nn.Module):
    """
    Fonction de perte combinant BCE-Focal Loss et Dice Loss, adaptative au seuil de hauteur.
    - BCE-Focal: Donne moins de poids aux exemples faciles à classifier
    - Dice Loss: Se concentre sur le recouvrement entre prédictions et masques
    - Adaptation au seuil: Ajuste la pondération selon le déséquilibre des classes par seuil
    """
    def __init__(self, alpha=0.5, gamma=2.0, smooth=1e-6, threshold_weights=None):
        """
        Args:
            alpha: Équilibre entre BCE et Dice (0.5 = poids égal)
            gamma: Facteur focal pour réduire l'impact des exemples faciles
            smooth: Valeur pour éviter division par zéro
            threshold_weights: Dictionnaire {seuil normalisé: poids} (calculé automatiquement si None)
        """
        super(CombinedFocalDiceLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.smooth = smooth
        self.threshold_weights = threshold_weights

    def forward(self, pred, target, threshold=None):
        # Vérifier les entrées
        if torch.isnan(pred).any():
            print("NaN détecté dans les prédictions")
            return torch.tensor(1.0, requires_grad=True, device=pred.device)

        # Application de sigmoid avec protection numérique renforcée
        pred_sigmoid = torch.sigmoid(pred)
        epsilon = 1e-7
        pred_sigmoid = torch.clamp(pred_sigmoid, epsilon, 1.0 - epsilon)

        # Calcul de BCE standard avec meilleure stabilité numérique
        bce = -target * torch.log(pred_sigmoid) - (1 - target) * torch.log(1 - pred_sigmoid)

        # Protection renforcée contre les valeurs extrêmes
        bce = torch.clamp(bce, 0, 50)  # Limiter les valeurs extrêmes

        # Terme focal
        pt = target * pred_sigmoid + (1 - target) * (1 - pred_sigmoid)
        focal_weight = (1 - pt) ** self.gamma

        # Utiliser une normalisation plus stable
        focal_bce = focal_weight * bce
        focal_bce_mean = torch.mean(focal_bce)

        # Vérification avant de multiplier par threshold_weight
        if torch.isnan(focal_bce_mean) or torch.isinf(focal_bce_mean):
            print("NaN ou Inf détecté dans focal_bce_mean, utilisation du dice_loss uniquement")
            focal_bce_mean = 0.0  # Utiliser 0 pour ignorer cette composante
        else:
            # Appliquer le poids du seuil si nécessaire
            if threshold is not None and self.threshold_weights is not None:
                t_value = threshold[0].item()
                closest_t = min(self.threshold_weights.keys(), key=lambda x: abs(x - t_value))
                threshold_weight = self.threshold_weights[closest_t]
                # Limiter les poids extrêmes qui pourraient causer des NaN
                threshold_weight = min(max(threshold_weight, 0.1), 10.0)
                focal_bce_mean = focal_bce_mean * threshold_weight

        # Calcul de Dice Loss avec protection numérique renforcée
        pred_flat = pred_sigmoid.view(-1)
        target_flat = target.view(-1)

        intersection = (pred_flat * target_flat).sum() + self.smooth
        union = pred_flat.sum() + target_flat.sum() + self.smooth * 2

        dice_loss = 1 - (2. * intersection) / union

        # Appliquer threshold_weight au dice_loss
        if threshold is not None and self.threshold_weights is not None:
            t_value = threshold[0].item()
            closest_t = min(self.threshold_weights.keys(), key=lambda x: abs(x - t_value))
            threshold_weight = self.threshold_weights[closest_t]
            threshold_weight = min(max(threshold_weight, 0.1), 10.0)
            dice_loss = dice_loss * threshold_weight

        # Combinaison pondérée avec vérification
        combined_loss = self.alpha * focal_bce_mean + (1 - self.alpha) * dice_loss

        if torch.isnan(combined_loss):
            print(f"NaN détecté dans la perte - focal_bce: {focal_bce_mean.item() if not isinstance(focal_bce_mean, float) else focal_bce_mean}, dice_loss: {dice_loss.item()}")
            # Utiliser seulement dice_loss si combined_loss est NaN
            return dice_loss

        return combined_loss

def create_threshold_weights(config, threshold_stats=None):
    """
    Calcule les poids pour chaque seuil en fonction du déséquilibre des classes.

    Args:
        config: Configuration avec les seuils
        threshold_stats: Optionnel - statistiques {seuil: {pixels_trouees, total_pixels}}
                        Si None, utilise des valeurs approximatives basées sur les données

    Returns:
        Dictionnaire {seuil_normalisé: poids}
    """
    max_threshold = max(config.THRESHOLDS)
    weights = {}

    # Si aucune statistique n'est fournie, utiliser des valeurs approximatives
    # basées sur les données présentées dans le prompt
    if threshold_stats is None:
        threshold_stats = {
            10: {'pixels_trouees': 0.15, 'total_pixels': 1.0},  # ~15% trouées
            15: {'pixels_trouees': 0.30, 'total_pixels': 1.0},  # ~30% trouées
            20: {'pixels_trouees': 0.50, 'total_pixels': 1.0},  # ~50% trouées
            25: {'pixels_trouees': 0.70, 'total_pixels': 1.0},  # ~70% trouées
            30: {'pixels_trouees': 0.85, 'total_pixels': 1.0}   # ~85% trouées
        }

    for threshold, stats in threshold_stats.items():
        if isinstance(stats, dict) and 'pixels_trouees' in stats and 'total_pixels' in stats:
            ratio_trouees = stats['pixels_trouees'] / stats['total_pixels']
        else:
            # Cas où stats est directement le ratio
            ratio_trouees = stats

        # Calcul du poids pour équilibrer les classes
        # Plus une classe est rare, plus son poids est élevé
        if ratio_trouees > 0.5:
            # Favoriser les pixels non-trouées (minoritaires)
            weight = ratio_trouees / (1 - ratio_trouees + 1e-6)
        else:
            # Favoriser les pixels trouées (minoritaires)
            weight = (1 - ratio_trouees) / (ratio_trouees + 1e-6)

        # Normaliser pour éviter des poids extrêmes
        weight = min(weight, 10.0)

        # Stocker avec le seuil normalisé
        weights[threshold / max_threshold] = weight

    return weights

class LossTracker:
    """
    Classe pour suivre et enregistrer les pertes et métriques pendant l'entraînement.
    Version améliorée avec intégration TensorBoard et gestion de métriques multiples.
    """
    def __init__(self, log_dir=None):
        # Métriques de base
        self.train_losses = []
        self.val_losses = []
        self.train_iou = []
        self.val_iou = []
        self.lr_history = []

        # Métriques supplémentaires (initialisées dynamiquement)
        self.metric_names = ['iou']  # IoU est toujours présent

        # Meilleures performances
        self.best_val_loss = float('inf')
        self.best_val_iou = 0.0
        self.best_metrics = {}  # Pour stocker les meilleures valeurs de chaque métrique

        # Compteur pour l'early stopping
        self.epochs_without_improvement = 0
        self.log_file = None

        # Initialisation du writer TensorBoard
        self.writer = SummaryWriter(log_dir=log_dir if log_dir else os.path.join(config.LOGS_DIR, 'tensorboard'))
        print(f"TensorBoard initialisé dans: {self.writer.log_dir}. Pour visualiser, exécutez: tensorboard --logdir={log_dir}")

        # Dictionnaire pour stocker les métriques par seuil
        self.threshold_metrics = {}

        # Historique des métriques complètes
        self.metrics_history = {
            'train': {},
            'val': {}
        }

    def set_log_file(self, filepath):
        """Définit le fichier de log textuel"""
        self.log_file = filepath

        # Créer l'en-tête du fichier de log avec toutes les métriques
        header = "Epoch,Train_Loss,Val_Loss"

        # Ajouter toutes les métriques au header
        for metric in self.metric_names:
            header += f",Train_{metric},Val_{metric}"

        header += ",Learning_Rate\n"

        with open(self.log_file, 'w') as f:
            f.write(header)

    def add_metric(self, metric_name):
        """
        Ajoute une nouvelle métrique à suivre.

        Args:
            metric_name: Nom de la métrique
        """
        if metric_name not in self.metric_names:
            self.metric_names.append(metric_name)

            # Initialiser les listes pour cette métrique
            setattr(self, f'train_{metric_name}', [])
            setattr(self, f'val_{metric_name}', [])

            # Initialiser la meilleure valeur (supposer que plus grand est meilleur)
            self.best_metrics[metric_name] = 0.0

            # Initialiser l'historique
            self.metrics_history['train'][metric_name] = []
            self.metrics_history['val'][metric_name] = []

    def update(self, train_metrics, val_metrics, lr):
        """
        Met à jour les métriques après une époque.

        Args:
            train_metrics: Dictionnaire de métriques d'entraînement
            val_metrics: Dictionnaire de métriques de validation
            lr: Taux d'apprentissage actuel

        Returns:
            Boolean indiquant si une amélioration a été observée
        """
        # Mettre à jour les pertes (toujours présentes)
        self.train_losses.append(train_metrics['loss'])
        self.val_losses.append(val_metrics['loss'])
        self.lr_history.append(lr)

        # Mettre à jour les autres métriques
        for metric_name in self.metric_names:
            if metric_name in train_metrics and metric_name in val_metrics:
                train_list = getattr(self, f'train_{metric_name}')
                val_list = getattr(self, f'val_{metric_name}')

                train_list.append(train_metrics[metric_name])
                val_list.append(val_metrics[metric_name])

                # Mettre à jour l'historique
                self.metrics_history['train'].setdefault(metric_name, []).append(train_metrics[metric_name])
                self.metrics_history['val'].setdefault(metric_name, []).append(val_metrics[metric_name])

        # Mettre à jour les métriques par seuil
        if 'threshold_metrics' in val_metrics:
            self.threshold_metrics = val_metrics['threshold_metrics']

        # Époque actuelle (0-indexed, donc +1 pour l'affichage)
        epoch = len(self.train_losses)

        # Enregistrer dans TensorBoard
        self.writer.add_scalar('Loss/train', train_metrics['loss'], epoch)
        self.writer.add_scalar('Loss/val', val_metrics['loss'], epoch)

        for metric_name in self.metric_names:
            if metric_name in train_metrics and metric_name in val_metrics:
                self.writer.add_scalar(f'{metric_name.capitalize()}/train', train_metrics[metric_name], epoch)
                self.writer.add_scalar(f'{metric_name.capitalize()}/val', val_metrics[metric_name], epoch)

                # Enregistrer la différence entre entraînement et validation
                if train_metrics[metric_name] is not None and val_metrics[metric_name] is not None:
                    self.writer.add_scalar(
                        f'{metric_name.capitalize()}/train_val_gap',
                        train_metrics[metric_name] - val_metrics[metric_name],
                        epoch
                    )

        self.writer.add_scalar('LearningRate', lr, epoch)

        # Vérifier si c'est la meilleure performance
        improved = False

        # Vérifier la perte
        if val_metrics['loss'] < self.best_val_loss:
            self.writer.add_scalar('BestMetrics/val_loss', val_metrics['loss'], epoch)
            self.best_val_loss = val_metrics['loss']
            improved = True

        # Vérifier les autres métriques
        for metric_name in self.metric_names:
            if metric_name in val_metrics:
                val_value = val_metrics[metric_name]
                best_value = self.best_metrics.get(metric_name, 0.0)

                # Supposer que plus grand est meilleur
                if val_value > best_value:
                    self.writer.add_scalar(f'BestMetrics/val_{metric_name}', val_value, epoch)
                    self.best_metrics[metric_name] = val_value

                    # Cas particulier pour l'IoU
                    if metric_name == 'iou':
                        self.best_val_iou = val_value

                    improved = True

        # Mettre à jour le compteur pour early stopping
        if improved:
            self.epochs_without_improvement = 0
        else:
            self.epochs_without_improvement += 1

        # Ajouter l'écriture dans le fichier de log
        if self.log_file:
            with open(self.log_file, 'a') as f:
                log_line = f"{epoch},{train_metrics['loss']:.6f},{val_metrics['loss']:.6f}"

                for metric_name in self.metric_names:
                    if metric_name in train_metrics and metric_name in val_metrics:
                        log_line += f",{train_metrics[metric_name]:.6f},{val_metrics[metric_name]:.6f}"
                    else:
                        log_line += ",N/A,N/A"

                log_line += f",{lr:.6f}\n"
                f.write(log_line)

        # Enregistrer les métriques par seuil
        if 'threshold_metrics' in val_metrics:
            for threshold, t_metrics in val_metrics['threshold_metrics'].items():
                for metric_name, value in t_metrics.items():
                    self.writer.add_scalar(
                        f'Threshold_{threshold}/{metric_name}',
                        value,
                        epoch
                    )

        return improved

    def save(self, filepath):
        """Sauvegarde les métriques dans un fichier"""
        metrics = {
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'lr_history': self.lr_history,
            'best_val_loss': self.best_val_loss,
            'metrics_history': self.metrics_history,
            'best_metrics': self.best_metrics,
            'threshold_metrics': self.threshold_metrics,
            'metric_names': self.metric_names
        }

        # Ajouter toutes les listes de métriques
        for metric_name in self.metric_names:
            train_key = f'train_{metric_name}'
            val_key = f'val_{metric_name}'

            if hasattr(self, train_key) and hasattr(self, val_key):
                metrics[train_key] = getattr(self, train_key)
                metrics[val_key] = getattr(self, val_key)

        with open(filepath, 'wb') as f:
            pickle.dump(metrics, f)

        # Fermer proprement le writer TensorBoard
        self.writer.close()

        print(f"Métriques sauvegardées dans {filepath}")

    def load(self, filepath):
        """Charge les métriques depuis un fichier"""
        with open(filepath, 'rb') as f:
            metrics = pickle.load(f)

        # Charger les métriques de base
        self.train_losses = metrics['train_losses']
        self.val_losses = metrics['val_losses']
        self.lr_history = metrics['lr_history']
        self.best_val_loss = metrics['best_val_loss']

        # Charger les métriques additionnelles
        if 'metric_names' in metrics:
            self.metric_names = metrics['metric_names']

        if 'metrics_history' in metrics:
            self.metrics_history = metrics['metrics_history']

        if 'best_metrics' in metrics:
            self.best_metrics = metrics['best_metrics']

        if 'threshold_metrics' in metrics:
            self.threshold_metrics = metrics['threshold_metrics']

        # Charger toutes les listes de métriques
        for metric_name in self.metric_names:
            train_key = f'train_{metric_name}'
            val_key = f'val_{metric_name}'

            if train_key in metrics and val_key in metrics:
                setattr(self, train_key, metrics[train_key])
                setattr(self, val_key, metrics[val_key])

                # Cas particulier pour l'IoU
                if metric_name == 'iou' and 'best_val_iou' in metrics:
                    self.best_val_iou = metrics['best_val_iou']
                elif metric_name == 'iou' and 'iou' in self.best_metrics:
                    self.best_val_iou = self.best_metrics['iou']

        # Re-enregistrer les métriques chargées dans TensorBoard
        for epoch, (tl, vl, lr) in enumerate(zip(
            self.train_losses, self.val_losses, self.lr_history
        ), 1):
            self.writer.add_scalar('Loss/train', tl, epoch)
            self.writer.add_scalar('Loss/val', vl, epoch)
            self.writer.add_scalar('LearningRate', lr, epoch)

            for metric_name in self.metric_names:
                train_key = f'train_{metric_name}'
                val_key = f'val_{metric_name}'

                if hasattr(self, train_key) and hasattr(self, val_key):
                    train_values = getattr(self, train_key)
                    val_values = getattr(self, val_key)

                    if epoch-1 < len(train_values) and epoch-1 < len(val_values):
                        self.writer.add_scalar(f'{metric_name.capitalize()}/train', train_values[epoch-1], epoch)
                        self.writer.add_scalar(f'{metric_name.capitalize()}/val', val_values[epoch-1], epoch)

        print(f"Métriques chargées depuis {filepath}")

    def plot(self, save_path=None):
        """
        Méthode pour visualiser l'évolution des métriques.
        """
        plt.figure(figsize=(15, 10))

        # Graphique des pertes
        plt.subplot(2, 2, 1)
        plt.plot(self.train_losses, label='Train')
        plt.plot(self.val_losses, label='Validation')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('Evolution de la fonction de perte')
        plt.legend()
        plt.grid(True)

        # Graphique de l'IoU (et autres métriques si disponibles)
        available_metrics = [m for m in self.metric_names if hasattr(self, f'train_{m}')]

        if available_metrics:
            metric_name = available_metrics[0]  # Prendre la première métrique disponible (habituellement IoU)
            train_values = getattr(self, f'train_{metric_name}')
            val_values = getattr(self, f'val_{metric_name}')

            plt.subplot(2, 2, 2)
            plt.plot(train_values, label='Train')
            plt.plot(val_values, label='Validation')
            plt.xlabel('Epoch')
            plt.ylabel(metric_name.upper())
            plt.title(f'Evolution de la métrique {metric_name.upper()}')
            plt.legend()
            plt.grid(True)

        # Graphique du taux d'apprentissage
        plt.subplot(2, 2, 3)
        plt.plot(self.lr_history)
        plt.xlabel('Epoch')
        plt.ylabel('Learning Rate')
        plt.title('Evolution du taux d\'apprentissage')
        plt.grid(True)
        plt.yscale('log')

        # Résumé des meilleures performances
        plt.subplot(2, 2, 4)
        plt.axis('off')
        plt.text(0.1, 0.9, f"Meilleure perte de validation: {self.best_val_loss:.6f}")

        y_pos = 0.8
        for metric_name, best_value in self.best_metrics.items():
            plt.text(0.1, y_pos, f"Meilleur {metric_name.upper()} de validation: {best_value:.6f}")
            y_pos -= 0.1

        plt.text(0.1, 0.2, f"Nombre d'époques: {len(self.train_losses)}")
        plt.text(0.1, 0.1, f"Pour des visualisations détaillées, utilisez TensorBoard")

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300)
            print(f"Graphiques sauvegardés dans {save_path}")

        plt.show()

        print("\nPour des visualisations plus détaillées et interactives, utilisez TensorBoard:")
        print(f"tensorboard --logdir={self.writer.log_dir}")

        # Si nous avons plusieurs métriques, recommander l'utilisation de visualize_metrics_evolution
        if len(self.metric_names) > 1:
            print("\nPour visualiser toutes les métriques, utilisez la fonction visualize_metrics_evolution(tracker)")

class TrainingControl:
    """
    Classe pour contrôler l'exécution de l'entraînement (pause, arrêt, etc.).
    """
    def __init__(self):
        self.stop_requested = False
        self.pause_requested = False
        self.is_paused = False

    def request_stop(self):
        self.stop_requested = True

    def request_pause(self):
        self.pause_requested = True

    def resume(self):
        self.pause_requested = False
        self.is_paused = False

    def check_and_handle_pause(self):
        if self.pause_requested and not self.is_paused:
            self.is_paused = True
            print("Entraînement en pause. Cliquez sur 'Reprendre' pour continuer.")
            while self.pause_requested and not self.stop_requested:
                import time
                time.sleep(0.5)
            self.is_paused = False
            print("Reprise de l'entraînement...")

# Créer une instance globale
training_control = TrainingControl()

"""## SECTION 4: DÉFINITION DU DATASET ET DU DATALOADER"""

# =====================================================================
# SECTION 4: DÉFINITION DU DATASET ET DU DATALOADER
# =====================================================================

class ForestGapTransforms:
    """
    Classe améliorée pour les transformations des données DSM avec:
    - Plus d'angles de rotation
    - Support pour elastic deformation (externe)
    - Random crop and zoom
    """
    def __init__(self, prob=0.7, is_train=True, advanced_aug_prob=0.3, enable_elastic=False):
        """
        Initialise les transformations avec des probabilités adaptées.

        Args:
            prob: Probabilité d'appliquer chaque augmentation de base
            is_train: Si True, applique des augmentations aléatoires
            advanced_aug_prob: Probabilité d'appliquer les augmentations avancées
            enable_elastic: Si True, active la déformation élastique
        """
        self.prob = prob  # Augmenté à 0.7 pour plus d'exposition aux augmentations
        self.is_train = is_train
        self.advanced_aug_prob = advanced_aug_prob
        self.enable_elastic = enable_elastic

        # Plus d'angles pour les rotations (multiples de 15° pour limiter les distorsions)
        self.rotation_angles = [15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180,
                               195, 210, 225, 240, 255, 270, 285, 300, 315, 330, 345]

        # Facteurs de zoom pour random crop and zoom
        self.zoom_factors = [0.8, 0.9, 1.0, 1.1, 1.2]  # 0.8 = zoom in, 1.2 = zoom out

    def _random_crop_zoom(self, image, mask, zoom_factor):
        """
        Effectue un crop aléatoire puis redimensionne à la taille originale.
        """
        h, w = image.shape

        # Calculer la taille du crop
        crop_height = int(h * zoom_factor)
        crop_width = int(w * zoom_factor)

        # S'assurer que les dimensions sont valides
        crop_height = max(min(crop_height, h), h//2)
        crop_width = max(min(crop_width, w), w//2)

        # Calculer les offsets pour le crop
        top = random.randint(0, h - crop_height)
        left = random.randint(0, w - crop_width)

        # Extraire le crop
        image_crop = image[top:top + crop_height, left:left + crop_width]
        mask_crop = mask[top:top + crop_height, left:left + crop_width]

        # Redimensionner à la taille originale
        image_resized = cv2.resize(image_crop, (w, h), interpolation=cv2.INTER_LINEAR)
        mask_resized = cv2.resize(mask_crop, (w, h), interpolation=cv2.INTER_NEAREST)

        return image_resized, mask_resized

    def __call__(self, dsm, mask):
        """
        Applique les transformations aux images DSM et aux masques.
        """
        # Normalisation des données DSM
        dsm_valid = ~np.isnan(dsm)
        if np.any(dsm_valid):
            dsm_min = np.nanmin(dsm)
            dsm_max = np.nanmax(dsm)
            dsm_range = dsm_max - dsm_min
            if dsm_range > 0:
                dsm = np.where(dsm_valid, (dsm - dsm_min) / dsm_range, 0)
            else:
                dsm = np.zeros_like(dsm)

        # Préparer le masque
        mask_valid = (mask != 255)
        mask_binary = np.where(mask_valid, (mask > 0).astype(np.float32), 0)

        # Appliquer les augmentations avancées avant la conversion en tenseurs
        if self.is_train:
            # 1. Elastic déformation (globale) - à appliquer AVANT la conversion en tenseurs
            if self.enable_elastic and random.random() < self.advanced_aug_prob:
                try:
                    # Appel à la fonction globale elastic_transform
                    dsm, mask_binary = elastic_transform(dsm, mask_binary)
                except Exception as e:
                    print(f"Attention: Erreur lors de la transformation élastique: {str(e)}")

            # 2. Random crop and zoom
            if random.random() < self.advanced_aug_prob:
                zoom_factor = random.choice(self.zoom_factors)
                dsm, mask_binary = self._random_crop_zoom(dsm, mask_binary, zoom_factor)

        # Conversion en tenseurs PyTorch (après toutes les augmentations numpy)
        dsm_tensor = torch.from_numpy(dsm).float().unsqueeze(0)
        mask_tensor = torch.from_numpy(mask_binary).float().unsqueeze(0)

        # Appliquer les augmentations PyTorch seulement pendant l'entraînement
        if self.is_train:
            # 3. Rotation avec plus d'angles
            if random.random() < self.prob:
                angle = random.choice(self.rotation_angles)
                dsm_tensor = TF.rotate(dsm_tensor, angle)
                mask_tensor = TF.rotate(mask_tensor, angle)

            # 4. Miroir horizontal
            if random.random() < self.prob:
                dsm_tensor = TF.hflip(dsm_tensor)
                mask_tensor = TF.hflip(mask_tensor)

            # 5. Miroir vertical
            if random.random() < self.prob:
                dsm_tensor = TF.vflip(dsm_tensor)
                mask_tensor = TF.vflip(mask_tensor)

        return dsm_tensor, mask_tensor

def elastic_transform(image, mask, alpha=50, sigma=5):
    """
    Applique une déformation élastique aux images.
    Version globale pour compatibilité avec les worker processes.

    Args:
        image: Image d'entrée (numpy array 2D)
        mask: Masque d'entrée (numpy array 2D)
        alpha: Intensité de la déformation
        sigma: Lissage de la déformation

    Returns:
        Tuple (image déformée, masque déformé)
    """
    shape = image.shape

    # Générer la grille de déplacement
    dx = np.random.rand(shape[0], shape[1]) * 2 - 1
    dy = np.random.rand(shape[0], shape[1]) * 2 - 1

    # Appliquer un filtre gaussien pour lisser les déplacements
    dx = ndimage.gaussian_filter(dx, sigma) * alpha
    dy = ndimage.gaussian_filter(dy, sigma) * alpha

    # Créer la grille de coordonnées
    x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))

    # Appliquer la déformation
    indices = np.reshape(y + dy, (-1, 1)), np.reshape(x + dx, (-1, 1))

    # Appliquer la transformation aux deux images
    warped_image = ndimage.map_coordinates(image, indices, order=1).reshape(shape)
    warped_mask = ndimage.map_coordinates(mask, indices, order=0).reshape(shape)

    return warped_image, warped_mask

class GapDataset(Dataset):
    """
    Dataset pour les données de trouées forestières.
    """
    def __init__(self, tile_info, thresholds, transform=None):
        """
        Args:
            tile_info: Liste d'informations sur les tuiles
            thresholds: Liste des seuils de hauteur (en mètres)
            transform: Transformations à appliquer
        """
        self.tile_info = tile_info
        self.thresholds = thresholds
        self.transform = transform

        # Créer tous les indices (tuile_idx, seuil)
        self.indices = []
        for i in range(len(tile_info)):
            for threshold in thresholds:
                self.indices.append((i, threshold))

    def __len__(self):
        """Retourne la taille du dataset"""
        return len(self.indices)

    def __getitem__(self, idx):
        """
        Retourne un élément à l'indice spécifié.

        Args:
            idx: Indice dans la liste

        Returns:
            Tuple (dsm_tensor, threshold_tensor, mask_tensor)
        """
        # Récupérer l'indice et le seuil
        info_idx, threshold = self.indices[idx]
        info = self.tile_info[info_idx]

        # Charger la tuile DSM
        dsm_tile = np.load(info['dsm_path'])

        # Charger la tuile de masque
        mask_tile = np.load(info['mask_paths'][threshold])

        # Appliquer les transformations
        if self.transform:
            dsm_tensor, mask_tensor = self.transform(dsm_tile, mask_tile)
        else:
            # Normalisation simple si pas de transform
            dsm_valid = ~np.isnan(dsm_tile)
            if np.any(dsm_valid):
                dsm_min = np.nanmin(dsm_tile)
                dsm_max = np.nanmax(dsm_tile)
                dsm_range = dsm_max - dsm_min
                if dsm_range > 0:
                    dsm_tile = np.where(dsm_valid, (dsm_tile - dsm_min) / dsm_range, 0)
                else:
                    dsm_tile = np.where(dsm_valid, 0, 0)

            # Conversion en tenseurs
            dsm_tensor = torch.from_numpy(dsm_tile).float().unsqueeze(0)
            mask_tensor = torch.from_numpy(mask_tile).float().unsqueeze(0)

        # Normaliser le seuil
        threshold_tensor = torch.tensor([threshold / max(self.thresholds)], dtype=torch.float32)

        return dsm_tensor, threshold_tensor, mask_tensor

def calculate_sampling_weights(tile_info, thresholds, gap_ratios):
    """
    Calcule les poids d'échantillonnage pour chaque combinaison (tuile, seuil).

    Args:
        tile_info: Liste d'informations sur les tuiles
        thresholds: Liste des seuils de hauteur
        gap_ratios: Dictionnaire des ratios de trouées par seuil

    Returns:
        Liste des poids d'échantillonnage
    """
    # Initialiser la liste des poids
    weights = []

    # Calculer les poids pour chaque seuil (une seule fois)
    threshold_weights = {}
    for threshold in thresholds:
        ratio = gap_ratios.get(threshold, 0.5)  # Valeur par défaut si non disponible

        # Calculer le facteur de pondération
        if ratio > 0.5:
            # Si plus de 50% des pixels sont des trouées, donner plus de poids aux non-trouées
            weight = ratio / (1 - ratio + 1e-6)
        else:
            # Sinon, donner plus de poids aux trouées
            weight = (1 - ratio) / (ratio + 1e-6)

        # Limiter les poids extrêmes
        threshold_weights[threshold] = min(weight, 5.0)

    # Attribuer un poids à chaque combinaison (tuile, seuil)
    for i in range(len(tile_info)):
        for threshold in thresholds:
            weights.append(threshold_weights[threshold])

    return weights

def create_data_loaders(config, train_tile_info, val_tile_info, test_tile_info=None):
    """
    Crée les DataLoaders pour l'entraînement, la validation et le test.

    Args:
        config: Configuration du projet
        train_tile_info: Informations sur les tuiles d'entraînement
        val_tile_info: Informations sur les tuiles de validation
        test_tile_info: Informations sur les tuiles de test (optionnel)

    Returns:
        Tuple (train_loader, val_loader, test_loader)
    """
    # Charger les ratios de trouées
    gap_ratios_path = os.path.join(config.PROCESSED_DIR, 'gap_ratios.json')
    gap_ratios = {}

    if os.path.exists(gap_ratios_path):
        try:
            with open(gap_ratios_path, 'r') as f:
                gap_ratios_data = json.load(f)
                gap_ratios = {int(k): float(v) for k, v in gap_ratios_data.items()}
            print(f"Ratios de trouées chargés: {gap_ratios}")
        except Exception as e:
            print(f"⚠️ Erreur lors du chargement des ratios de trouées: {str(e)}")
            # Valeurs par défaut approximatives
            gap_ratios = {10: 0.15, 15: 0.30, 20: 0.50, 25: 0.70, 30: 0.85}
    else:
        # Valeurs par défaut approximatives
        gap_ratios = {10: 0.15, 15: 0.30, 20: 0.50, 25: 0.70, 30: 0.85}
        print("Utilisation de ratios de trouées par défaut.")

    # Créer les datasets
    train_dataset = GapDataset(
        train_tile_info,
        config.THRESHOLDS,
        transform=ForestGapTransforms(
            is_train=True,
            prob=0.7,
            advanced_aug_prob=0.3,
            enable_elastic=False  # Désactivé par défaut pour éviter les problèmes
        )
    )

    val_dataset = GapDataset(
        val_tile_info,
        config.THRESHOLDS,
        transform=ForestGapTransforms(is_train=False)  # Désactive l'augmentation pour la validation
    )

    # Calculer les poids d'échantillonnage pour l'entraînement
    train_weights = calculate_sampling_weights(train_tile_info, config.THRESHOLDS, gap_ratios)

    # Créer le sampler pondéré pour l'entraînement
    train_sampler = torch.utils.data.WeightedRandomSampler(
        weights=train_weights,
        num_samples=len(train_dataset),
        replacement=True  # Permettre le remplacement
    )

    # Configurer les paramètres du DataLoader
    persistent_workers = config.NUM_WORKERS > 0
    prefetch_factor = config.PREFETCH_FACTOR if config.NUM_WORKERS > 0 else None

    # Créer le DataLoader d'entraînement avec le sampler
    train_loader = DataLoader(
        train_dataset,
        batch_size=config.BATCH_SIZE,
        sampler=train_sampler,  # Utiliser le sampler au lieu de shuffle
        num_workers=config.NUM_WORKERS,
        pin_memory=config.PIN_MEMORY,
        persistent_workers=persistent_workers,
        prefetch_factor=prefetch_factor,
        drop_last=True
    )

    # DataLoader de validation (sans sampler)
    val_loader = DataLoader(
        val_dataset,
        batch_size=config.BATCH_SIZE,
        shuffle=False,
        num_workers=config.NUM_WORKERS,
        pin_memory=config.PIN_MEMORY,
        persistent_workers=persistent_workers,
        prefetch_factor=prefetch_factor
    )

    # Créer le DataLoader de test si des données de test sont fournies
    test_loader = None
    if test_tile_info is not None:
        test_dataset = GapDataset(
            test_tile_info,
            config.THRESHOLDS,
            transform=ForestGapTransforms(is_train=False)
        )
        test_loader = DataLoader(
            test_dataset,
            batch_size=config.BATCH_SIZE,
            shuffle=False,
            num_workers=config.NUM_WORKERS,
            pin_memory=config.PIN_MEMORY,
            persistent_workers=persistent_workers,
            prefetch_factor=prefetch_factor
        )

    return train_loader, val_loader, test_loader

"""## SECTION 5: DÉFINITION DES BLOCS D'ARCHITECTURE

### Achitecture base : position, attention et blocs résiduels
"""

# =====================================================================
# SECTION 5: DÉFINITION DES BLOCS D'ARCHITECTURE
# =====================================================================

class PositionalEncoding(nn.Module):
    """
    Module d'encodage de position qui ajoute des informations spatiales aux features.
    """
    def __init__(self):
        super(PositionalEncoding, self).__init__()

    def forward(self, x):
        """
        Args:
            x: Tensor d'entrée (B, C, H, W)

        Returns:
            Tensor avec informations de position (B, C+4, H, W)
        """
        # Obtenir les dimensions
        batch_size, _, h, w = x.size()

        # Créer des grilles de coordonnées normalisées
        y_range = torch.linspace(0, 1, h, device=x.device)
        x_range = torch.linspace(0, 1, w, device=x.device)

        # Créer des grilles 2D
        y_grid, x_grid = torch.meshgrid(y_range, x_range, indexing='ij')

        # Distance au centre (0.5, 0.5)
        y_center = torch.abs(y_grid - 0.5)
        x_center = torch.abs(x_grid - 0.5)

        # Répéter pour chaque élément du batch
        y_grid = y_grid.expand(batch_size, 1, -1, -1)
        x_grid = x_grid.expand(batch_size, 1, -1, -1)
        y_center = y_center.expand(batch_size, 1, -1, -1)
        x_center = x_center.expand(batch_size, 1, -1, -1)

        # Concaténer avec les features existantes
        pos_encoding = torch.cat([y_grid, x_grid, y_center, x_center], dim=1)

        return torch.cat([x, pos_encoding], dim=1)

class ResidualBlock(nn.Module):
    """
    Bloc résiduel pour permettre un meilleur flux de gradient.
    """
    def __init__(self, in_channels, out_channels, kernel_size=3, dropout_rate=0.0):
        super(ResidualBlock, self).__init__()

        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, padding=kernel_size//2)
        self.bn2 = nn.BatchNorm2d(out_channels)

        # Connexion résiduelle (shortcut)
        self.shortcut = nn.Sequential()
        if in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1),
                nn.BatchNorm2d(out_channels)
            )

        # Dropout pour la régularisation
        self.dropout = nn.Dropout2d(dropout_rate) if dropout_rate > 0 else None

    def forward(self, x):
        residual = x

        # Chemin principal
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)

        # Appliquer dropout si activé
        if self.dropout is not None:
            out = self.dropout(out)

        # Ajouter la connexion résiduelle
        out += self.shortcut(residual)
        out = self.relu(out)

        return out

class SpatialAttentionBlock(nn.Module):
    """
    Bloc d'attention spatiale qui aide le modèle à se concentrer sur les régions importantes.
    """
    def __init__(self, enc_channels, dec_channels, out_channels):
        super(SpatialAttentionBlock, self).__init__()

        # Réduire le nombre de canaux
        self.theta_x = nn.Conv2d(enc_channels, out_channels, kernel_size=1, padding=0)
        self.phi_g = nn.Conv2d(dec_channels, out_channels, kernel_size=1, padding=0)

        # Couche pour générer les coefficients d'attention
        self.psi = nn.Sequential(
            nn.Conv2d(out_channels, 1, kernel_size=1, padding=0),
            nn.Sigmoid()
        )

        self.relu = nn.ReLU(inplace=True)

    def forward(self, x, g):
        """
        Args:
            x: Features de l'encodeur (B, C1, H, W)
            g: Features du décodeur (B, C2, H, W)

        Returns:
            Features avec attention appliquée
        """
        # Réduire le nombre de canaux
        theta_x = self.theta_x(x)
        phi_g = self.phi_g(g)

        # Ajouter les features et activer
        f = self.relu(theta_x + phi_g)

        # Générer les coefficients d'attention
        attention = self.psi(f)

        # Appliquer l'attention aux features d'entrée
        return x * attention

class UNet(nn.Module):
    """
    Modèle U-Net amélioré avec encodage de position, blocs résiduels et attention spatiale.
    """
    def __init__(self, in_channels=1, dropout_rate=0.2, use_checkpointing=False):
        super(UNet, self).__init__()
        self.use_checkpointing = use_checkpointing

        # Encodage de position (ajoute 4 canaux)
        self.pos_encoding = PositionalEncoding()

        # Encodeur avec blocs résiduels
        self.enc1 = ResidualBlock(in_channels + 4, 64, dropout_rate=dropout_rate)  # +4 pour l'encodage positionnel
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.enc2 = ResidualBlock(64, 128, dropout_rate=dropout_rate)
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.enc3 = ResidualBlock(128, 256, dropout_rate=dropout_rate)
        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)

        # Bottleneck (fond du U)
        self.bottleneck = ResidualBlock(256, 512, dropout_rate=dropout_rate)

        # Module de traitement du seuil de hauteur
        self.threshold_encoder = nn.Sequential(
            nn.Linear(1, 32),
            nn.ReLU(inplace=True),
            nn.Linear(32, 64),
            nn.ReLU(inplace=True),
            nn.Linear(64, 128),
            nn.ReLU(inplace=True)
        )

        # Décodeur avec attention spatiale
        self.upconv3 = nn.ConvTranspose2d(512 + 128, 256, kernel_size=2, stride=2)  # +128 pour le seuil encodé
        self.att3 = SpatialAttentionBlock(256, 256, 256)
        self.dec3 = ResidualBlock(2 * 256, 256, dropout_rate=dropout_rate)

        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.att2 = SpatialAttentionBlock(128, 128, 128)
        self.dec2 = ResidualBlock(2 * 128, 128, dropout_rate=dropout_rate)

        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.att1 = SpatialAttentionBlock(64, 64, 64)
        self.dec1 = ResidualBlock(2 * 64, 64, dropout_rate=dropout_rate)

        # Couche de sortie pour la segmentation binaire (sans sigmoid)
        self.final_conv = nn.Conv2d(64, 1, kernel_size=1)

    def forward(self, dsm, threshold):
        """
        Args:
            dsm: Tensor DSM (B, 1, H, W)
            threshold: Tensor seuil (B, 1)

        Returns:
            Masque de segmentation prédit (B, 1, H, W)
        """
        if self.use_checkpointing and self.training:
            from torch.utils.checkpoint import checkpoint

            # Ajouter l'encodage de position
            x = self.pos_encoding(dsm)

            # Encodeur avec checkpointing
            e1 = self.enc1(x)
            p1 = self.pool1(e1)

            # Utiliser le checkpointing pour les parties lourdes
            e2 = checkpoint(self.enc2, p1, use_reentrant=False)
            p2 = self.pool2(e2)

            e3 = checkpoint(self.enc3, p2)
            p3 = self.pool3(e3)

            # Bottleneck avec checkpointing
            b = checkpoint(self.bottleneck, p3)

            # Traitement du seuil (léger, pas besoin de checkpoint)
            t = self.threshold_encoder(threshold)  # (B, 128)

            # Redimensionner le seuil encodé
            _, _, H, W = b.size()
            t = t.unsqueeze(-1).unsqueeze(-1)  # (B, 128, 1, 1)
            t = t.expand(-1, -1, H, W)  # (B, 128, H, W)

            # Concaténer le seuil avec le bottleneck
            b_with_threshold = torch.cat([b, t], dim=1)

            # Décodeur avec checkpointing pour les blocs lourds
            d3 = self.upconv3(b_with_threshold)
            a3 = self.att3(e3, d3)
            d3 = torch.cat([a3, d3], dim=1)
            d3 = checkpoint(self.dec3, d3)

            d2 = self.upconv2(d3)
            a2 = self.att2(e2, d2)
            d2 = torch.cat([a2, d2], dim=1)
            d2 = checkpoint(self.dec2, d2)

            d1 = self.upconv1(d2)
            a1 = self.att1(e1, d1)
            d1 = torch.cat([a1, d1], dim=1)
            d1 = checkpoint(self.dec1, d1)

            # Couche finale (légère, pas besoin de checkpoint)
            out = self.final_conv(d1)

        else:
            # Version standard sans checkpointing
            # Ajouter l'encodage de position
            x = self.pos_encoding(dsm)

            # Encodeur
            e1 = self.enc1(x)
            p1 = self.pool1(e1)

            e2 = self.enc2(p1)
            p2 = self.pool2(e2)

            e3 = self.enc3(p2)
            p3 = self.pool3(e3)

            # Bottleneck
            b = self.bottleneck(p3)

            # Traitement du seuil
            t = self.threshold_encoder(threshold)  # (B, 128)

            # Redimensionner le seuil encodé pour l'ajouter aux features
            _, _, H, W = b.size()
            t = t.unsqueeze(-1).unsqueeze(-1)  # (B, 128, 1, 1)
            t = t.expand(-1, -1, H, W)  # (B, 128, H, W)

            # Concaténer le seuil avec le bottleneck
            b_with_threshold = torch.cat([b, t], dim=1)

            # Décodeur avec attention
            d3 = self.upconv3(b_with_threshold)
            a3 = self.att3(e3, d3)
            d3 = torch.cat([a3, d3], dim=1)
            d3 = self.dec3(d3)

            d2 = self.upconv2(d3)
            a2 = self.att2(e2, d2)
            d2 = torch.cat([a2, d2], dim=1)
            d2 = self.dec2(d2)

            d1 = self.upconv1(d2)
            a1 = self.att1(e1, d1)
            d1 = torch.cat([a1, d1], dim=1)
            d1 = self.dec1(d1)

            # Couche finale pour la segmentation
            out = self.final_conv(d1)

        return out

"""### Architecture avec implémentation de FiLM (Feature-wise Linear Modulation)"""

class FiLMGenerator(nn.Module):
    """
    Génère les paramètres de modulation FiLM (gamma, beta) à partir d'une entrée conditionnelle.
    Dans notre cas, l'entrée est le seuil de hauteur.
    """
    def __init__(self, input_dim=1, hidden_dim=64, output_dim=128):
        """
        Args:
            input_dim: Dimension d'entrée (1 pour le seuil)
            hidden_dim: Dimension des couches cachées
            output_dim: Dimension de sortie (num_channels*2 pour gamma et beta)
        """
        super(FiLMGenerator, self).__init__()

        self.input_dim = input_dim
        self.output_dim = output_dim

        # Réseau MLP pour générer les paramètres FiLM
        self.mlp = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(inplace=True),
            nn.Linear(hidden_dim, hidden_dim*2),
            nn.ReLU(inplace=True),
            nn.Linear(hidden_dim*2, output_dim*2)  # *2 pour gamma et beta
        )

    def forward(self, condition):
        """
        Args:
            condition: Tenseur de condition (B, input_dim)

        Returns:
            Tuple (gamma, beta) de paramètres FiLM
        """
        # Générer les paramètres FiLM
        film_params = self.mlp(condition)

        # Séparer en gamma et beta
        gamma, beta = torch.split(film_params, self.output_dim, dim=1)

        # Reshape pour le broadcasting
        gamma = gamma.view(-1, self.output_dim, 1, 1)
        beta = beta.view(-1, self.output_dim, 1, 1)

        return gamma, beta


class FiLMModulation(nn.Module):
    """
    Applique une modulation FiLM aux caractéristiques d'entrée.
    """
    def __init__(self, num_channels):
        """
        Args:
            num_channels: Nombre de canaux dans les caractéristiques à moduler
        """
        super(FiLMModulation, self).__init__()
        self.num_channels = num_channels

    def forward(self, features, gamma, beta):
        """
        Args:
            features: Caractéristiques à moduler (B, C, H, W)
            gamma: Coefficient de multiplication (B, C, 1, 1)
            beta: Coefficient d'addition (B, C, 1, 1)

        Returns:
            Caractéristiques modulées
        """
        # Appliquer la modulation FiLM: gamma * features + beta
        return gamma * features + beta


class FiLMResidualBlock(nn.Module):
    """
    Bloc résiduel avec modulation FiLM intégrée.
    """
    def __init__(self, in_channels, out_channels, kernel_size=3, dropout_rate=0.0):
        super(FiLMResidualBlock, self).__init__()

        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, padding=kernel_size//2)
        self.bn2 = nn.BatchNorm2d(out_channels)

        # Modulation FiLM après la normalisation par batch
        self.film = FiLMModulation(out_channels)

        # Connexion résiduelle (shortcut)
        self.shortcut = nn.Sequential()
        if in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1),
                nn.BatchNorm2d(out_channels)
            )

        # Dropout pour la régularisation
        self.dropout = nn.Dropout2d(dropout_rate) if dropout_rate > 0 else None

    def forward(self, x, gamma=None, beta=None):
        residual = x

        # Chemin principal
        out = self.conv1(x)
        out = self.bn1(out)

        # Appliquer FiLM si les paramètres sont fournis
        if gamma is not None and beta is not None:
            out = self.film(out, gamma, beta)

        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)

        # Appliquer dropout si activé
        if self.dropout is not None:
            out = self.dropout(out)

        # Ajouter la connexion résiduelle
        out += self.shortcut(residual)
        out = self.relu(out)

        return out


# Modification du modèle U-Net pour intégrer FiLM
class UNetWithFiLM(nn.Module):
    """
    Modèle U-Net amélioré avec encodage de position, blocs résiduels, attention spatiale et FiLM.
    """
    def __init__(self, in_channels=1, dropout_rate=0.2, use_checkpointing=False):
        super(UNetWithFiLM, self).__init__()
        self.use_checkpointing = use_checkpointing

        # Encodage de position (ajoute 4 canaux)
        self.pos_encoding = PositionalEncoding()

        # Encodeur avec blocs résiduels
        self.enc1 = ResidualBlock(in_channels + 4, 64, dropout_rate=dropout_rate)  # +4 pour l'encodage positionnel
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.enc2 = ResidualBlock(64, 128, dropout_rate=dropout_rate)
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.enc3 = ResidualBlock(128, 256, dropout_rate=dropout_rate)
        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)

        # Bottleneck (fond du U)
        self.bottleneck = ResidualBlock(256, 512, dropout_rate=dropout_rate)

        # Générateurs de paramètres FiLM pour chaque niveau du décodeur
        self.film_generator3 = FiLMGenerator(input_dim=1, hidden_dim=64, output_dim=256)
        self.film_generator2 = FiLMGenerator(input_dim=1, hidden_dim=64, output_dim=128)
        self.film_generator1 = FiLMGenerator(input_dim=1, hidden_dim=64, output_dim=64)

        # Modulateurs FiLM pour chaque niveau du décodeur
        self.film3 = FiLMModulation(256)
        self.film2 = FiLMModulation(128)
        self.film1 = FiLMModulation(64)

        # Décodeur avec attention spatiale
        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.att3 = SpatialAttentionBlock(256, 256, 256)
        self.dec3 = FiLMResidualBlock(2 * 256, 256, dropout_rate=dropout_rate)

        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.att2 = SpatialAttentionBlock(128, 128, 128)
        self.dec2 = FiLMResidualBlock(2 * 128, 128, dropout_rate=dropout_rate)

        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.att1 = SpatialAttentionBlock(64, 64, 64)
        self.dec1 = FiLMResidualBlock(2 * 64, 64, dropout_rate=dropout_rate)

        # Couche de sortie pour la segmentation binaire (sans sigmoid)
        self.final_conv = nn.Conv2d(64, 1, kernel_size=1)

    def forward(self, dsm, threshold):
        """
        Args:
            dsm: Tensor DSM (B, 1, H, W)
            threshold: Tensor seuil (B, 1)

        Returns:
            Masque de segmentation prédit (B, 1, H, W)
        """
        # Ajouter l'encodage de position
        x = self.pos_encoding(dsm)

        # Encodeur
        e1 = self.enc1(x)
        p1 = self.pool1(e1)

        e2 = self.enc2(p1)
        p2 = self.pool2(e2)

        e3 = self.enc3(p2)
        p3 = self.pool3(e3)

        # Bottleneck
        b = self.bottleneck(p3)

        # Générer les paramètres FiLM pour chaque niveau du décodeur
        gamma3, beta3 = self.film_generator3(threshold)
        gamma2, beta2 = self.film_generator2(threshold)
        gamma1, beta1 = self.film_generator1(threshold)

        # Décodeur avec attention et FiLM
        d3 = self.upconv3(b)
        a3 = self.att3(e3, d3)
        d3 = torch.cat([a3, d3], dim=1)
        d3 = self.dec3(d3, gamma3, beta3)

        d2 = self.upconv2(d3)
        a2 = self.att2(e2, d2)
        d2 = torch.cat([a2, d2], dim=1)
        d2 = self.dec2(d2, gamma2, beta2)

        d1 = self.upconv1(d2)
        a1 = self.att1(e1, d1)
        d1 = torch.cat([a1, d1], dim=1)
        d1 = self.dec1(d1, gamma1, beta1)

        # Couche finale pour la segmentation
        out = self.final_conv(d1)

        return out


# Adaptation du module de traitement du seuil
# (Cette partie peut être retirée puisque nous utilisons maintenant FiLM)
"""
# Ancien module de traitement du seuil (remplacé par FiLM)
self.threshold_encoder = nn.Sequential(
    nn.Linear(1, 32),
    nn.ReLU(inplace=True),
    nn.Linear(32, 64),
    nn.ReLU(inplace=True),
    nn.Linear(64, 128),
    nn.ReLU(inplace=True)
)
"""

"""### Architecture avec attention par canal (Channel Attention Module) de CBAM (+FiLM)"""

class ChannelAttention(nn.Module):
    """
    Module d'attention par canal (Channel Attention Module) de CBAM.
    Utilise à la fois l'information de max pooling et d'average pooling.
    """
    def __init__(self, channels, reduction_ratio=16):
        """
        Args:
            channels: Nombre de canaux d'entrée
            reduction_ratio: Ratio de réduction pour le goulot d'étranglement dans le MLP
        """
        super(ChannelAttention, self).__init__()

        # Calculer la dimension réduite (au moins 8 neurones)
        reduced_channels = max(8, channels // reduction_ratio)

        # MLP partagé: FC -> ReLU -> FC
        self.mlp = nn.Sequential(
            nn.Linear(channels, reduced_channels),
            nn.ReLU(inplace=True),
            nn.Linear(reduced_channels, channels)
        )

    def forward(self, x):
        """
        Args:
            x: Tenseur d'entrée (B, C, H, W)

        Returns:
            Tenseur d'attention par canal (B, C, 1, 1)
        """
        batch_size, channels, height, width = x.size()

        # Average pooling global (spatial)
        avg_pool = F.avg_pool2d(x, kernel_size=(height, width)).view(batch_size, channels)
        avg_attention = self.mlp(avg_pool)

        # Max pooling global (spatial)
        max_pool = F.max_pool2d(x, kernel_size=(height, width)).view(batch_size, channels)
        max_attention = self.mlp(max_pool)

        # Fusionner les deux informations (somme) et appliquer sigmoid
        attention = torch.sigmoid(avg_attention + max_attention).view(batch_size, channels, 1, 1)

        return attention


class SpatialAttention(nn.Module):
    """
    Module d'attention spatiale (Spatial Attention Module) de CBAM.
    Utilise l'information des caractéristiques spatiales agrégées par canal.
    """
    def __init__(self, kernel_size=7):
        """
        Args:
            kernel_size: Taille du noyau pour la convolution spatiale
        """
        super(SpatialAttention, self).__init__()

        # Assurons-nous que kernel_size est impair pour un padding correct
        assert kernel_size % 2 == 1, "La taille du noyau doit être impaire"

        # Couche de convolution 2D pour l'attention spatiale
        self.conv = nn.Conv2d(
            in_channels=2,  # Deux cartes de caractéristiques: max et avg
            out_channels=1,  # Une carte d'attention
            kernel_size=kernel_size,
            padding=kernel_size // 2,
            bias=False
        )

    def forward(self, x):
        """
        Args:
            x: Tenseur d'entrée (B, C, H, W)

        Returns:
            Tenseur d'attention spatiale (B, 1, H, W)
        """
        # Calculer les valeurs moyennes et max le long de la dimension des canaux
        avg_pool = torch.mean(x, dim=1, keepdim=True)  # (B, 1, H, W)
        max_pool, _ = torch.max(x, dim=1, keepdim=True)  # (B, 1, H, W)

        # Concaténer les deux informations
        spatial_info = torch.cat([avg_pool, max_pool], dim=1)  # (B, 2, H, W)

        # Appliquer la convolution et sigmoid pour obtenir la carte d'attention
        attention = torch.sigmoid(self.conv(spatial_info))  # (B, 1, H, W)

        return attention


class CBAM(nn.Module):
    """
    Convolutional Block Attention Module (CBAM) complet.
    Combine l'attention par canal et l'attention spatiale séquentiellement.
    """
    def __init__(self, channels, reduction_ratio=16, kernel_size=7):
        """
        Args:
            channels: Nombre de canaux d'entrée
            reduction_ratio: Ratio de réduction pour le module d'attention par canal
            kernel_size: Taille du noyau pour le module d'attention spatiale
        """
        super(CBAM, self).__init__()

        # Modules d'attention
        self.channel_attention = ChannelAttention(channels, reduction_ratio)
        self.spatial_attention = SpatialAttention(kernel_size)

    def forward(self, x):
        """
        Args:
            x: Tenseur d'entrée (B, C, H, W)

        Returns:
            Tenseur avec attention appliquée (B, C, H, W)
        """
        # Appliquer l'attention par canal
        channel_attention = self.channel_attention(x)
        x = x * channel_attention

        # Appliquer l'attention spatiale
        spatial_attention = self.spatial_attention(x)
        x = x * spatial_attention

        return x


class ResidualBlockWithCBAM(nn.Module):
    """
    Bloc résiduel avec module CBAM intégré.
    """
    def __init__(self, in_channels, out_channels, kernel_size=3, dropout_rate=0.0):
        super(ResidualBlockWithCBAM, self).__init__()

        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, padding=kernel_size//2)
        self.bn2 = nn.BatchNorm2d(out_channels)

        # Module CBAM après les convolutions et avant l'addition de la résiduelle
        self.cbam = CBAM(out_channels)

        # Connexion résiduelle (shortcut)
        self.shortcut = nn.Sequential()
        if in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1),
                nn.BatchNorm2d(out_channels)
            )

        # Dropout pour la régularisation
        self.dropout = nn.Dropout2d(dropout_rate) if dropout_rate > 0 else None

    def forward(self, x):
        residual = x

        # Chemin principal
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)

        # Appliquer CBAM avant l'addition résiduelle
        out = self.cbam(out)

        # Appliquer dropout si activé
        if self.dropout is not None:
            out = self.dropout(out)

        # Ajouter la connexion résiduelle
        out += self.shortcut(residual)
        out = self.relu(out)

        return out


class DecoderBlockWithCBAM(nn.Module):
    """
    Bloc de décodeur avec attention CBAM après l'upsampling.
    """
    def __init__(self, in_channels, skip_channels, out_channels, dropout_rate=0.0):
        super(DecoderBlockWithCBAM, self).__init__()

        # Upsampling
        self.upconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)

        # CBAM après l'upsampling (avant la concaténation avec skip connection)
        self.cbam_upconv = CBAM(out_channels)

        # Attention pour la skip connection
        self.skip_attention = SpatialAttentionBlock(skip_channels, out_channels, out_channels)

        # Convolutions après la concaténation
        self.conv1 = nn.Conv2d(out_channels + skip_channels, out_channels, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(out_channels)

        # CBAM final (après les convolutions)
        self.cbam_final = CBAM(out_channels)

        # Dropout
        self.dropout = nn.Dropout2d(dropout_rate) if dropout_rate > 0 else None

    def forward(self, x, skip):
        # Upsampling et CBAM
        up = self.upconv(x)
        up_attended = self.cbam_upconv(up)

        # Appliquer l'attention à la skip connection
        skip_attended = self.skip_attention(skip, up_attended)

        # Concaténer
        concat = torch.cat([skip_attended, up_attended], dim=1)

        # Convolutions
        out = self.conv1(concat)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)

        # CBAM final
        out = self.cbam_final(out)

        # Dropout
        if self.dropout is not None:
            out = self.dropout(out)

        out = self.relu(out)

        return out


# Modèle U-Net avec CBAM intégré
class UNetWithCBAM(nn.Module):
    """
    Modèle U-Net amélioré avec encodage de position, blocs résiduels avec CBAM et décodeurs avec CBAM.
    """
    def __init__(self, in_channels=1, dropout_rate=0.2, use_checkpointing=False):
        super(UNetWithCBAM, self).__init__()
        self.use_checkpointing = use_checkpointing

        # Encodage de position (ajoute 4 canaux)
        self.pos_encoding = PositionalEncoding()

        # Encodeur avec blocs résiduels et CBAM
        self.enc1 = ResidualBlockWithCBAM(in_channels + 4, 64, dropout_rate=dropout_rate)  # +4 pour l'encodage positionnel
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.enc2 = ResidualBlockWithCBAM(64, 128, dropout_rate=dropout_rate)
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.enc3 = ResidualBlockWithCBAM(128, 256, dropout_rate=dropout_rate)
        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)

        # Bottleneck (fond du U)
        self.bottleneck = ResidualBlockWithCBAM(256, 512, dropout_rate=dropout_rate)

        # Module de traitement du seuil de hauteur
        self.threshold_encoder = nn.Sequential(
            nn.Linear(1, 32),
            nn.ReLU(inplace=True),
            nn.Linear(32, 64),
            nn.ReLU(inplace=True),
            nn.Linear(64, 128),
            nn.ReLU(inplace=True)
        )

        # Décodeur avec blocs de décodeur CBAM
        self.dec3 = DecoderBlockWithCBAM(512 + 128, 256, 256, dropout_rate=dropout_rate)  # +128 pour le seuil encodé
        self.dec2 = DecoderBlockWithCBAM(256, 128, 128, dropout_rate=dropout_rate)
        self.dec1 = DecoderBlockWithCBAM(128, 64, 64, dropout_rate=dropout_rate)

        # Couche de sortie pour la segmentation binaire (sans sigmoid)
        self.final_conv = nn.Conv2d(64, 1, kernel_size=1)

    def forward(self, dsm, threshold):
        """
        Args:
            dsm: Tensor DSM (B, 1, H, W)
            threshold: Tensor seuil (B, 1)

        Returns:
            Masque de segmentation prédit (B, 1, H, W)
        """
        # Ajouter l'encodage de position
        x = self.pos_encoding(dsm)

        # Encodeur
        e1 = self.enc1(x)
        p1 = self.pool1(e1)

        e2 = self.enc2(p1)
        p2 = self.pool2(e2)

        e3 = self.enc3(p2)
        p3 = self.pool3(e3)

        # Bottleneck
        b = self.bottleneck(p3)

        # Traitement du seuil
        t = self.threshold_encoder(threshold)  # (B, 128)

        # Redimensionner le seuil encodé pour l'ajouter aux features
        _, _, H, W = b.size()
        t = t.unsqueeze(-1).unsqueeze(-1)  # (B, 128, 1, 1)
        t = t.expand(-1, -1, H, W)  # (B, 128, H, W)

        # Concaténer le seuil avec le bottleneck
        b_with_threshold = torch.cat([b, t], dim=1)

        # Décodeur avec CBAM
        d3 = self.dec3(b_with_threshold, e3)
        d2 = self.dec2(d3, e2)
        d1 = self.dec1(d2, e1)

        # Couche finale pour la segmentation
        out = self.final_conv(d1)

        return out


# Combinaison FiLM et CBAM en un seul modèle (version optimale)
class UNetWithFiLMAndCBAM(nn.Module):
    """
    Modèle U-Net amélioré combinant FiLM pour la modulation conditionnelle et CBAM pour l'attention.
    Cette architecture optimale utilise:
    - Blocs résiduels avec CBAM dans l'encodeur
    - FiLM pour la modulation conditionnelle dans le décodeur
    - Décodeur avec CBAM après les skip connections
    """
    def __init__(self, in_channels=1, dropout_rate=0.2, use_checkpointing=False):
        super(UNetWithFiLMAndCBAM, self).__init__()
        self.use_checkpointing = use_checkpointing

        # Encodage de position (ajoute 4 canaux)
        self.pos_encoding = PositionalEncoding()

        # Encodeur avec blocs résiduels et CBAM
        self.enc1 = ResidualBlockWithCBAM(in_channels + 4, 64, dropout_rate=dropout_rate)  # +4 pour l'encodage positionnel
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.enc2 = ResidualBlockWithCBAM(64, 128, dropout_rate=dropout_rate)
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.enc3 = ResidualBlockWithCBAM(128, 256, dropout_rate=dropout_rate)
        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)

        # Bottleneck (fond du U)
        self.bottleneck = ResidualBlockWithCBAM(256, 512, dropout_rate=dropout_rate)

        # Générateurs de paramètres FiLM pour chaque niveau du décodeur
        self.film_generator3 = FiLMGenerator(input_dim=1, hidden_dim=64, output_dim=256)
        self.film_generator2 = FiLMGenerator(input_dim=1, hidden_dim=64, output_dim=128)
        self.film_generator1 = FiLMGenerator(input_dim=1, hidden_dim=64, output_dim=64)

        # Blocs de décodeur optimisés (upconv, FiLM, concatenation, conv, CBAM)
        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.film3 = FiLMModulation(256)
        self.att3 = SpatialAttentionBlock(256, 256, 256)
        self.cbam3 = CBAM(256 * 2)  # Pour après la concaténation
        self.dec_conv3 = nn.Sequential(
            nn.Conv2d(256 * 2, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True)
        )

        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.film2 = FiLMModulation(128)
        self.att2 = SpatialAttentionBlock(128, 128, 128)
        self.cbam2 = CBAM(128 * 2)
        self.dec_conv2 = nn.Sequential(
            nn.Conv2d(128 * 2, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True)
        )

        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.film1 = FiLMModulation(64)
        self.att1 = SpatialAttentionBlock(64, 64, 64)
        self.cbam1 = CBAM(64 * 2)
        self.dec_conv1 = nn.Sequential(
            nn.Conv2d(64 * 2, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True)
        )

        # Couche de sortie pour la segmentation binaire (sans sigmoid)
        self.final_conv = nn.Conv2d(64, 1, kernel_size=1)

        # Dropout
        self.dropout = nn.Dropout2d(dropout_rate) if dropout_rate > 0 else None

    def forward(self, dsm, threshold):
        """
        Args:
            dsm: Tensor DSM (B, 1, H, W)
            threshold: Tensor seuil (B, 1)

        Returns:
            Masque de segmentation prédit (B, 1, H, W)
        """
        # Ajouter l'encodage de position
        x = self.pos_encoding(dsm)

        # Encodeur avec CBAM
        e1 = self.enc1(x)
        p1 = self.pool1(e1)

        e2 = self.enc2(p1)
        p2 = self.pool2(e2)

        e3 = self.enc3(p2)
        p3 = self.pool3(e3)

        # Bottleneck
        b = self.bottleneck(p3)

        # Générer les paramètres FiLM pour chaque niveau
        gamma3, beta3 = self.film_generator3(threshold)
        gamma2, beta2 = self.film_generator2(threshold)
        gamma1, beta1 = self.film_generator1(threshold)

        # Niveau 3: upconv -> FiLM -> attention -> concat -> CBAM -> conv
        d3 = self.upconv3(b)
        d3 = self.film3(d3, gamma3, beta3)
        a3 = self.att3(e3, d3)
        d3 = torch.cat([a3, d3], dim=1)
        d3 = self.cbam3(d3)
        d3 = self.dec_conv3(d3)
        if self.dropout is not None:
            d3 = self.dropout(d3)

        # Niveau 2
        d2 = self.upconv2(d3)
        d2 = self.film2(d2, gamma2, beta2)
        a2 = self.att2(e2, d2)
        d2 = torch.cat([a2, d2], dim=1)
        d2 = self.cbam2(d2)
        d2 = self.dec_conv2(d2)
        if self.dropout is not None:
            d2 = self.dropout(d2)

        # Niveau 1
        d1 = self.upconv1(d2)
        d1 = self.film1(d1, gamma1, beta1)
        a1 = self.att1(e1, d1)
        d1 = torch.cat([a1, d1], dim=1)
        d1 = self.cbam1(d1)
        d1 = self.dec_conv1(d1)
        if self.dropout is not None:
            d1 = self.dropout(d1)

        # Couche finale
        out = self.final_conv(d1)

        return out

"""### Architecture avec implémentation de DropPath (+CBAM +FiLM = UNetWithAllFeatures)"""

class DropPath(nn.Module):
    """
    Module DropPath (Stochastic Depth).

    Abandonne aléatoirement le chemin résiduel complet avec une probabilité drop_prob
    pendant l'entraînement. Pendant l'inférence, le chemin est toujours conservé.

    Implémenté selon "Deep Networks with Stochastic Depth"
    (https://arxiv.org/abs/1603.09382)
    """
    def __init__(self, drop_prob=0.0):
        """
        Args:
            drop_prob: Probabilité d'abandonner le chemin (0.0 = aucun drop, 1.0 = drop toujours)
        """
        super(DropPath, self).__init__()
        self.drop_prob = drop_prob

    def forward(self, x):
        """
        Args:
            x: Tenseur d'entrée

        Returns:
            Tenseur d'entrée avec probabilité (1-drop_prob) ou zéros avec probabilité drop_prob
        """
        if self.drop_prob == 0.0 or not self.training:
            return x

        # Générer un masque de survie pour tout le batch
        keep_prob = 1.0 - self.drop_prob
        shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # Forme pour le broadcasting

        # Générer un masque binaire avec une probabilité keep_prob
        random_tensor = torch.rand(shape, dtype=x.dtype, device=x.device) < keep_prob

        # Normaliser la sortie pour maintenir l'espérance statistique
        output = x.div(keep_prob) * random_tensor.float()

        return output


class DropPathScheduler:
    """
    Scheduler pour ajuster le taux de DropPath pendant l'entraînement.
    Implémente différentes stratégies: linéaire, exponentielle, cosine, etc.
    """
    def __init__(self, model, start_prob=0.0, final_prob=0.3, epochs=100, strategy='linear',
                 layer_wise=True, deeper_more_drop=True):
        """
        Args:
            model: Modèle contenant des modules DropPath
            start_prob: Probabilité initiale de drop
            final_prob: Probabilité finale de drop (atteinte à la fin de l'entraînement)
            epochs: Nombre total d'époques d'entraînement
            strategy: Stratégie d'évolution ('linear', 'cosine', 'exp', 'constant')
            layer_wise: Si True, applique des taux différents selon la profondeur
            deeper_more_drop: Si True, les couches plus profondes ont plus de drop
        """
        self.model = model
        self.start_prob = start_prob
        self.final_prob = final_prob
        self.epochs = epochs
        self.strategy = strategy
        self.layer_wise = layer_wise
        self.deeper_more_drop = deeper_more_drop

        # Identifier tous les modules DropPath dans le modèle
        self.droppath_modules = []
        self._find_droppath_modules(self.model)

        self.num_modules = len(self.droppath_modules)
        print(f"DropPathScheduler initialisé avec {self.num_modules} modules DropPath")

    def _find_droppath_modules(self, module, path=""):
        """
        Trouve récursivement tous les modules DropPath dans le modèle.
        """
        for name, child in module.named_children():
            new_path = f"{path}.{name}" if path else name
            if isinstance(child, DropPath):
                self.droppath_modules.append((new_path, child))
            else:
                self._find_droppath_modules(child, new_path)

    def step(self, epoch):
        """
        Met à jour les probabilités de drop pour l'époque actuelle.

        Args:
            epoch: Époque actuelle (0-indexed)
        """
        if self.num_modules == 0:
            return

        # Normaliser l'époque entre 0 et 1
        t = epoch / self.epochs

        # Calculer la probabilité globale selon la stratégie
        if self.strategy == 'constant':
            global_prob = self.final_prob
        elif self.strategy == 'linear':
            global_prob = self.start_prob + (self.final_prob - self.start_prob) * t
        elif self.strategy == 'cosine':
            global_prob = self.start_prob + (self.final_prob - self.start_prob) * (1 - math.cos(t * math.pi)) / 2
        elif self.strategy == 'exp':
            global_prob = self.start_prob + (self.final_prob - self.start_prob) * (1 - math.exp(-5 * t))
        else:
            raise ValueError(f"Stratégie inconnue: {self.strategy}")

        # Appliquer la même probabilité à tous les modules (non layer-wise)
        if not self.layer_wise:
            for _, module in self.droppath_modules:
                module.drop_prob = global_prob
            return

        # Appliquer des probabilités différentes selon la profondeur (layer-wise)
        for i, (path, module) in enumerate(self.droppath_modules):
            if self.deeper_more_drop:
                # Les modules plus profonds ont une probabilité plus élevée
                depth_factor = (i + 1) / self.num_modules
                module.drop_prob = global_prob * depth_factor
            else:
                # Les modules plus superficiels ont une probabilité plus élevée
                depth_factor = 1.0 - (i / self.num_modules)
                module.drop_prob = global_prob * depth_factor

        # Afficher les probabilités actuelles (pour débogage)
        if epoch % 10 == 0:
            print(f"Époque {epoch}: Probabilité DropPath globale = {global_prob:.4f}")
            if self.layer_wise:
                print("Probabilités par couche:")
                for path, module in self.droppath_modules:
                    print(f"  {path}: {module.drop_prob:.4f}")


class ResidualBlockWithDropPath(nn.Module):
    """
    Bloc résiduel avec DropPath intégré.
    """
    def __init__(self, in_channels, out_channels, kernel_size=3, dropout_rate=0.0, drop_path_rate=0.0):
        super(ResidualBlockWithDropPath, self).__init__()

        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, padding=kernel_size//2)
        self.bn2 = nn.BatchNorm2d(out_channels)

        # Connexion résiduelle (shortcut)
        self.shortcut = nn.Sequential()
        if in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1),
                nn.BatchNorm2d(out_channels)
            )

        # Dropout pour la régularisation
        self.dropout = nn.Dropout2d(dropout_rate) if dropout_rate > 0 else None

        # DropPath pour la régularisation stochastique de profondeur
        self.drop_path = DropPath(drop_path_rate) if drop_path_rate > 0 else nn.Identity()

    def forward(self, x):
        residual = x

        # Chemin principal
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)

        # Appliquer dropout si activé
        if self.dropout is not None:
            out = self.dropout(out)

        # Appliquer drop path à la sortie avant l'addition résiduelle
        out = self.drop_path(out)

        # Ajouter la connexion résiduelle
        out += self.shortcut(residual)
        out = self.relu(out)

        return out


# Combine DropPath avec FiLM et CBAM
class ResidualBlockWithFiLMCBAMDropPath(nn.Module):
    """
    Bloc résiduel avancé intégrant:
    1. Modulation FiLM
    2. Attention CBAM
    3. DropPath pour la régularisation
    """
    def __init__(self, in_channels, out_channels, kernel_size=3, dropout_rate=0.0, drop_path_rate=0.0):
        super(ResidualBlockWithFiLMCBAMDropPath, self).__init__()

        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, padding=kernel_size//2)
        self.bn2 = nn.BatchNorm2d(out_channels)

        # CBAM après les convolutions
        self.cbam = CBAM(out_channels)

        # Modulation FiLM
        self.film = FiLMModulation(out_channels)

        # Connexion résiduelle (shortcut)
        self.shortcut = nn.Sequential()
        if in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1),
                nn.BatchNorm2d(out_channels)
            )

        # Dropout pour la régularisation
        self.dropout = nn.Dropout2d(dropout_rate) if dropout_rate > 0 else None

        # DropPath pour la régularisation stochastique de profondeur
        self.drop_path = DropPath(drop_path_rate) if drop_path_rate > 0 else nn.Identity()

    def forward(self, x, gamma=None, beta=None):
        residual = x

        # Chemin principal
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)

        # Appliquer CBAM
        out = self.cbam(out)

        # Appliquer FiLM si les paramètres sont fournis
        if gamma is not None and beta is not None:
            out = self.film(out, gamma, beta)

        # Appliquer dropout si activé
        if self.dropout is not None:
            out = self.dropout(out)

        # Appliquer drop path à la sortie avant l'addition résiduelle
        out = self.drop_path(out)

        # Ajouter la connexion résiduelle
        out += self.shortcut(residual)
        out = self.relu(out)

        return out


# Modèle U-Net complet avec les trois techniques
class UNetWithAllFeatures(nn.Module):
    """
    Modèle U-Net avancé intégrant toutes les techniques:
    - FiLM pour la modulation conditionnelle
    - CBAM pour l'attention
    - DropPath pour la régularisation

    Cette architecture est organisée avec:
    - Blocs résiduels avancés dans l'encodeur (CBAM + DropPath)
    - FiLM pour la modulation conditionnelle dans le décodeur
    - Taux de DropPath progressif (plus élevé dans les couches profondes)
    """
    def __init__(self, in_channels=1, dropout_rate=0.2, drop_path_rate=0.2, use_checkpointing=False):
        super(UNetWithAllFeatures, self).__init__()
        self.use_checkpointing = use_checkpointing

        # Encodage de position (ajoute 4 canaux)
        self.pos_encoding = PositionalEncoding()

        # Taux de DropPath progressif (plus élevé dans les couches profondes)
        # Les couches superficielles ont un taux plus faible pour préserver les détails
        dp_rates = [drop_path_rate * i / 3 for i in range(4)]  # [0, dp/3, 2dp/3, dp]

        # Encodeur avec blocs résiduels, CBAM et DropPath
        self.enc1 = ResidualBlockWithFiLMCBAMDropPath(
            in_channels + 4, 64, dropout_rate=dropout_rate, drop_path_rate=dp_rates[0])
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.enc2 = ResidualBlockWithFiLMCBAMDropPath(
            64, 128, dropout_rate=dropout_rate, drop_path_rate=dp_rates[1])
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.enc3 = ResidualBlockWithFiLMCBAMDropPath(
            128, 256, dropout_rate=dropout_rate, drop_path_rate=dp_rates[2])
        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)

        # Bottleneck (fond du U) - taux de DropPath maximal
        self.bottleneck = ResidualBlockWithFiLMCBAMDropPath(
            256, 512, dropout_rate=dropout_rate, drop_path_rate=dp_rates[3])

        # Générateurs de paramètres FiLM pour chaque niveau du décodeur
        self.film_generator3 = FiLMGenerator(input_dim=1, hidden_dim=64, output_dim=256)
        self.film_generator2 = FiLMGenerator(input_dim=1, hidden_dim=64, output_dim=128)
        self.film_generator1 = FiLMGenerator(input_dim=1, hidden_dim=64, output_dim=64)

        # Décodeur - utilisez des taux de DropPath décroissants pour le décodeur
        # pour éviter de perdre des détails spatials fins
        dec_dp_rates = list(reversed(dp_rates[:-1])) + [0.0]  # [2dp/3, dp/3, 0]

        # Blocs de décodeur avancés
        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.att3 = SpatialAttentionBlock(256, 256, 256)
        self.dec3 = ResidualBlockWithFiLMCBAMDropPath(
            2 * 256, 256, dropout_rate=dropout_rate, drop_path_rate=dec_dp_rates[0])

        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.att2 = SpatialAttentionBlock(128, 128, 128)
        self.dec2 = ResidualBlockWithFiLMCBAMDropPath(
            2 * 128, 128, dropout_rate=dropout_rate, drop_path_rate=dec_dp_rates[1])

        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.att1 = SpatialAttentionBlock(64, 64, 64)
        self.dec1 = ResidualBlockWithFiLMCBAMDropPath(
            2 * 64, 64, dropout_rate=dropout_rate, drop_path_rate=dec_dp_rates[2])

        # Couche de sortie pour la segmentation binaire (sans sigmoid)
        self.final_conv = nn.Conv2d(64, 1, kernel_size=1)

    def forward(self, dsm, threshold):
        """
        Args:
            dsm: Tensor DSM (B, 1, H, W)
            threshold: Tensor seuil (B, 1)

        Returns:
            Masque de segmentation prédit (B, 1, H, W)
        """
        # Ajouter l'encodage de position
        x = self.pos_encoding(dsm)

        # Encodeur avec CBAM et DropPath (pas de FiLM ici)
        e1 = self.enc1(x)
        p1 = self.pool1(e1)

        e2 = self.enc2(p1)
        p2 = self.pool2(e2)

        e3 = self.enc3(p2)
        p3 = self.pool3(e3)

        # Bottleneck (pas de FiLM ici non plus)
        b = self.bottleneck(p3)

        # Générer les paramètres FiLM pour chaque niveau du décodeur
        gamma3, beta3 = self.film_generator3(threshold)
        gamma2, beta2 = self.film_generator2(threshold)
        gamma1, beta1 = self.film_generator1(threshold)

        # Décodeur avec attention, FiLM et DropPath
        d3 = self.upconv3(b)
        a3 = self.att3(e3, d3)
        d3 = torch.cat([a3, d3], dim=1)
        d3 = self.dec3(d3, gamma3, beta3)

        d2 = self.upconv2(d3)
        a2 = self.att2(e2, d2)
        d2 = torch.cat([a2, d2], dim=1)
        d2 = self.dec2(d2, gamma2, beta2)

        d1 = self.upconv1(d2)
        a1 = self.att1(e1, d1)
        d1 = torch.cat([a1, d1], dim=1)
        d1 = self.dec1(d1, gamma1, beta1)

        # Couche finale pour la segmentation
        out = self.final_conv(d1)

        return out


# Utilisation de DropPathScheduler pendant l'entraînement
def train_with_droppath_scheduling(model, train_loader, val_loader, criterion, optimizer, config, device):
    """
    Fonction d'entraînement avec scheduling DropPath.
    """
    # Initialiser le scheduleur DropPath
    droppath_scheduler = DropPathScheduler(
        model,
        start_prob=0.0,
        final_prob=0.3,  # Probabilité finale de drop (ajustable)
        epochs=config.EPOCHS,
        strategy='linear',  # Options: 'linear', 'cosine', 'exp', 'constant'
        layer_wise=True,  # Différentes probabilités par couche
        deeper_more_drop=True  # Les couches profondes ont plus de drop
    )

    # Reste du code d'entraînement, ajoutez simplement:
    for epoch in range(start_epoch, config.EPOCHS):
        # Mettre à jour les probabilités de DropPath pour cette époque
        droppath_scheduler.step(epoch)

        # Code d'entraînement existant...

    return model, tracker

"""## SECTION 6 : FONCTION FACTORY - CENTRALISATION DES MODÈLES"""

def create_unet_model(config):
    """
    Fonction factory qui crée une instance du modèle U-Net selon la configuration.

    Args:
        config: Configuration contenant les paramètres du modèle
            - model_type: Type de modèle ('basic', 'film', 'cbam', 'droppath', 'all')
            - in_channels: Nombre de canaux d'entrée (défaut: 1)
            - dropout_rate: Taux de dropout (défaut: 0.2)
            - drop_path_rate: Taux de droppath (défaut: 0.1, utilisé seulement si 'droppath' ou 'all')
            - use_gradient_checkpointing: Utilisation du checkpointing (défaut: False)

    Returns:
        Un modèle U-Net configuré selon les options spécifiées
    """
    # Mettre à jour les chemins selon le type de modèle
    config = setup_model_paths(config)

    # Extraire les paramètres du modèle de la configuration
    model_type = getattr(config, 'MODEL_TYPE', 'basic').lower()
    in_channels = getattr(config, 'IN_CHANNELS', 1)
    dropout_rate = getattr(config, 'DROPOUT_RATE', 0.2)
    drop_path_rate = getattr(config, 'DROP_PATH_RATE', 0.1)
    use_checkpointing = getattr(config, 'USE_GRADIENT_CHECKPOINTING', False)

    # Créer le modèle selon le type spécifié
    if model_type == 'basic':
        # Modèle U-Net standard
        model = UNet(
            in_channels=in_channels,
            dropout_rate=dropout_rate,
            use_checkpointing=use_checkpointing
        )

    elif model_type == 'film':
        # Modèle avec modulation FiLM
        model = UNetWithFiLM(
            in_channels=in_channels,
            dropout_rate=dropout_rate,
            use_checkpointing=use_checkpointing
        )

    elif model_type == 'cbam':
        # Modèle avec attention CBAM
        model = UNetWithCBAM(
            in_channels=in_channels,
            dropout_rate=dropout_rate,
            use_checkpointing=use_checkpointing
        )

    elif model_type == 'droppath':
        # Modèle avec DropPath
        model = UNet(
            in_channels=in_channels,
            dropout_rate=dropout_rate,
            use_checkpointing=use_checkpointing
        )
        # Remplacer les blocs résiduels par des blocs avec DropPath
        model = convert_to_droppath(model, drop_path_rate)

    elif model_type == 'film_cbam':
        # Modèle avec FiLM et CBAM
        model = UNetWithFiLMAndCBAM(
            in_channels=in_channels,
            dropout_rate=dropout_rate,
            use_checkpointing=use_checkpointing
        )

    elif model_type == 'all':
        # Modèle avec toutes les améliorations
        model = UNetWithAllFeatures(
            in_channels=in_channels,
            dropout_rate=dropout_rate,
            drop_path_rate=drop_path_rate,
            use_checkpointing=use_checkpointing
        )

    else:
        print(f"Type de modèle non reconnu: {model_type}. Utilisation du modèle de base.")
        model = UNet(
            in_channels=in_channels,
            dropout_rate=dropout_rate,
            use_checkpointing=use_checkpointing
        )

    return model


def convert_to_droppath(model, drop_path_rate):
    """
    Convertit les blocs résiduels d'un modèle existant en blocs avec DropPath.

    Args:
        model: Modèle à convertir
        drop_path_rate: Taux de DropPath à appliquer

    Returns:
        Modèle avec DropPath
    """
    # Liste pour stocker les changements à faire
    replacement_dict = {}

    # Détecter les blocs résiduels et préparer leur remplacement
    for name, module in model.named_children():
        if isinstance(module, ResidualBlock):
            # Créer un nouveau bloc avec DropPath
            new_module = ResidualBlockWithDropPath(
                in_channels=module.conv1.in_channels,
                out_channels=module.conv1.out_channels,
                kernel_size=module.conv1.kernel_size[0],
                dropout_rate=module.dropout.p if module.dropout else 0.0,
                drop_path_rate=drop_path_rate
            )
            replacement_dict[name] = new_module
        elif len(list(module.children())) > 0:
            # Appliquer récursivement aux sous-modules
            converted_module = convert_to_droppath(module, drop_path_rate)
            replacement_dict[name] = converted_module

    # Appliquer les remplacements
    for name, new_module in replacement_dict.items():
        setattr(model, name, new_module)

    return model


def get_model_type_string(config):
    """
    Génère une chaîne de caractères décrivant le type de modèle pour les noms de fichiers.

    Args:
        config: Configuration contenant les paramètres du modèle

    Returns:
        Chaîne décrivant le type de modèle (ex: "unet_film_cbam")
    """
    model_type = getattr(config, 'MODEL_TYPE', 'basic').lower()

    if model_type == 'basic':
        return "unet"
    elif model_type in ['film', 'cbam', 'droppath']:
        return f"unet_{model_type}"
    elif model_type == 'film_cbam':
        return "unet_film_cbam"
    elif model_type == 'all':
        return "unet_advanced"
    else:
        return "unet_custom"


def setup_model_paths(config):
    """
    Configure les chemins de sauvegarde spécifiques au type de modèle.

    Args:
        config: Configuration à modifier

    Returns:
        Configuration avec chemins mis à jour
    """
    # Obtenir la chaîne décrivant le type de modèle
    model_type_str = get_model_type_string(config)

    # Créer des sous-répertoires pour le type de modèle
    base_dir = config.MODELS_DIR
    model_dir = os.path.join(base_dir, model_type_str)

    # Mettre à jour les chemins dans la configuration
    config.UNET_DIR = model_dir
    config.CHECKPOINTS_DIR = os.path.join(model_dir, 'checkpoints')
    config.LOGS_DIR = os.path.join(model_dir, 'logs')
    config.RESULTS_DIR = os.path.join(model_dir, 'results')
    config.VISUALIZATIONS_DIR = os.path.join(model_dir, 'visualizations')

    # Créer les répertoires s'ils n'existent pas
    for dir_path in [
        config.CHECKPOINTS_DIR, config.LOGS_DIR,
        config.RESULTS_DIR, config.VISUALIZATIONS_DIR
    ]:
        os.makedirs(dir_path, exist_ok=True)

    return config

"""## SECTION 7: FONCTIONS D'ENTRAÎNEMENT ET D'ÉVALUATION"""

# =====================================================================
# SECTION 7: FONCTIONS D'ENTRAÎNEMENT ET D'ÉVALUATION
# =====================================================================

def clear_gpu_memory():
    """Vide la mémoire GPU non utilisée"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

def train_epoch(model, data_loader, criterion, optimizer, device, segmentation_metrics, report_interval=10):
    """
    Entraîne le modèle pendant une époque avec des métriques améliorées et une barre de progression.
    Remarque: L'équilibrage des classes est maintenant géré par les indices pré-calculés,
    ce qui améliore les performances en évitant l'overhead lié au sampler.

    Args:
        model: Modèle PyTorch
        data_loader: DataLoader pour les données d'entraînement
        criterion: Fonction de perte
        optimizer: Optimiseur
        device: Périphérique (CPU ou GPU)
        segmentation_metrics: Objet SegmentationMetrics pour calculer diverses métriques
        report_interval: Intervalle pour la mise à jour de la barre de progression

    Returns:
        Dictionnaire de métriques d'entraînement
    """
    model.train()
    running_loss = 0.0
    total_samples = 0

    # Réinitialiser les métriques
    segmentation_metrics.reset()

    # Initialiser le scaler pour la précision mixte
    scaler = torch.amp.GradScaler('cuda')

    # Configuration améliorée de tqdm pour une barre de progression nette
    progress_bar = tqdm(
        total=len(data_loader),
        desc="Entraînement",
        position=0,
        leave=True,
        bar_format='{l_bar}{bar:30}{r_bar}{bar:-10b}',
        dynamic_ncols=True
    )

    for batch_idx, (dsm, threshold, target) in enumerate(data_loader):
        # Déplacer les tenseurs vers le périphérique
        dsm = dsm.to(device)
        threshold = threshold.to(device)
        target = target.to(device)

        # Forward pass avec précision mixte
        optimizer.zero_grad()

        with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):
            output = model(dsm, threshold)
            loss = criterion(output, target, threshold)

        # Backward pass et optimisation avec scaling
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        # Mettre à jour les métriques
        with torch.no_grad():
            segmentation_metrics.update(output, target)
            # Mettre à jour les métriques spécifiques au seuil
            threshold_value = threshold[0].item() * max(data_loader.dataset.thresholds)
            closest_threshold = min(data_loader.dataset.thresholds, key=lambda x: abs(x - threshold_value))
            segmentation_metrics.update_by_threshold(output, target, closest_threshold)

        # Mettre à jour les statistiques
        batch_size = dsm.size(0)
        running_loss += loss.item() * batch_size
        total_samples += batch_size

        # Mettre à jour la barre de progression à intervalles réguliers
        if (batch_idx + 1) % report_interval == 0 or batch_idx == len(data_loader) - 1:
            # Calculer les métriques en cours
            current_metrics = segmentation_metrics.compute()

            # Préparer les métriques à afficher
            metrics_str = f"loss={running_loss/total_samples:.4f}"
            for metric_name in ['iou', 'accuracy', 'f1_score']:
                if metric_name in current_metrics:
                    metrics_str += f", {metric_name}={current_metrics[metric_name]:.4f}"

            # Mettre à jour la barre de progression
            progress_bar.set_postfix_str(metrics_str)
            progress_bar.update(min(report_interval, len(data_loader) - progress_bar.n))

    # Fermer la barre de progression
    progress_bar.close()

    # Calculer les métriques finales
    epoch_loss = running_loss / total_samples
    metrics = segmentation_metrics.compute()

    # Préparer le dictionnaire de retour
    result_metrics = {
        'loss': epoch_loss,
        'iou': metrics['iou']
    }

    # Ajouter d'autres métriques
    for metric_name in ['accuracy', 'precision', 'recall', 'f1_score', 'kappa']:
        if metric_name in metrics:
            result_metrics[metric_name] = metrics[metric_name]

    # Ajouter les métriques par seuil
    if 'threshold_metrics' in metrics:
        result_metrics['threshold_metrics'] = metrics['threshold_metrics']

    clear_gpu_memory()
    return result_metrics

def validate(model, data_loader, criterion, device, segmentation_metrics):
    """
    Évalue le modèle sur l'ensemble de validation avec des métriques améliorées.

    Args:
        model: Modèle PyTorch
        data_loader: DataLoader pour les données de validation
        criterion: Fonction de perte
        device: Périphérique (CPU ou GPU)
        segmentation_metrics: Objet SegmentationMetrics pour calculer diverses métriques

    Returns:
        Dictionnaire de métriques de validation
    """
    model.eval()
    running_loss = 0.0
    total_samples = 0

    # Réinitialiser les métriques
    segmentation_metrics.reset()

    progress_bar = tqdm(
        total=len(data_loader),
        desc="Validation",
        position=0,
        leave=True,
        bar_format='{l_bar}{bar:30}{r_bar}{bar:-10b}',
        dynamic_ncols=True
    )

    with torch.no_grad():
        for batch_idx, (dsm, threshold, target) in enumerate(data_loader):
            # Déplacer les tenseurs vers le périphérique
            dsm = dsm.to(device)
            threshold = threshold.to(device)
            target = target.to(device)

            # Forward pass
            output = model(dsm, threshold)
            loss = criterion(output, target, threshold)

            # Mettre à jour les métriques
            segmentation_metrics.update(output, target)

            # Mettre à jour les métriques spécifiques au seuil
            threshold_value = threshold[0].item() * max(data_loader.dataset.thresholds)
            closest_threshold = min(data_loader.dataset.thresholds, key=lambda x: abs(x - threshold_value))
            segmentation_metrics.update_by_threshold(output, target, closest_threshold)

            # Mettre à jour les statistiques
            batch_size = dsm.size(0)
            running_loss += loss.item() * batch_size
            total_samples += batch_size

            # Mettre à jour la barre de progression
            progress_bar.update(1)

    # Fermer la barre de progression
    progress_bar.close()

    # Calculer les métriques finales
    epoch_loss = running_loss / total_samples
    metrics = segmentation_metrics.compute()

    # Préparer le dictionnaire de retour
    result_metrics = {
        'loss': epoch_loss,
        'iou': metrics['iou']
    }

    # Ajouter d'autres métriques
    for metric_name in ['accuracy', 'precision', 'recall', 'f1_score', 'kappa']:
        if metric_name in metrics:
            result_metrics[metric_name] = metrics[metric_name]

    # Ajouter les métriques par seuil
    if 'threshold_metrics' in metrics:
        result_metrics['threshold_metrics'] = metrics['threshold_metrics']

    return result_metrics

def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, config, device, callbacks=None, is_test_mode=False, droppath_scheduler=None):
    """
    Fonction principale pour l'entraînement du modèle avec suivi amélioré des métriques.

    Args:
        model: Modèle U-Net
        train_loader: DataLoader pour les données d'entraînement
        val_loader: DataLoader pour les données de validation
        criterion: Fonction de perte
        optimizer: Optimiseur
        scheduler: Scheduler pour le taux d'apprentissage
        config: Configuration du projet
        device: Périphérique (CPU ou GPU)
        callbacks: Objet contenant des méthodes de callback pour personnaliser le processus
        is_test_mode: Booléen indiquant si on est en mode test
        droppath_scheduler: Scheduler pour DropPath (optionnel)

    Returns:
        Tuple (model, tracker)
    """
    # Fixer l'avertissement de future warning de torch.load
    import warnings
    warnings.filterwarnings("ignore", category=FutureWarning, module="torch.serialization")

    # Initialiser le tracker de métriques avec TensorBoard
    tracker = LossTracker(log_dir=config.LOGS_DIR)

    # Ajouter les métriques supplémentaires à suivre
    for metric_name in ['accuracy', 'precision', 'recall', 'f1_score', 'kappa']:
        # Utiliser la méthode add_metric modifiée pour éviter les messages redondants
        if metric_name not in tracker.metric_names:
            tracker.metric_names.append(metric_name)
            setattr(tracker, f'train_{metric_name}', [])
            setattr(tracker, f'val_{metric_name}', [])
            tracker.best_metrics[metric_name] = 0.0
            tracker.metrics_history['train'][metric_name] = []
            tracker.metrics_history['val'][metric_name] = []

    log_file = os.path.join(config.LOGS_DIR, 'training_log.csv')
    tracker.set_log_file(log_file)

    # Initialiser les objets pour le calcul des métriques
    train_metrics_calculator = SegmentationMetrics(device)
    val_metrics_calculator = SegmentationMetrics(device)

    # Chemin pour sauvegarder le meilleur modèle
    best_model_path = os.path.join(config.CHECKPOINTS_DIR, 'best_model.pth')

    # Vérifier s'il existe un checkpoint pour reprendre l'entraînement
    start_epoch = 0
    resume_training = not is_test_mode  # Ne pas reprendre en mode test

    if os.path.exists(best_model_path) and resume_training:
        print("Un modèle précédent a été trouvé. Chargement du modèle pour reprendre l'entraînement...")
        try:
            checkpoint = torch.load(best_model_path, map_location=device)

            if 'epoch' in checkpoint:
                start_epoch = checkpoint['epoch'] + 1
                model.load_state_dict(checkpoint['model_state_dict'])
                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

                # Déplacer l'optimiseur sur le bon device si nécessaire
                for state in optimizer.state.values():
                    for k, v in state.items():
                        if isinstance(v, torch.Tensor):
                            state[k] = v.to(device)

                if 'scheduler_state_dict' in checkpoint and scheduler is not None:
                    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])

                tracker_path = os.path.join(config.LOGS_DIR, 'metrics.pkl')
                if os.path.exists(tracker_path):
                    tracker.load(tracker_path)

                print(f"✅ Modèle chargé avec succès! Reprise de l'entraînement à partir de l'époque {start_epoch}")
                print(f"   Meilleur IoU précédent: {tracker.best_val_iou:.4f}")

                # Ajouter le modèle à TensorBoard pour visualiser sa structure
                try:
                    tracker.writer.add_graph(model,
                                            (torch.zeros(1, 1, config.TILE_SIZE, config.TILE_SIZE).to(device),
                                             torch.zeros(1, 1).to(device)))
                except Exception as e:
                    print(f"Note: Impossible d'ajouter le graphe du modèle à TensorBoard: {str(e)}")
            else:
                print("⚠️ Checkpoint trouvé mais sans information d'époque. Démarrage à l'époque 0.")
        except Exception as e:
            print(f"❌ Erreur lors du chargement du checkpoint: {str(e)}")
            print("   Démarrage à l'époque 0.")
    else:
        if is_test_mode:
            print("Mode test: Démarrage d'un nouvel entraînement.")
        else:
            print("Aucun modèle précédent trouvé. Démarrage d'un nouvel entraînement.")

        # Ajouter le modèle à TensorBoard pour visualiser sa structure
        sample_input = (torch.zeros(1, 1, config.TILE_SIZE, config.TILE_SIZE).to(device),
                         torch.zeros(1, 1).to(device))
        try:
            tracker.writer.add_graph(model, sample_input)
        except Exception as e:
            print(f"Note: Impossible d'ajouter le graphe du modèle à TensorBoard: {str(e)}")

    # Si des callbacks sont fournis et possèdent la méthode before_training_start, l'appeler
    if callbacks and hasattr(callbacks, 'before_training_start'):
        custom_start_epoch = callbacks.before_training_start(model, optimizer, tracker)
        if custom_start_epoch is not None:
            start_epoch = custom_start_epoch

    # Critères d'arrêt précoce
    patience = 10
    min_delta = 0.001

    # Entraînement par époque
    print(f"Début de l'entraînement pour {config.EPOCHS} époques")
    start_time = time.time()

    # Initialiser la variable epoch en dehors de la boucle pour éviter l'erreur "cannot access local variable 'epoch'"
    epoch = start_epoch

    for epoch in range(start_epoch, config.EPOCHS):
        epoch_start = time.time()

        # Appliquer DropPath scheduler si présent
        if droppath_scheduler is not None:
            droppath_scheduler.step(epoch)

        # Entraînement et validation
        train_metrics = train_epoch(model, train_loader, criterion, optimizer, device, train_metrics_calculator)
        val_metrics = validate(model, val_loader, criterion, device, val_metrics_calculator)

        # Mise à jour du scheduler
        if scheduler is not None:
            if isinstance(scheduler, ReduceLROnPlateau):
                scheduler.step(val_metrics['loss'])
            else:
                scheduler.step()

        # Obtenir le taux d'apprentissage actuel
        current_lr = optimizer.param_groups[0]['lr']

        # Mettre à jour le tracker
        improved = tracker.update(train_metrics, val_metrics, current_lr)

        # Ajouter des visualisations de prédictions à TensorBoard (tous les 5 époques)
        if (epoch % 5 == 0 or epoch == config.EPOCHS - 1) and not is_test_mode:
            for threshold in config.THRESHOLDS:
                visualize_predictions_tensorboard(
                    model, val_loader, device, tracker.writer, epoch, threshold, num_samples=4
                )

        # Afficher les métriques
        epoch_time = time.time() - epoch_start

        # Afficher un résumé des métriques principales
        metrics_summary = (
            f"Époque {epoch+1}/{config.EPOCHS} | "
            f"Train Loss: {train_metrics['loss']:.4f} | Val Loss: {val_metrics['loss']:.4f} | "
            f"Train IoU: {train_metrics['iou']:.4f} | Val IoU: {val_metrics['iou']:.4f} | "
        )

        # Ajouter d'autres métriques si disponibles
        for metric_name in ['accuracy', 'f1_score']:
            if metric_name in train_metrics and metric_name in val_metrics:
                metrics_summary += f"Val {metric_name.capitalize()}: {val_metrics[metric_name]:.4f} | "

        metrics_summary += f"LR: {current_lr:.6f} | Temps: {epoch_time:.2f}s"
        print(metrics_summary)

        # Si des callbacks sont fournis et possèdent la méthode after_epoch, l'appeler
        continue_training = True
        if callbacks and hasattr(callbacks, 'after_epoch'):
            continue_training = callbacks.after_epoch(
                epoch, model, optimizer, train_metrics, val_metrics, tracker, improved
            )
            if continue_training is False:
                print("Entraînement interrompu par le callback after_epoch")
                break

        # Sauvegarder le meilleur modèle
        should_save = True
        if callbacks and hasattr(callbacks, 'should_save_checkpoint'):
            should_save = callbacks.should_save_checkpoint(epoch, model, optimizer, improved)

        if improved and should_save:
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': val_metrics['loss'],
                'val_iou': val_metrics['iou'],
                'val_metrics': val_metrics
            }

            if scheduler is not None:
                checkpoint['scheduler_state_dict'] = scheduler.state_dict()

            torch.save(checkpoint, best_model_path)
            print(f"✅ Modèle sauvegardé: {best_model_path}")

            # Sauvegarder les métriques
            tracker.save(os.path.join(config.LOGS_DIR, 'metrics.pkl'))

        # Vérifier les critères d'arrêt précoce
        if tracker.epochs_without_improvement >= patience:
            print(f"Arrêt précoce après {epoch+1} époques sans amélioration.")
            break

    # Calculer le temps total d'entraînement
    total_time = time.time() - start_time
    print(f"Entraînement terminé en {total_time/60:.2f} minutes")

    # Stocker le temps d'entraînement dans le tracker
    tracker.train_time = total_time

    # Ajouter des hyperparamètres à TensorBoard
    hparams = {
        'batch_size': config.BATCH_SIZE,
        'learning_rate': config.LEARNING_RATE,
        'dropout_rate': config.DROPOUT_RATE,
        'thresholds': str(config.THRESHOLDS),
        'epochs': epoch + 1,
        'early_stopping_patience': patience,
    }

    metrics = {
        'hparam/best_val_loss': tracker.best_val_loss,
        'hparam/best_val_iou': tracker.best_val_iou,
        'hparam/train_time_minutes': total_time/60
    }

    tracker.writer.add_hparams(hparams, metrics)

    # Visualiser l'évolution des métriques
    visualize_metrics_evolution(
        tracker,
        save_path=os.path.join(config.VISUALIZATIONS_DIR, 'learning_curves.png')
    )

    # Charger le meilleur modèle
    try:
        checkpoint = torch.load(best_model_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        print(f"Meilleur modèle chargé (époque {checkpoint['epoch']+1})")
    except Exception as e:
        print(f"⚠️ Impossible de charger le meilleur modèle: {str(e)}")
        print("Utilisation du modèle actuel comme meilleur modèle.")

    return model, tracker

def test_model(model, test_loader, device, config, segmentation_metrics=None, threshold=0.5, visualize=True):
    """
    Évalue le modèle sur l'ensemble de test avec évaluation complète des métriques.

    Args:
        model: Modèle PyTorch
        test_loader: DataLoader pour les données de test
        device: Périphérique (CPU ou GPU)
        config: Configuration
        segmentation_metrics: Objet SegmentationMetrics (créé si None)
        threshold: Seuil pour binariser les prédictions
        visualize: Si True, génère des visualisations

    Returns:
        Dictionnaire de métriques et résultats visuels
    """
    model.eval()

    # Créer l'objet de métriques si non fourni
    if segmentation_metrics is None:
        segmentation_metrics = SegmentationMetrics(device)
    else:
        segmentation_metrics.reset()

    # Collecter quelques exemples pour visualisation
    visualization_samples = []

    progress_bar = tqdm(
        total=len(test_loader),
        desc="Test",
        position=0,
        leave=True,
        bar_format='{l_bar}{bar:30}{r_bar}{bar:-10b}',
        dynamic_ncols=True
    )

    try:
        with torch.no_grad():
            for dsm, threshold_val, target in test_loader:
                # Gérer le cas où le batch est vide
                if dsm.size(0) == 0:
                    continue

                # Déplacer les tenseurs vers le périphérique
                dsm = dsm.to(device)
                threshold_val = threshold_val.to(device)
                target = target.to(device)

                # Forward pass
                output = model(dsm, threshold_val)

                # Mettre à jour les métriques
                segmentation_metrics.update(output, target)

                # Mettre à jour les métriques spécifiques au seuil
                threshold_value = threshold_val[0].item() * max(test_loader.dataset.thresholds)
                closest_threshold = min(test_loader.dataset.thresholds, key=lambda x: abs(x - threshold_value))
                segmentation_metrics.update_by_threshold(output, target, closest_threshold)

                # Collecter quelques échantillons pour visualisation
                if visualize and len(visualization_samples) < 5:
                    for i in range(min(dsm.size(0), 5 - len(visualization_samples))):
                        visualization_samples.append({
                            'dsm': dsm[i].cpu().numpy(),
                            'target': target[i].cpu().numpy(),
                            'output': output[i].cpu().numpy(),
                            'threshold': threshold_val[i].item() * max(config.THRESHOLDS)
                        })

                # Mettre à jour la barre de progression
                progress_bar.update(1)

        # Fermer la barre de progression
        progress_bar.close()

        # Calculer les métriques
        metrics = segmentation_metrics.compute()
        confusion_data = segmentation_metrics.compute_confusion_matrix()

        # Afficher le tableau des métriques
        metrics_table = create_metrics_tables(metrics, title="Métriques d'évaluation sur l'ensemble de test")
        print(metrics_table)

        # Créer des visualisations si demandé
        results = {
            'metrics': metrics,
            'confusion_data': confusion_data
        }

        if visualize and visualization_samples:
            try:
                # Visualisation de la matrice de confusion
                confusion_fig = visualize_confusion_matrix(
                    confusion_data,
                    title="Matrice de confusion sur l'ensemble de test",
                    save_path=os.path.join(config.VISUALIZATIONS_DIR, 'test_confusion_matrix.png')
                )
                results['confusion_fig'] = confusion_fig

                # Visualisation des métriques par seuil
                if 'threshold_metrics' in metrics and metrics['threshold_metrics']:
                    threshold_fig = visualize_metrics_by_threshold(
                        metrics,
                        title="Métriques par seuil sur l'ensemble de test",
                        save_path=os.path.join(config.VISUALIZATIONS_DIR, 'test_metrics_by_threshold.png')
                    )
                    results['threshold_fig'] = threshold_fig

                # Visualisation des prédictions
                predictions_fig = visualize_predictions_grid(
                    model, test_loader, device, config,
                    num_samples=5, threshold_idx=0
                )
                plt.savefig(os.path.join(config.VISUALIZATIONS_DIR, 'test_predictions.png'), dpi=300, bbox_inches='tight')
                plt.show()
                results['predictions_fig'] = predictions_fig

                # Visualisation comparative par seuil
                comparison_fig = visualize_threshold_comparison(
                    model, test_loader, device, config,
                    sample_idx=0
                )
                if comparison_fig is not None:
                    plt.savefig(os.path.join(config.VISUALIZATIONS_DIR, 'test_threshold_comparison.png'), dpi=300, bbox_inches='tight')
                    plt.show()
                    results['comparison_fig'] = comparison_fig

            except Exception as e:
                print(f"Erreur lors de la visualisation: {str(e)}")
                print(traceback.format_exc())

        return results

    except Exception as e:
        progress_bar.close()
        print(f"Erreur lors de l'évaluation du modèle: {str(e)}")
        print(traceback.format_exc())

        # Retourner des métriques par défaut en cas d'erreur
        return {
            'metrics': {'iou': 0.0, 'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0, 'kappa': 0.0},
            'confusion_data': {'matrix': {'tp': 0, 'fp': 0, 'tn': 0, 'fn': 0}, 'percentages': {}, 'total_pixels': 0}
        }

"""## SECTION 8: FONCTIONS DE PRÉDICTION ET UTILITAIRES"""

# =====================================================================
# SECTION 8: FONCTIONS DE PRÉDICTION ET UTILITAIRES
# =====================================================================

def predict_on_tiles(model, tile_info, threshold_value, device, config):
    """
    Fait des prédictions sur un ensemble de tuiles.

    Args:
        model: Modèle PyTorch
        tile_info: Liste d'informations sur les tuiles
        threshold_value: Seuil de hauteur pour la segmentation
        device: Périphérique (CPU ou GPU)
        config: Configuration

    Returns:
        Liste des prédictions pour chaque tuile
    """
    model.eval()
    predictions = []

    # Normaliser le seuil
    normalized_threshold = threshold_value / max(config.THRESHOLDS)
    threshold_tensor = torch.tensor([[normalized_threshold]], dtype=torch.float32).to(device)

    with torch.no_grad():
        for info in tqdm(tile_info, desc=f"Prédictions (seuil {threshold_value}m)"):
            # Charger la tuile DSM
            dsm_tile = np.load(info['dsm_path'])

            # Normaliser
            dsm_valid = ~np.isnan(dsm_tile)
            if np.any(dsm_valid):
                dsm_min = np.nanmin(dsm_tile)
                dsm_max = np.nanmax(dsm_tile)
                dsm_range = dsm_max - dsm_min
                if dsm_range > 0:
                    dsm_tile = np.where(dsm_valid, (dsm_tile - dsm_min) / dsm_range, 0)
                else:
                    dsm_tile = np.where(dsm_valid, 0, 0)

            # Convertir en tensor
            dsm_tensor = torch.tensor(dsm_tile, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)

            # Faire la prédiction
            output = model(dsm_tensor, threshold_tensor)

            # Convertir en NumPy
            prediction = torch.sigmoid(output).squeeze().cpu().numpy()

            predictions.append({
                'site': info['site'],
                'row_idx': info['row_idx'],
                'col_idx': info['col_idx'],
                'prediction': prediction
            })

    return predictions

def visualize_predictions_with_actual(model, tile_info, threshold_value, device, config, num_samples=5):
    """
    Visualise les prédictions du modèle comparées aux masques réels.

    Args:
        model: Modèle PyTorch
        tile_info: Liste d'informations sur les tuiles
        threshold_value: Seuil de hauteur pour la segmentation
        device: Périphérique (CPU ou GPU)
        config: Configuration
        num_samples: Nombre d'exemples à visualiser
    """
    model.eval()

    # Sélectionner des tuiles aléatoires
    indices = np.random.choice(len(tile_info), num_samples, replace=False)

    # Normaliser le seuil
    normalized_threshold = threshold_value / max(config.THRESHOLDS)
    threshold_tensor = torch.tensor([[normalized_threshold]], dtype=torch.float32).to(device)

    # Créer la figure
    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))

    with torch.no_grad():
        for i, idx in enumerate(indices):
            info = tile_info[idx]

            # Charger la tuile DSM
            dsm_tile = np.load(info['dsm_path'])

            # Charger le masque réel
            mask_path = info['mask_paths'][threshold_value]
            mask_tile = np.load(mask_path)

            # Convertir le masque en binaire
            mask_valid = (mask_tile != 255)
            mask_binary = np.where(mask_valid, (mask_tile > 0).astype(np.float32), 0)

            # Normaliser la tuile DSM
            dsm_valid = ~np.isnan(dsm_tile)
            dsm_display = dsm_tile.copy()  # Pour l'affichage

            if np.any(dsm_valid):
                dsm_min = np.nanmin(dsm_tile)
                dsm_max = np.nanmax(dsm_tile)
                dsm_range = dsm_max - dsm_min
                if dsm_range > 0:
                    dsm_tile = np.where(dsm_valid, (dsm_tile - dsm_min) / dsm_range, 0)
                else:
                    dsm_tile = np.where(dsm_valid, 0, 0)

            # Convertir en tensor
            dsm_tensor = torch.tensor(dsm_tile, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)

            # Faire la prédiction
            output = model(dsm_tensor, threshold_tensor)

            # Convertir en NumPy
            prediction = output.squeeze().cpu().numpy()

            # Calculer l'IoU
            pred_tensor = torch.sigmoid(torch.tensor(prediction, dtype=torch.float32)).unsqueeze(0).unsqueeze(0)
            mask_tensor = torch.tensor(mask_binary, dtype=torch.float32).unsqueeze(0).unsqueeze(0)
            iou = iou_metric(pred_tensor, mask_tensor).item()

            # Afficher
            axes[i, 0].imshow(dsm_display, cmap='terrain')
            axes[i, 0].set_title(f"DSM - {info['site']}")

            axes[i, 1].imshow(mask_binary, cmap='binary')
            axes[i, 1].set_title(f"Trouées réelles (seuil {threshold_value}m)")

            axes[i][2].imshow(torch.sigmoid(torch.tensor(prediction)).numpy() > 0.5, cmap='binary')
            axes[i, 2].set_title(f"Trouées prédites (IoU: {iou:.4f})")

    plt.tight_layout()
    plt.savefig(os.path.join(config.VISUALIZATIONS_DIR, f'predictions_threshold_{threshold_value}m.png'), dpi=300)
    plt.show()

def load_or_create_dummy_data(config):
    """
    Fonction utilitaire pour charger les informations sur les tuiles
    ou créer des données fictives si nécessaire.

    Args:
        config: Configuration du projet

    Returns:
        Tuple (train_tile_info, val_tile_info, test_tile_info)
    """
    train_info_path = os.path.join(config.TILES_DIR, 'train_tile_info.pkl')
    val_info_path = os.path.join(config.TILES_DIR, 'val_tile_info.pkl')
    test_info_path = os.path.join(config.TILES_DIR, 'test_tile_info.pkl')

    try:
        # Essayer de charger les fichiers d'information
        if os.path.exists(train_info_path):
            with open(train_info_path, 'rb') as f:
                train_tile_info = pickle.load(f)
        else:
            raise FileNotFoundError(f"Fichier manquant: {train_info_path}")

        if os.path.exists(val_info_path):
            with open(val_info_path, 'rb') as f:
                val_tile_info = pickle.load(f)
        else:
            raise FileNotFoundError(f"Fichier manquant: {val_info_path}")

        if os.path.exists(test_info_path):
            with open(test_info_path, 'rb') as f:
                test_tile_info = pickle.load(f)
        else:
            raise FileNotFoundError(f"Fichier manquant: {test_info_path}")

    except (FileNotFoundError, pickle.UnpicklingError) as e:
        print(f"ERREUR lors du chargement des fichiers: {str(e)}")

        # Créer des données factices pour test
        print("Création de données factices pour développement...")

        def create_dummy_tile_info(num_tiles):
            dummy_info = []
            tile_size = config.TILE_SIZE

            for i in range(num_tiles):
                # Créer des faux chemins de fichiers
                dsm_path = f"/tmp/dummy_dsm_{i}.npy"
                mask_paths = {t: f"/tmp/dummy_mask_{i}_{t}m.npy" for t in config.THRESHOLDS}

                # Créer des données factices pour simuler les tuiles
                if not os.path.exists(dsm_path):
                    np.save(dsm_path, np.random.rand(tile_size, tile_size))

                for t, path in mask_paths.items():
                    if not os.path.exists(path):
                        np.save(path, (np.random.rand(tile_size, tile_size) > 0.7).astype(np.uint8))

                dummy_info.append({
                    'site': f'dummy_site_{i//10}',
                    'row_idx': i % 10,
                    'col_idx': i % 10,
                    'window': None,
                    'dsm_path': dsm_path,
                    'mask_paths': mask_paths
                })
            return dummy_info

        # Créer des données factices
        train_tile_info = create_dummy_tile_info(100)
        val_tile_info = create_dummy_tile_info(20)
        test_tile_info = create_dummy_tile_info(20)

    return train_tile_info, val_tile_info, test_tile_info

"""## SECTION X: FONCTIONS DE VISUALISATION ET REPORTING"""

# =====================================================================
# SECTION X: FONCTIONS DE VISUALISATION ET REPORTING
# =====================================================================

def visualize_metrics_evolution(tracker, save_path=None):
    """
    Visualise l'évolution de toutes les métriques pendant l'entraînement.

    Args:
        tracker: Objet LossTracker contenant l'historique des métriques
        save_path: Chemin pour sauvegarder la figure (optionnel)
    """
    # Récupérer les données d'historique
    history = {
        'epochs': list(range(1, len(tracker.train_losses) + 1)),
        'train_loss': tracker.train_losses,
        'val_loss': tracker.val_losses,
        'train_iou': tracker.train_iou,
        'val_iou': tracker.val_iou,
        'lr': tracker.lr_history
    }

    # Ajouter d'autres métriques si disponibles
    for metric_name in ['accuracy', 'precision', 'recall', 'f1_score', 'kappa']:
        train_key = f'train_{metric_name}'
        val_key = f'val_{metric_name}'

        if hasattr(tracker, train_key) and hasattr(tracker, val_key):
            history[train_key] = getattr(tracker, train_key)
            history[val_key] = getattr(tracker, val_key)

    # Créer des sous-figures pour chaque groupe de métriques
    plt.figure(figsize=(20, 15))

    # Nombre de lignes à calculer en fonction des métriques disponibles
    metrics_count = 1  # Loss est toujours présent
    for metric_pair in [('iou', 'IoU'), ('accuracy', 'Accuracy'),
                      ('precision', 'Precision'), ('recall', 'Recall'),
                      ('f1_score', 'F1-Score'), ('kappa', 'Kappa')]:
        metric_key, _ = metric_pair
        train_key = f'train_{metric_key}'
        if train_key in history:
            metrics_count += 1

    # Ajout d'un graphique pour le taux d'apprentissage
    num_rows = metrics_count + 1

    # 1. Graphique des pertes
    plt.subplot(num_rows, 1, 1)
    plt.plot(history['epochs'], history['train_loss'], 'b-', label='Entraînement')
    plt.plot(history['epochs'], history['val_loss'], 'r-', label='Validation')
    plt.xlabel('Époque')
    plt.ylabel('Perte')
    plt.title('Évolution de la fonction de perte')
    plt.legend()
    plt.grid(True)

    # 2. Graphiques pour chaque métrique disponible
    current_row = 2

    for metric_pair in [('iou', 'IoU'), ('accuracy', 'Accuracy'),
                      ('precision', 'Precision'), ('recall', 'Recall'),
                      ('f1_score', 'F1-Score'), ('kappa', 'Kappa')]:
        metric_key, metric_name = metric_pair
        train_key = f'train_{metric_key}'
        val_key = f'val_{metric_key}'

        if train_key in history:
            plt.subplot(num_rows, 1, current_row)
            plt.plot(history['epochs'], history[train_key], 'b-', label='Entraînement')
            plt.plot(history['epochs'], history[val_key], 'r-', label='Validation')
            plt.xlabel('Époque')
            plt.ylabel(metric_name)
            plt.title(f'Évolution de {metric_name}')
            plt.legend()
            plt.grid(True)
            current_row += 1

    # Graphique du taux d'apprentissage
    plt.subplot(num_rows, 1, num_rows)
    plt.plot(history['epochs'], history['lr'], 'g-')
    plt.xlabel('Époque')
    plt.ylabel('Taux d\'apprentissage')
    plt.title('Évolution du taux d\'apprentissage')
    plt.grid(True)
    plt.yscale('log')

    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=300)
        print(f"Graphiques d'évolution des métriques sauvegardés dans {save_path}")

    plt.show()


def visualize_metrics_by_threshold(metrics, title="Métriques par seuil", save_path=None):
    """
    Visualise les métriques en fonction du seuil de hauteur.

    Args:
        metrics: Dictionnaire de métriques retourné par SegmentationMetrics.compute()
        title: Titre de la figure
        save_path: Chemin pour sauvegarder la figure (optionnel)
    """
    if 'threshold_metrics' not in metrics or not metrics['threshold_metrics']:
        print("Aucune métrique par seuil disponible")
        return

    # Extraire les données
    thresholds = sorted(metrics['threshold_metrics'].keys())

    # Métriques à visualiser
    metric_configs = [
        ('accuracy', 'Accuracy', 'tab:blue'),
        ('precision', 'Precision', 'tab:orange'),
        ('recall', 'Recall', 'tab:green'),
        ('f1_score', 'F1-Score', 'tab:red'),
        ('iou', 'IoU', 'tab:purple')
    ]

    # Créer la figure
    plt.figure(figsize=(14, 10))

    # Tracer chaque métrique
    for metric_key, metric_name, color in metric_configs:
        values = [metrics['threshold_metrics'][t][metric_key] for t in thresholds]
        plt.plot(thresholds, values, '-o', color=color, label=metric_name)

    plt.xlabel('Seuil de hauteur (m)')
    plt.ylabel('Valeur')
    plt.title(title)
    plt.grid(True)
    plt.legend()

    # Ajouter des annotations pour chaque point
    for metric_key, metric_name, color in metric_configs:
        for i, threshold in enumerate(thresholds):
            value = metrics['threshold_metrics'][threshold][metric_key]
            plt.annotate(
                f'{value:.3f}',
                (threshold, value),
                textcoords="offset points",
                xytext=(0, 10),
                ha='center',
                fontsize=8,
                color=color
            )

    # Ajuster les limites de l'axe y
    plt.ylim(0, 1.1)

    if save_path:
        plt.savefig(save_path, dpi=300)
        print(f"Graphique des métriques par seuil sauvegardé dans {save_path}")

    plt.show()


def visualize_confusion_matrix(confusion_data, title="Matrice de confusion", save_path=None):
    """
    Visualise la matrice de confusion sous forme de heatmap.

    Args:
        confusion_data: Dictionnaire retourné par SegmentationMetrics.compute_confusion_matrix()
        title: Titre de la figure
        save_path: Chemin pour sauvegarder la figure (optionnel)
    """
    # Extraire les valeurs de la matrice
    matrix = confusion_data['matrix']
    percentages = confusion_data['percentages']

    # Créer la matrice 2x2
    conf_matrix = np.array([
        [matrix['tp'], matrix['fp']],
        [matrix['fn'], matrix['tn']]
    ])

    # Créer la matrice des pourcentages
    percent_matrix = np.array([
        [percentages['tp_percent'], percentages['fp_percent']],
        [percentages['fn_percent'], percentages['tn_percent']]
    ])

    # Définir les labels
    class_names = ['Trouée', 'Non-trouée']

    # Créer la figure
    plt.figure(figsize=(10, 8))

    # Afficher la heatmap
    im = plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)
    plt.colorbar(im, fraction=0.046, pad=0.04)

    # Ajouter les titres et labels
    plt.title(title)
    plt.ylabel('Vérité terrain')
    plt.xlabel('Prédiction')

    # Ajouter les classes
    tick_marks = np.arange(len(class_names))
    plt.xticks(tick_marks, class_names)
    plt.yticks(tick_marks, class_names)

    # Ajouter les valeurs dans chaque cellule
    thresh = conf_matrix.max() / 2.
    for i in range(conf_matrix.shape[0]):
        for j in range(conf_matrix.shape[1]):
            plt.text(j, i, f"{conf_matrix[i, j]}\n({percent_matrix[i, j]:.2f}%)",
                     horizontalalignment="center",
                     verticalalignment="center",
                     color="white" if conf_matrix[i, j] > thresh else "black")

    # Ajouter des informations supplémentaires
    info_text = f"""
    Total pixels: {confusion_data['total_pixels']:,}

    Vrais positifs (TP): {matrix['tp']:,} ({percentages['tp_percent']:.2f}%)
    Faux positifs (FP): {matrix['fp']:,} ({percentages['fp_percent']:.2f}%)
    Vrais négatifs (TN): {matrix['tn']:,} ({percentages['tn_percent']:.2f}%)
    Faux négatifs (FN): {matrix['fn']:,} ({percentages['fn_percent']:.2f}%)
    """

    plt.figtext(0.5, -0.05, info_text, horizontalalignment='center', fontsize=10,
                bbox=dict(facecolor='white', alpha=0.8))

    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"Matrice de confusion sauvegardée dans {save_path}")

    plt.show()


def visualize_predictions_grid(model, data_loader, device, config, num_samples=5, threshold_idx=0):
    """
    Crée une grille de visualisations des prédictions sur plusieurs échantillons.

    Args:
        model: Modèle U-Net
        data_loader: DataLoader contenant les données
        device: Périphérique (GPU/CPU)
        config: Configuration
        num_samples: Nombre d'échantillons à visualiser
        threshold_idx: Index du seuil de hauteur à utiliser

    Returns:
        Figure matplotlib
    """
    model.eval()

    # Sélectionner le seuil
    threshold = config.THRESHOLDS[threshold_idx]
    normalized_threshold = threshold / max(config.THRESHOLDS)
    threshold_tensor = torch.tensor([[normalized_threshold]], dtype=torch.float32).to(device)

    # Collecter les échantillons
    samples = []
    with torch.no_grad():
        for dsm, _, target in data_loader:
            # Prendre seulement le nombre d'échantillons nécessaires
            for i in range(min(dsm.size(0), num_samples - len(samples))):
                dsm_i = dsm[i:i+1].to(device)
                target_i = target[i:i+1].to(device)

                # Prédiction
                output_i = model(dsm_i, threshold_tensor)
                pred_binary = (torch.sigmoid(output_i) > 0.5).float()

                # Calculer l'IoU pour cet échantillon
                iou = iou_metric(output_i, target_i).item()

                # Ajouter l'échantillon
                samples.append({
                    'dsm': dsm_i.cpu().numpy()[0, 0],
                    'target': target_i.cpu().numpy()[0, 0],
                    'output': torch.sigmoid(output_i).cpu().numpy()[0, 0],
                    'pred_binary': pred_binary.cpu().numpy()[0, 0],
                    'iou': iou
                })

                if len(samples) >= num_samples:
                    break

            if len(samples) >= num_samples:
                break

    # Créer la figure
    fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4 * num_samples))

    # Titres des colonnes
    column_titles = ['DSM', 'Vérité terrain', 'Prédiction (probabilité)', 'Prédiction (binaire)']

    # Ajouter les titres des colonnes
    for j, title in enumerate(column_titles):
        fig.text(0.125 + j * 0.22, 0.95, title, ha='center', va='center', fontsize=14)

    # Pour chaque échantillon
    for i, sample in enumerate(samples):
        # DSM
        im = axes[i, 0].imshow(sample['dsm'], cmap='terrain')
        fig.colorbar(im, ax=axes[i, 0], fraction=0.046, pad=0.04)
        axes[i, 0].set_title(f"DSM")

        # Vérité terrain
        axes[i, 1].imshow(sample['target'], cmap='binary', vmin=0, vmax=1)
        axes[i, 1].set_title(f"Trouées réelles (seuil {threshold}m)")

        # Prédiction (probabilité)
        im = axes[i, 2].imshow(sample['output'], cmap='plasma', vmin=0, vmax=1)
        fig.colorbar(im, ax=axes[i, 2], fraction=0.046, pad=0.04)
        axes[i, 2].set_title(f"Probabilité")

        # Prédiction (binaire)
        axes[i, 3].imshow(sample['pred_binary'], cmap='binary', vmin=0, vmax=1)
        axes[i, 3].set_title(f"IoU: {sample['iou']:.4f}")

    # Supprimer les axes
    for ax in axes.flat:
        ax.axis('off')

    plt.tight_layout()
    return fig


def visualize_threshold_comparison(model, data_loader, device, config, sample_idx=0):
    """
    Visualise les prédictions du modèle pour différents seuils de hauteur sur un même échantillon.

    Args:
        model: Modèle U-Net
        data_loader: DataLoader contenant les données
        device: Périphérique (GPU/CPU)
        config: Configuration
        sample_idx: Index de l'échantillon à visualiser

    Returns:
        Figure matplotlib
    """
    model.eval()

    # Obtenir un échantillon
    sample_found = False
    dsm_sample = None

    with torch.no_grad():
        for idx, (dsm, _, _) in enumerate(data_loader):
            if idx * data_loader.batch_size + sample_idx < len(data_loader.dataset):
                if sample_idx < dsm.size(0):
                    dsm_sample = dsm[sample_idx:sample_idx+1].to(device)
                    sample_found = True
                    break

    if not sample_found or dsm_sample is None:
        print(f"Échantillon à l'index {sample_idx} non trouvé")
        return None

    # Créer la figure
    rows = len(config.THRESHOLDS)
    fig, axes = plt.subplots(rows, 3, figsize=(12, 4 * rows))

    # Afficher le DSM original seulement une fois
    dsm_np = dsm_sample.cpu().numpy()[0, 0]

    # Pour chaque seuil
    for i, threshold in enumerate(config.THRESHOLDS):
        # Normaliser le seuil
        normalized_threshold = threshold / max(config.THRESHOLDS)
        threshold_tensor = torch.tensor([[normalized_threshold]], dtype=torch.float32).to(device)

        # Prédiction
        output = model(dsm_sample, threshold_tensor)
        pred_prob = torch.sigmoid(output).cpu().numpy()[0, 0]
        pred_binary = (pred_prob > 0.5).astype(float)

        # DSM
        if i == 0:
            im = axes[i, 0].imshow(dsm_np, cmap='terrain')
            fig.colorbar(im, ax=axes[i, 0], fraction=0.046, pad=0.04)
        else:
            axes[i, 0].imshow(dsm_np, cmap='terrain')

        axes[i, 0].set_title(f"DSM (seuil {threshold}m)")

        # Prédiction (probabilité)
        im = axes[i, 1].imshow(pred_prob, cmap='plasma', vmin=0, vmax=1)
        fig.colorbar(im, ax=axes[i, 1], fraction=0.046, pad=0.04)
        axes[i, 1].set_title(f"Probabilité")

        # Prédiction (binaire)
        axes[i, 2].imshow(pred_binary, cmap='binary', vmin=0, vmax=1)
        axes[i, 2].set_title(f"Trouées prédites")

    # Supprimer les axes
    for ax in axes.flat:
        ax.axis('off')

    plt.tight_layout()
    return fig


def create_metrics_tables(metrics, title="Métriques d'évaluation"):
    """
    Crée des tableaux formatés pour afficher les métriques dans la console.

    Args:
        metrics: Dictionnaire de métriques
        title: Titre du tableau

    Returns:
        Chaîne formatée contenant le tableau de métriques
    """
    # Fonction pour formater les nombres
    def format_num(num):
        return f"{num:.4f}"

    # Largeur des colonnes
    col_width = 16

    # Créer la ligne d'en-tête avec des séparateurs
    header = f"{'=' * (col_width * 5)}\n"
    header += f"{title.center(col_width * 5)}\n"
    header += f"{'-' * (col_width * 5)}\n"

    # Tableau des métriques globales
    global_table = f"MÉTRIQUES GLOBALES:\n"
    global_table += f"{'Métrique'.ljust(col_width)}{'Valeur'.ljust(col_width)}\n"
    global_table += f"{'-' * (col_width * 2)}\n"

    for metric_name, display_name in [
        ('accuracy', 'Accuracy'),
        ('balanced_accuracy', 'Balanced Acc.'),
        ('precision', 'Precision'),
        ('recall', 'Recall'),
        ('f1_score', 'F1-Score'),
        ('iou', 'IoU'),
        ('kappa', 'Kappa')
    ]:
        if metric_name in metrics:
            global_table += f"{display_name.ljust(col_width)}{format_num(metrics[metric_name]).ljust(col_width)}\n"

    # Tableau des moyennes par image
    mean_table = f"\nMOYENNES PAR IMAGE:\n"
    mean_table += f"{'Métrique'.ljust(col_width)}{'Valeur'.ljust(col_width)}\n"
    mean_table += f"{'-' * (col_width * 2)}\n"

    for metric_name, display_name in [
        ('precision_mean', 'Precision Mean'),
        ('recall_mean', 'Recall Mean'),
        ('f1_mean', 'F1-Score Mean'),
        ('iou_mean', 'IoU Mean')
    ]:
        if metric_name in metrics:
            mean_table += f"{display_name.ljust(col_width)}{format_num(metrics[metric_name]).ljust(col_width)}\n"

    # Tableau des métriques par seuil
    threshold_table = ""
    if 'threshold_metrics' in metrics and metrics['threshold_metrics']:
        threshold_table += f"\nMÉTRIQUES PAR SEUIL:\n"

        # En-tête avec les seuils
        threshold_header = "Métrique".ljust(col_width)
        thresholds = sorted(metrics['threshold_metrics'].keys())

        for threshold in thresholds:
            threshold_header += f"{f'Seuil {threshold}m'.ljust(col_width)}"

        threshold_table += threshold_header + "\n"
        threshold_table += f"{'-' * (col_width * (len(thresholds) + 1))}\n"

        # Remplir le tableau par métrique
        for metric_name, display_name in [
            ('accuracy', 'Accuracy'),
            ('precision', 'Precision'),
            ('recall', 'Recall'),
            ('f1_score', 'F1-Score'),
            ('iou', 'IoU'),
            ('precision_mean', 'Prec. Mean'),
            ('recall_mean', 'Recall Mean'),
            ('f1_mean', 'F1 Mean'),
            ('iou_mean', 'IoU Mean')
        ]:
            row = display_name.ljust(col_width)

            for threshold in thresholds:
                t_metrics = metrics['threshold_metrics'][threshold]
                if metric_name in t_metrics:
                    row += format_num(t_metrics[metric_name]).ljust(col_width)
                else:
                    row += "N/A".ljust(col_width)

            threshold_table += row + "\n"

    # Assembler tous les tableaux
    return header + global_table + mean_table + threshold_table + f"{'=' * (col_width * 5)}"


def visualize_predictions_tensorboard(model, dataloader, device, writer, epoch, threshold_value, num_samples=4):
    """
    Visualise quelques prédictions du modèle dans TensorBoard avec des métriques enrichies.

    Args:
        model: Modèle U-Net
        dataloader: DataLoader contenant les données de validation ou test
        device: Périphérique (GPU/CPU)
        writer: SummaryWriter de TensorBoard
        epoch: Époque actuelle
        threshold_value: Valeur de seuil utilisée (pour le titre)
        num_samples: Nombre d'exemples à visualiser
    """
    model.eval()

    # Create an object SegmentationMetrics to calculate metrics on these samples
    metrics_calculator = SegmentationMetrics(device)

    # Get some samples
    samples = []
    with torch.no_grad():
        for dsm, threshold, target in dataloader:
            if len(samples) >= num_samples:
                break

            # Take only the necessary number of samples
            for i in range(min(dsm.size(0), num_samples - len(samples))):
                # Check if this threshold corresponds to the one requested
                threshold_val = threshold[i].item() * max(dataloader.dataset.thresholds)
                closest_threshold = min(dataloader.dataset.thresholds, key=lambda x: abs(x - threshold_val))

                if abs(closest_threshold - threshold_value) > 1.0:  # Tolerance of 1m
                    continue

                # Prediction for this sample
                dsm_i = dsm[i:i+1].to(device)
                threshold_i = threshold[i:i+1].to(device)
                target_i = target[i:i+1].to(device)

                # Prediction
                output_i = model(dsm_i, threshold_i)

                # Calculate metrics for this sample
                metrics_calculator.reset()
                metrics_calculator.update(output_i, target_i)
                sample_metrics = metrics_calculator.compute()

                # Add to samples
                samples.append({
                    'dsm': dsm_i.cpu(),
                    'target': target_i.cpu(),
                    'output': output_i.cpu(),
                    'threshold_val': threshold_val,
                    'metrics': sample_metrics
                })

    # Create a grid of images for TensorBoard
    if samples:
        # Prepare the DSM images (convert to RGB for visualization)
        dsm_grid = []
        for sample in samples:
            # Normalize for visualization
            dsm_img = sample['dsm'][0]  # Shape [C, H, W]
            dsm_img = dsm_img.repeat(3, 1, 1)  # Convert to RGB by repeating the channel
            dsm_grid.append(dsm_img)

        # Prepare the mask images
        target_grid = []
        for sample in samples:
            # Convert to RGB (white = gap, black = non-gap)
            target_img = sample['target'][0].repeat(3, 1, 1)
            target_grid.append(target_img)

        # Prepare the prediction images (probabilities)
        prob_grid = []
        for sample in samples:
            # Apply a colormap for better visualization of probabilities
            prob = torch.sigmoid(sample['output'][0])
            # Create an RGB image with red channel for high probabilities
            prob_rgb = torch.zeros(3, prob.size(1), prob.size(2))
            prob_rgb[0] = prob  # Red channel
            prob_grid.append(prob_rgb)

        # Prepare the binary prediction images
        pred_grid = []
        for sample in samples:
            # Convert to RGB
            pred_binary = (torch.sigmoid(sample['output'][0]) > 0.5).float()
            pred_img = pred_binary.repeat(3, 1, 1)
            pred_grid.append(pred_img)

        # Merge into a single tensor for each type
        dsm_tensor = torch.stack(dsm_grid)
        target_tensor = torch.stack(target_grid)
        prob_tensor = torch.stack(prob_grid)
        pred_tensor = torch.stack(pred_grid)

        # Write to TensorBoard
        writer.add_images(f'DSM/threshold_{threshold_value}m', dsm_tensor, epoch)
        writer.add_images(f'Masks_True/threshold_{threshold_value}m', target_tensor, epoch)
        writer.add_images(f'Probabilities/threshold_{threshold_value}m', prob_tensor, epoch)
        writer.add_images(f'Predictions/threshold_{threshold_value}m', pred_tensor, epoch)

        # Create overlay images (prediction on DSM) - CORRECTION ICI
        overlay_grid = []
        for i, sample in enumerate(samples):
            # DSM in background with prediction in color
            dsm_rgb = dsm_grid[i]
            pred_binary = (torch.sigmoid(sample['output'][0]) > 0.5).float()

            # Create a colored version of the mask prediction (red)
            red_mask = torch.zeros_like(dsm_rgb)  # Créer un masque de même taille que dsm_rgb
            red_mask[0] = pred_binary  # Appliquer le masque binaire au canal rouge

            # Add the red mask to the DSM image with some transparency
            overlay = dsm_rgb.clone()
            overlay[0] = torch.clamp(overlay[0] + red_mask[0] * 0.7, 0, 1)  # Red channel
            overlay_grid.append(overlay)

        # Merge and add to TensorBoard
        overlay_tensor = torch.stack(overlay_grid)
        writer.add_images(f'Overlay/threshold_{threshold_value}m', overlay_tensor, epoch)

        # Also add the metrics for each sample
        for i, sample in enumerate(samples):
            metrics = sample['metrics']
            for metric_name, value in metrics.items():
                if isinstance(value, (int, float)):
                    writer.add_scalar(f'Samples/threshold_{threshold_value}m/sample_{i+1}/{metric_name}', value, epoch)

        # Calculate and add the average metrics for this batch of samples
        avg_metrics = {}
        for metric_name in ['iou', 'accuracy', 'precision', 'recall', 'f1_score']:
            values = [s['metrics'].get(metric_name, 0) for s in samples]
            if values:
                avg_metrics[metric_name] = sum(values) / len(values)
                writer.add_scalar(f'Averages/threshold_{threshold_value}m/{metric_name}', avg_metrics[metric_name], epoch)

        # Create an image with text to display the average metrics
        import matplotlib.pyplot as plt
        from io import BytesIO
        from PIL import Image

        fig, ax = plt.subplots(figsize=(10, 6))
        ax.axis('off')
        ax.text(0.5, 0.5, '\n'.join([f"{m.capitalize()}: {v:.4f}" for m, v in avg_metrics.items()]),
                ha='center', va='center', fontsize=14)

        # Convert the figure to an image for TensorBoard
        buf = BytesIO()
        fig.savefig(buf, format='png')
        buf.seek(0)
        img = Image.open(buf)
        img_tensor = torch.tensor(np.array(img)).permute(2, 0, 1).unsqueeze(0).float() / 255.0

        writer.add_images(f'Metrics/threshold_{threshold_value}m', img_tensor, epoch)
        plt.close(fig)

def print_config_summary(config, title="Configuration utilisée"):
    """Affiche un résumé des paramètres importants de la configuration"""
    print("\n" + "=" * 60)
    print(f"{title.center(60)}")
    print("=" * 60)
    print(f"• Nombre d'époques: {config.EPOCHS}")
    print(f"• Taille des batchs: {config.BATCH_SIZE}")
    print(f"• Type de modèle: {getattr(config, 'MODEL_TYPE', 'basic')}")
    print(f"• Seuils utilisés: {config.THRESHOLDS}")
    if hasattr(config, 'MAX_TRAIN_TILES'):
        print(f"• Tuiles d'entraînement: {config.MAX_TRAIN_TILES}")
        print(f"• Tuiles de validation: {config.MAX_VAL_TILES}")
        print(f"• Tuiles de test: {config.MAX_TEST_TILES}")
    print("=" * 60 + "\n")

"""## SECTION 9: CONFIGURATION ENVIRONNEMENT, WORKFLOW ET TEST

"""

# =====================================================================
# SECTION 9: CONFIGURATION ET TEST RAPIDE
# =====================================================================

def setup_quick_test_environment(config, use_quick_mode=False, max_train_tiles=20, max_val_tiles=5, max_test_tiles=5, epochs=None):
    """
    Configure un environnement de test rapide pour vérifier le workflow complet
    avec un nombre réduit de données et d'époques.

    Args:
        config: La configuration existante
        use_quick_mode: Si True, active le mode de test rapide
        max_train_tiles: Nombre maximum de tuiles d'entraînement à utiliser
        max_val_tiles: Nombre maximum de tuiles de validation à utiliser
        max_test_tiles: Nombre maximum de tuiles de test à utiliser
        epochs: Nombre d'époques personnalisé (remplace config.EPOCHS si fourni)

    Returns:
        Une configuration modifiée pour le test rapide
    """
    if not use_quick_mode:
        return config

    print("\n=== MODE TEST RAPIDE ACTIVÉ ===")

    # Créer une copie de la configuration pour ne pas modifier l'originale
    quick_config = Config()

    # Hériter des chemins et configurations de base
    for attr, value in vars(config).items():
        setattr(quick_config, attr, value)

    # Réduire les paramètres pour un test rapide
    quick_config.THRESHOLDS = config.THRESHOLDS[:2] if len(config.THRESHOLDS) > 2 else config.THRESHOLDS

    # Stocker les limites de tuiles
    quick_config.MAX_TRAIN_TILES = max_train_tiles
    quick_config.MAX_VAL_TILES = max_val_tiles
    quick_config.MAX_TEST_TILES = max_test_tiles

    # Appliquer le nombre d'époques personnalisé si fourni
    if epochs is not None:
        quick_config.EPOCHS = epochs

    # Création d'un dossier de test isolé avec timestamp pour éviter les conflits
    import datetime
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    test_dir = os.path.join(config.LOGS_DIR, f'quick_test_{timestamp}')
    os.makedirs(test_dir, exist_ok=True)

    # Remplacer les chemins de sauvegarde par des chemins dans le dossier de test
    quick_config.QUICK_TEST_DIR = test_dir
    quick_config.TEST_CHECKPOINTS_DIR = os.path.join(test_dir, 'checkpoints')
    quick_config.TEST_LOGS_DIR = os.path.join(test_dir, 'logs')
    quick_config.TEST_RESULTS_DIR = os.path.join(test_dir, 'results')
    quick_config.TEST_VISUALIZATIONS_DIR = os.path.join(test_dir, 'visualizations')

    # Créer les sous-répertoires
    for dir_path in [
        quick_config.TEST_CHECKPOINTS_DIR,
        quick_config.TEST_LOGS_DIR,
        quick_config.TEST_RESULTS_DIR,
        quick_config.TEST_VISUALIZATIONS_DIR
    ]:
        os.makedirs(dir_path, exist_ok=True)

    # Sauvegarder la configuration rapide
    quick_config.save_config(os.path.join(quick_config.TEST_LOGS_DIR, 'quick_config.json'))

    # Afficher le résumé de configuration
    print_config_summary(quick_config, "Configuration du mode test rapide")
    print(f"Environnement de test isolé créé dans: {test_dir}")

    return quick_config

def train_model_for_test(model, train_loader, val_loader, criterion, optimizer, scheduler, config, device):
    """
    Version simplifiée de train_model pour les tests rapides.
    Réutilise la fonction principale en modifiant certains paramètres pour le test.

    Args:
        Les mêmes que train_model

    Returns:
        Tuple (model, tracker)
    """
    # Créer une copie de la configuration pour le mode test
    test_config = copy.deepcopy(config)

    # Modifier les paramètres spécifiques pour le test
    if hasattr(config, 'QUICK_TEST_DIR'):
        # Remplacer les chemins par ceux du test
        test_config.CHECKPOINTS_DIR = getattr(config, 'TEST_CHECKPOINTS_DIR', config.CHECKPOINTS_DIR)
        test_config.LOGS_DIR = getattr(config, 'TEST_LOGS_DIR', config.LOGS_DIR)
        test_config.RESULTS_DIR = getattr(config, 'TEST_RESULTS_DIR', config.RESULTS_DIR)
        test_config.VISUALIZATIONS_DIR = getattr(config, 'TEST_VISUALIZATIONS_DIR', config.VISUALIZATIONS_DIR)

    # Forcer l'ignore des checkpoints existants pour le test
    class TestTrainingCallbacks:
        def before_training_start(self, model, optimizer, tracker):
            """Callback appelé avant le début de l'entraînement"""
            print("Mode TEST: Ignorer les checkpoints existants, démarrage à l'époque 0")
            return 0  # Forcer l'époque de départ à 0

        def after_epoch(self, epoch, model, optimizer, train_metrics, val_metrics, tracker, improved):
            """Callback appelé après chaque époque"""
            # Limiter le nombre d'évaluations visuelles en mode test
            return True  # Continuer l'entraînement

        def should_save_checkpoint(self, epoch, model, optimizer, improved):
            """Callback pour déterminer si on doit sauvegarder un checkpoint"""
            # En mode test, on peut limiter les sauvegardes
            return improved and epoch > 0  # Sauvegarder seulement si amélioré et après époque 0

    # Créer les callbacks de test
    test_callbacks = TestTrainingCallbacks()

    # Appeler la fonction principale avec les paramètres modifiés
    return train_model(
        model,
        train_loader,
        val_loader,
        criterion,
        optimizer,
        scheduler,
        test_config,
        device,
        callbacks=test_callbacks,
        is_test_mode=True  # Indicateur spécial pour le mode test
    )

def reduce_dataset_size(dataset_info, max_size=20):
    """
    Réduit la taille d'un dataset pour les tests rapides.

    Args:
        dataset_info: Liste d'informations sur les tuiles
        max_size: Nombre maximum de tuiles à conserver

    Returns:
        Une version réduite de la liste d'informations
    """
    if len(dataset_info) <= max_size:
        return dataset_info

    # Réduire la taille du dataset en sélectionnant un sous-ensemble
    # Stratégie: prendre des exemples distribués sur tous les sites
    sites = set(info['site'] for info in dataset_info)

    # Assurer une distribution équilibrée entre les sites
    reduced_info = []
    samples_per_site = max(1, max_size // len(sites))

    for site in sites:
        site_samples = [info for info in dataset_info if info['site'] == site]
        # Prendre les premiers échantillons (ou on pourrait les choisir aléatoirement)
        site_selection = site_samples[:samples_per_site]
        reduced_info.extend(site_selection)

    # Si nous n'avons pas assez d'échantillons, en ajouter d'autres
    if len(reduced_info) < max_size:
        remaining = [info for info in dataset_info if info not in reduced_info]
        reduced_info.extend(remaining[:max_size - len(reduced_info)])

    print(f"Dataset réduit de {len(dataset_info)} à {len(reduced_info)} échantillons")
    return reduced_info[:max_size]  # Assurer que nous ne dépassons pas max_sizedef run_workflow_test(use_quick_mode=True, custom_epochs=None, max_train_tiles=20, max_val_tiles=5, max_test_tiles=5):
    """
    Exécute un test rapide du workflow complet.

    Args:
        use_quick_mode: Si True, utilise la configuration rapide
        custom_epochs: Nombre personnalisé d'époques pour le test
        max_train_tiles: Nombre maximum de tuiles d'entraînement pour le mode test
        max_val_tiles: Nombre maximum de tuiles de validation pour le mode test
        max_test_tiles: Nombre maximum de tuiles de test pour le mode test

    Returns:
        Les résultats du test
    """
    print("\n=== DÉMARRAGE DU TEST DE WORKFLOW ===\n")

    # Initialiser la configuration standard
    standard_config = Config()

    # Appliquer la configuration rapide si demandé
    active_config = setup_quick_test_environment(
        standard_config,
        use_quick_mode,
        max_train_tiles,
        max_val_tiles,
        max_test_tiles,
        epochs=custom_epochs  # Passer les époques personnalisées
    )

    # Si custom_epochs est fourni, l'utiliser pour écraser EPOCHS
    if custom_epochs is not None and custom_epochs > 0:
        active_config.EPOCHS = custom_epochs
        print(f"Nombre d'époques personnalisé: {active_config.EPOCHS}")

    # Configurer l'entraînement avec la configuration active
    print("\nConfiguration de l'environnement d'entraînement...")

    # Au lieu d'appeler setup_model_training(), créons directement ce dont nous avons besoin
    train_info_path = os.path.join(active_config.TILES_DIR, 'train_tile_info.pkl')
    val_info_path = os.path.join(active_config.TILES_DIR, 'val_tile_info.pkl')
    test_info_path = os.path.join(active_config.TILES_DIR, 'test_tile_info.pkl')

    try:
        # Essayer de charger les fichiers d'information
        if os.path.exists(train_info_path):
            with open(train_info_path, 'rb') as f:
                train_tile_info = pickle.load(f)
        else:
            raise FileNotFoundError(f"Fichier manquant: {train_info_path}")

        if os.path.exists(val_info_path):
            with open(val_info_path, 'rb') as f:
                val_tile_info = pickle.load(f)
        else:
            raise FileNotFoundError(f"Fichier manquant: {val_info_path}")

        if os.path.exists(test_info_path):
            with open(test_info_path, 'rb') as f:
                test_tile_info = pickle.load(f)
        else:
            raise FileNotFoundError(f"Fichier manquant: {test_info_path}")

    except (FileNotFoundError, pickle.UnpicklingError) as e:
        print(f"ERREUR lors du chargement des fichiers: {str(e)}")

        # Créer des données factices pour test
        print("Création de données factices pour test uniquement...")

        def create_dummy_tile_info(num_tiles):
            dummy_info = []
            tile_size = active_config.TILE_SIZE

            for i in range(num_tiles):
                # Créer des faux chemins de fichiers
                dsm_path = f"/tmp/dummy_dsm_{i}.npy"
                mask_paths = {t: f"/tmp/dummy_mask_{i}_{t}m.npy" for t in active_config.THRESHOLDS}

                # Créer des données factices pour simuler les tuiles
                if not os.path.exists(dsm_path):
                    np.save(dsm_path, np.random.rand(tile_size, tile_size))

                for t, path in mask_paths.items():
                    if not os.path.exists(path):
                        np.save(path, (np.random.rand(tile_size, tile_size) > 0.7).astype(np.uint8))

                dummy_info.append({
                    'site': f'dummy_site_{i//10}',
                    'row_idx': i % 10,
                    'col_idx': i % 10,
                    'window': None,
                    'dsm_path': dsm_path,
                    'mask_paths': mask_paths
                })
            return dummy_info

        # Créer des données factices
        train_tile_info = create_dummy_tile_info(50)
        val_tile_info = create_dummy_tile_info(10)
        test_tile_info = create_dummy_tile_info(10)

    # Réduire les datasets pour le test rapide
    if use_quick_mode:
        print("\nRéduction des datasets pour le test rapide...")
        train_tile_info = reduce_dataset_size(train_tile_info, max_size=max_train_tiles)
        val_tile_info = reduce_dataset_size(val_tile_info, max_size=max_val_tiles)
        test_tile_info = reduce_dataset_size(test_tile_info, max_size=max_test_tiles)

    # Créer les dataloaders
    print("Création des DataLoaders...")
    train_loader, val_loader, test_loader = create_data_loaders(
        active_config, train_tile_info, val_tile_info, test_tile_info
    )

    # Créer le modèle
    print("Initialisation du modèle U-Net...")
    model = UNet(
        in_channels=1,
        dropout_rate=active_config.DROPOUT_RATE,
        use_checkpointing=active_config.USE_GRADIENT_CHECKPOINTING
    ).to(DEVICE)

    # Calculer les poids pour chaque seuil
    threshold_stats = {}
    for threshold in active_config.THRESHOLDS:
        # Ces valeurs sont approximatives basées sur les données fournies
        if threshold == 10:
            ratio_trouees = 0.15  # Environ 15% de trouées
        elif threshold == 15:
            ratio_trouees = 0.30  # Environ 30% de trouées
        elif threshold == 20:
            ratio_trouees = 0.50  # Environ 50% de trouées
        elif threshold == 25:
            ratio_trouees = 0.70  # Environ 70% de trouées
        elif threshold == 30:
            ratio_trouees = 0.85  # Environ 85% de trouées
        else:
            ratio_trouees = 0.50  # Valeur par défaut

        threshold_stats[threshold] = ratio_trouees

    # Créer les poids pour chaque seuil
    threshold_weights = create_threshold_weights(active_config, threshold_stats)

    # Définir la fonction de perte combinée
    criterion = CombinedFocalDiceLoss(
        alpha=0.5,  # Équilibre entre BCE et Dice
        gamma=2.0,  # Paramètre focal standard
        threshold_weights=threshold_weights
    )

    print("Fonction de perte combinée (BCE-Focal + Dice) initialisée avec pondération adaptative aux seuils")

    optimizer = optim.Adam(model.parameters(), lr=active_config.LEARNING_RATE)
    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)

    # Créer le dictionnaire de setup
    setup_dict = {
        'model': model,
        'train_loader': train_loader,
        'val_loader': val_loader,
        'test_loader': test_loader,
        'criterion': criterion,
        'optimizer': optimizer,
        'scheduler': scheduler,
        'config': active_config,
        'device': DEVICE,
        'train_tile_info': train_tile_info,
        'val_tile_info': val_tile_info,
        'test_tile_info': test_tile_info
    }

    # Exécuter un entraînement rapide avec la version spéciale pour tests
    print("\nLancement de l'entraînement test...")
    model, tracker = train_model_for_test(
        setup_dict['model'],
        setup_dict['train_loader'],
        setup_dict['val_loader'],
        setup_dict['criterion'],
        setup_dict['optimizer'],
        setup_dict['scheduler'],
        setup_dict['config'],
        setup_dict['device']
    )

    # Tester rapidement le modèle en utilisant le dossier de visualisations dédié aux tests
    print("\nEvaluation du modèle...")
    visualizations_dir = getattr(active_config, 'TEST_VISUALIZATIONS_DIR', active_config.VISUALIZATIONS_DIR)

    # Fonction de test modifiée pour utiliser les chemins de test
    def test_model_for_test(model, test_loader, device, config, threshold=0.5):
        """Version de test_model qui utilise les dossiers de test"""
        model.eval()
        total_iou = 0.0
        total_samples = 0
        visualization_samples = []

        try:
            with torch.no_grad():
                for dsm, threshold_val, target in tqdm(test_loader, desc="Test"):
                    if dsm.size(0) == 0:
                        continue
                    dsm = dsm.to(device)
                    threshold_val = threshold_val.to(device)
                    target = target.to(device)
                    output = model(dsm, threshold_val)
                    iou = iou_metric(output, target)
                    batch_size = dsm.size(0)
                    total_iou += iou.item() * batch_size
                    total_samples += batch_size

                    if len(visualization_samples) < 5:
                        for i in range(min(batch_size, 5 - len(visualization_samples))):
                            visualization_samples.append({
                                'dsm': dsm[i].cpu().numpy(),
                                'target': target[i].cpu().numpy(),
                                'output': output[i].cpu().numpy(),
                                'threshold': threshold_val[i].item() * max(config.THRESHOLDS)
                            })

            mean_iou = total_iou / total_samples if total_samples > 0 else 0.0
            print(f"Évaluation sur {total_samples} échantillons")
            print(f"IoU moyen: {mean_iou:.4f}")

            if visualization_samples:
                try:
                    fig, axes = plt.subplots(len(visualization_samples), 3, figsize=(15, 5*len(visualization_samples)))
                    if len(visualization_samples) == 1:
                        axes = [axes]

                    for i, sample in enumerate(visualization_samples):
                        axes[i][0].imshow(sample['dsm'][0], cmap='terrain')
                        axes[i][0].set_title(f"DSM")
                        axes[i][1].imshow(sample['target'][0], cmap='binary')
                        axes[i][1].set_title(f"Réel (seuil {sample['threshold']:.1f}m)")
                        pred_binary = (torch.sigmoid(torch.tensor(sample['output'][0])) > threshold).float().cpu().numpy()
                        axes[i][2].imshow(pred_binary, cmap='binary')
                        sample_iou = iou_metric(
                            torch.tensor(sample['output']).unsqueeze(0),
                            torch.tensor(sample['target']).unsqueeze(0)
                        ).item()
                        axes[i][2].set_title(f"Prédit (IoU: {sample_iou:.4f})")

                    plt.tight_layout()

                    # Utiliser le dossier de visualisations de test
                    visualizations_dir = getattr(config, 'TEST_VISUALIZATIONS_DIR', config.VISUALIZATIONS_DIR)
                    os.makedirs(visualizations_dir, exist_ok=True)

                    plt.savefig(os.path.join(visualizations_dir, 'test_predictions.png'), dpi=300)
                    plt.show()
                except Exception as e:
                    print(f"Erreur lors de la visualisation: {str(e)}")

            return {'iou': mean_iou}

        except Exception as e:
            print(f"Erreur lors de l'évaluation du modèle: {str(e)}")
            return {'iou': 0.0}

    # Évaluer avec la fonction modifiée
    test_metrics = test_model_for_test(
        model,
        setup_dict['test_loader'],
        setup_dict['device'],
        setup_dict['config']
    )

    # Tester une prédiction simple en utilisant les dossiers de test
    print("\nTest de prédiction...")

    # Version modifiée qui utilise les dossiers de test
    def visualize_predictions_for_test(model, tile_info, threshold_value, device, config, num_samples=2):
        """Version qui utilise les dossiers de test pour les visualisations"""
        visualizations_dir = getattr(config, 'TEST_VISUALIZATIONS_DIR', config.VISUALIZATIONS_DIR)
        model.eval()

        indices = list(range(min(num_samples, len(tile_info))))
        normalized_threshold = threshold_value / max(config.THRESHOLDS)
        threshold_tensor = torch.tensor([[normalized_threshold]], dtype=torch.float32).to(device)

        fig, axes = plt.subplots(len(indices), 3, figsize=(15, 5*len(indices)))
        if len(indices) == 1:
            axes = [axes]

        with torch.no_grad():
            for i, idx in enumerate(indices):
                info = tile_info[idx]
                dsm_tile = np.load(info['dsm_path'])
                mask_path = info['mask_paths'][threshold_value]
                mask_tile = np.load(mask_path)

                mask_valid = (mask_tile != 255)
                mask_binary = np.where(mask_valid, (mask_tile > 0).astype(np.float32), 0)

                dsm_valid = ~np.isnan(dsm_tile)
                dsm_display = dsm_tile.copy()

                if np.any(dsm_valid):
                    dsm_min = np.nanmin(dsm_tile)
                    dsm_max = np.nanmax(dsm_tile)
                    dsm_range = dsm_max - dsm_min
                    if dsm_range > 0:
                        dsm_tile = np.where(dsm_valid, (dsm_tile - dsm_min) / dsm_range, 0)
                    else:
                        dsm_tile = np.where(dsm_valid, 0, 0)

                dsm_tensor = torch.tensor(dsm_tile, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)
                output = model(dsm_tensor, threshold_tensor)
                prediction = output.squeeze().cpu().numpy()

                pred_tensor = torch.sigmoid(torch.tensor(prediction, dtype=torch.float32)).unsqueeze(0).unsqueeze(0)
                mask_tensor = torch.tensor(mask_binary, dtype=torch.float32).unsqueeze(0).unsqueeze(0)
                iou = iou_metric(pred_tensor, mask_tensor).item()

                axes[i][0].imshow(dsm_display, cmap='terrain')
                axes[i][0].set_title(f"DSM - {info['site']}")
                axes[i][1].imshow(mask_binary, cmap='binary')
                axes[i][1].set_title(f"Trouées réelles (seuil {threshold_value}m)")
                axes[i][2].imshow(torch.sigmoid(torch.tensor(prediction)).numpy() > 0.5, cmap='binary')
                axes[i][2].set_title(f"Trouées prédites (IoU: {iou:.4f})")

        plt.tight_layout()
        os.makedirs(visualizations_dir, exist_ok=True)
        plt.savefig(os.path.join(visualizations_dir, f'predictions_threshold_{threshold_value}m.png'), dpi=300)
        plt.show()

    # Visualisation avec la fonction modifiée
    visualize_predictions_for_test(
        model,
        setup_dict['test_tile_info'][:2],
        active_config.THRESHOLDS[0],
        setup_dict['device'],
        active_config,
        num_samples=2
    )

    # Résumé des résultats
    print("\n=== RÉSUMÉ DU TEST DE WORKFLOW ===")
    print(f"Configuration: {'Rapide' if use_quick_mode else 'Standard'}")
    print(f"Nombre d'époques réalisées: {len(tracker.train_losses)}")
    print(f"IoU final sur le jeu de test: {test_metrics['iou']:.4f}")
    print(f"Meilleur IoU de validation: {tracker.best_val_iou:.4f}")
    print(f"Résultats enregistrés dans: {getattr(active_config, 'TEST_VISUALIZATIONS_DIR', active_config.VISUALIZATIONS_DIR)}")

    return {
        'model': model,
        'tracker': tracker,
        'test_metrics': test_metrics,
        'config': active_config
    }

class TestTrainingCallbacks:
    """
    Classe de callbacks pour le mode test, qui permet de personnaliser
    le comportement de l'entraînement en mode test.
    """
    def before_training_start(self, model, optimizer, tracker):
        """
        Callback appelé avant le début de l'entraînement.
        Force le démarrage à l'époque 0 en mode test.
        """
        print("Mode TEST: Ignorer les checkpoints existants, démarrage à l'époque 0")
        return 0  # Forcer l'époque de départ à 0

    def after_epoch(self, epoch, model, optimizer, train_metrics, val_metrics, tracker, improved):
        """
        Callback appelé après chaque époque.
        Permet de limiter certaines opérations en mode test.
        """
        # Par exemple, limiter les évaluations visuelles
        return True  # Continuer l'entraînement

    def should_save_checkpoint(self, epoch, model, optimizer, improved):
        """
        Callback pour déterminer si on doit sauvegarder un checkpoint.
        En mode test, on peut limiter les sauvegardes.
        """
        # Sauvegarder seulement si amélioré et après l'époque 0
        return improved and epoch > 0

def estimate_optimal_epochs(config, initial_epochs=30, patience=10):
    """
    Estime le nombre optimal d'époques basé sur des règles heuristiques
    et des bonnes pratiques.

    Args:
        config: La configuration
        initial_epochs: Nombre d'époques initial à considérer
        patience: Patience pour l'arrêt précoce

    Returns:
        Estimation du nombre optimal d'époques et recommandations
    """
    # Facteurs qui influencent le nombre d'époques optimal
    dataset_size = 1000  # Valeur par défaut si non disponible
    try:
        # Essayer de charger les informations sur les tuiles
        train_info_path = os.path.join(config.TILES_DIR, 'train_tile_info.pkl')
        if os.path.exists(train_info_path):
            with open(train_info_path, 'rb') as f:
                train_tile_info = pickle.load(f)
                dataset_size = len(train_tile_info)
    except:
        pass  # Utiliser la valeur par défaut

    # Heuristiques pour l'estimation
    if dataset_size < 100:
        base_epochs = 50  # Plus d'époques pour petits datasets
    elif dataset_size < 500:
        base_epochs = 40
    elif dataset_size < 1000:
        base_epochs = 30
    else:
        base_epochs = 25  # Moins d'époques pour grands datasets

    # Ajuster en fonction du dropout (plus de dropout = plus d'époques)
    dropout_factor = 1.0 + config.DROPOUT_RATE

    # Ajuster en fonction de la taille du batch (plus petit batch = moins d'époques)
    batch_factor = max(0.8, min(1.2, 32 / config.BATCH_SIZE))

    # Calcul final
    estimated_epochs = int(base_epochs * dropout_factor * batch_factor)

    # Recommandation pour une approche progressive
    phase1 = min(10, estimated_epochs // 3)
    phase2 = min(20, estimated_epochs // 2)

    recommendations = {
        'initial_estimate': estimated_epochs,
        'with_early_stopping': estimated_epochs + patience,
        'progressive_approach': {
            'phase1': phase1,
            'phase2': phase2,
            'phase3': estimated_epochs
        },
        'explanation': f"""
            Recommandation d'une approche progressive en 3 phases :
            1. Phase de test rapide ({phase1} époques) : Vérifier la convergence initiale
            2. Phase intermédiaire ({phase2} époques) : Affiner l'apprentissage
            3. Phase complète ({estimated_epochs} époques) : Optimiser les performances

            Utiliser un arrêt précoce avec patience={patience} pour éviter le surapprentissage.
            Surveiller la validation à chaque phase pour décider s'il faut poursuivre.
        """
    }

    return recommendations

def setup_model_training():
    """
    Configure l'environnement pour l'entraînement du modèle U-Net.
    """
    print("=== CONFIGURATION POUR L'ENTRAÎNEMENT DU MODÈLE U-NET ===\n")

    # Configuration des chemins selon le type de modèle
    config = Config()
    config = setup_model_paths(config)

    # Sauvegarder la configuration
    config.save_config()

    # Afficher le type de modèle utilisé
    model_type = config.MODEL_TYPE
    print(f"\nType de modèle sélectionné: {model_type}")

    # Charger les informations sur les tuiles
    print("\n1. CHARGEMENT DES INFORMATIONS SUR LES TUILES")
    print("-------------------------------------------")

    train_info_path = os.path.join(config.TILES_DIR, 'train_tile_info.pkl')
    val_info_path = os.path.join(config.TILES_DIR, 'val_tile_info.pkl')
    test_info_path = os.path.join(config.TILES_DIR, 'test_tile_info.pkl')

    # Vérifier l'existence du répertoire et des fichiers individuellement
    print(f"Répertoire TILES_DIR: {config.TILES_DIR}")
    print(f"Ce répertoire existe: {os.path.exists(config.TILES_DIR)}")

    if os.path.exists(config.TILES_DIR):
        print(f"Contenu du répertoire: {os.listdir(config.TILES_DIR)}")

    print(f"Chemin train_info: {train_info_path} (existe: {os.path.exists(train_info_path)})")
    print(f"Chemin val_info: {val_info_path} (existe: {os.path.exists(val_info_path)})")
    print(f"Chemin test_info: {test_info_path} (existe: {os.path.exists(test_info_path)})")

    # Tenter de charger les fichiers existants ou créer des données factices si nécessaire
    try:
        # Essayer de charger les fichiers d'information
        if os.path.exists(train_info_path):
            with open(train_info_path, 'rb') as f:
                train_tile_info = pickle.load(f)
        else:
            raise FileNotFoundError(f"Fichier manquant: {train_info_path}")

        if os.path.exists(val_info_path):
            with open(val_info_path, 'rb') as f:
                val_tile_info = pickle.load(f)
        else:
            raise FileNotFoundError(f"Fichier manquant: {val_info_path}")

        if os.path.exists(test_info_path):
            with open(test_info_path, 'rb') as f:
                test_tile_info = pickle.load(f)
        else:
            raise FileNotFoundError(f"Fichier manquant: {test_info_path}")

    except (FileNotFoundError, pickle.UnpicklingError) as e:
        print(f"ERREUR lors du chargement des fichiers: {str(e)}")
        print("\nVérifier que:")
        print("1. Vous avez bien exécuté le script de préparation des données")
        print(f"2. Les chemins sont corrects: BASE_DIR={config.BASE_DIR}")
        print("3. Les fichiers .pkl ne sont pas corrompus")

        # Demander à l'utilisateur s'il souhaite utiliser des données factices pour le développement
        use_dummy = input("\nVoulez-vous utiliser des données factices pour le développement? (o/n): ")

        if use_dummy.lower() == 'o':
            print("Création de données factices pour test uniquement...")

            # Fonction pour créer des données factices
            def create_dummy_tile_info(num_tiles):
                dummy_info = []
                tile_size = config.TILE_SIZE

                for i in range(num_tiles):
                    # Créer des faux chemins de fichiers (ils n'existent pas réellement)
                    dsm_path = f"/tmp/dummy_dsm_{i}.npy"
                    mask_paths = {t: f"/tmp/dummy_mask_{i}_{t}m.npy" for t in config.THRESHOLDS}

                    # Créer des données factices pour simuler les tuiles
                    if not os.path.exists(dsm_path):
                        np.save(dsm_path, np.random.rand(tile_size, tile_size))

                    for t, path in mask_paths.items():
                        if not os.path.exists(path):
                            np.save(path, (np.random.rand(tile_size, tile_size) > 0.7).astype(np.uint8))

                    dummy_info.append({
                        'site': f'dummy_site_{i//10}',
                        'row_idx': i % 10,
                        'col_idx': i % 10,
                        'window': None,
                        'dsm_path': dsm_path,
                        'mask_paths': mask_paths
                    })
                return dummy_info

            # Créer des données factices
            train_tile_info = create_dummy_tile_info(100)  # 100 tuiles d'entrainement
            val_tile_info = create_dummy_tile_info(20)     # 20 tuiles de validation
            test_tile_info = create_dummy_tile_info(20)    # 20 tuiles de test

            print("Données factices créées avec succès!")
        else:
            raise FileNotFoundError("Les fichiers d'information sur les tuiles n'existent pas. Exécutez d'abord le script de préparation des données.")

    print(f"Nombre de tuiles d'entraînement: {len(train_tile_info)}")
    print(f"Nombre de tuiles de validation: {len(val_tile_info)}")
    print(f"Nombre de tuiles de test: {len(test_tile_info)}")

    # Créer les DataLoaders
    print("\n2. CRÉATION DES DATALOADERS")
    print("---------------------------")

    train_loader, val_loader, test_loader = create_data_loaders(
        config, train_tile_info, val_tile_info, test_tile_info
    )

    print(f"Nombre de batchs d'entraînement: {len(train_loader)}")
    print(f"Nombre de batchs de validation: {len(val_loader)}")
    print(f"Nombre de batchs de test: {len(test_loader)}")

    print("\n3. CRÉATION DU MODÈLE U-NET")
    print("----------------------------")

    # Créer le modèle
    # Utiliser la factory de modèles
    model = create_unet_model(config).to(DEVICE)

    # Afficher le nombre de paramètres
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"Nombre total de paramètres: {total_params:,}")
    print(f"Nombre de paramètres entraînables: {trainable_params:,}")

    print("\n4. CONFIGURATION DE LA FONCTION DE PERTE ET DE L'OPTIMISATION")
    print("-----------------------------------------------------------")

    # Calculer les poids pour chaque seuil
    threshold_stats = {}
    for threshold in config.THRESHOLDS:
        # Ces valeurs sont approximatives basées sur les données fournies
        if threshold == 10:
            ratio_trouees = 0.15  # Environ 15% de trouées
        elif threshold == 15:
            ratio_trouees = 0.30  # Environ 30% de trouées
        elif threshold == 20:
            ratio_trouees = 0.50  # Environ 50% de trouées
        elif threshold == 25:
            ratio_trouees = 0.70  # Environ 70% de trouées
        elif threshold == 30:
            ratio_trouees = 0.85  # Environ 85% de trouées
        else:
            ratio_trouees = 0.50  # Valeur par défaut

        threshold_stats[threshold] = ratio_trouees

    # Créer les poids pour chaque seuil
    threshold_weights = create_threshold_weights(config, threshold_stats)

    # Définir la fonction de perte combinée
    criterion = CombinedFocalDiceLoss(
        alpha=0.5,  # Équilibre entre BCE et Dice
        gamma=2.0,  # Paramètre focal standard
        threshold_weights=threshold_weights
    )

    # Définir l'optimiseur
    optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)

    # Définir le scheduler
    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)

    # Initialiser l'objet de métriques
    segmentation_metrics = SegmentationMetrics(DEVICE)

    print("\nModèle U-Net configuré avec succès!")
    print("Prêt pour l'entraînement avec fonction de perte combinée et métriques avancées.")

    # Créer le dictionnaire setup_dict
    setup_dict = {
        'model': model,
        'train_loader': train_loader,
        'val_loader': val_loader,
        'test_loader': test_loader,
        'criterion': criterion,
        'optimizer': optimizer,
        'scheduler': scheduler,
        'config': config,
        'device': DEVICE,
        'train_tile_info': train_tile_info,
        'val_tile_info': val_tile_info,
        'test_tile_info': test_tile_info
    }

    # PLACER LE CODE ICI, juste avant le return
    # Si le modèle utilise DropPath, ajouter le scheduler
    model_type = config.MODEL_TYPE
    if model_type in ['droppath', 'all']:
        droppath_scheduler = DropPathScheduler(
            model,
            start_prob=0.0,
            final_prob=config.DROP_PATH_RATE,
            epochs=config.EPOCHS,
            strategy='linear',
            layer_wise=True,
            deeper_more_drop=True
        )
        setup_dict['droppath_scheduler'] = droppath_scheduler

    return setup_dict

"""## SECTION 10: EXÉCUTION DANS COLAB"""

# =====================================================================
# SECTION 10: EXÉCUTION DANS COLAB
# =====================================================================

def run_workflow_colab(mode='full', custom_epochs=None, model_type='basic', batch_size=None,
                      max_train_tiles=20, max_val_tiles=5, max_test_tiles=5, model_path=None):
    """
    Fonction principale pour exécuter le workflow dans Colab avec différents modes.

    Args:
        mode: Mode d'exécution ('test', 'estimate', 'full', 'evaluate')
        custom_epochs: Nombre personnalisé d'époques (si None, utilise la valeur par défaut ou estimée)
        model_type: Type de modèle à utiliser ('basic', 'film', 'cbam', etc.)
        batch_size: Taille des batchs pour l'entraînement
        max_train_tiles: Nombre maximum de tuiles d'entraînement pour le mode test
        max_val_tiles: Nombre maximum de tuiles de validation pour le mode test
        max_test_tiles: Nombre maximum de tuiles de test pour le mode test
        model_path: Chemin vers un modèle à évaluer (pour le mode 'evaluate')

    Returns:
        Résultats de l'exécution (modèle, tracker, métriques)
    """
    import os
    import sys
    import pickle
    import numpy as np
    import torch
    import torch.optim as optim
    from torch.optim.lr_scheduler import ReduceLROnPlateau

    # Configuration initiale
    config = Config()

    # Définir le type de modèle
    config.MODEL_TYPE = model_type

    # Mettre à jour la taille des batchs si spécifiée
    if batch_size is not None:
        config.BATCH_SIZE = batch_size

    # Mettre à jour le nombre d'époques si spécifié
    if custom_epochs is not None:
        config.EPOCHS = custom_epochs

    # Configuration pour le mode test ou les autres modes
    if mode == 'test':
        config = setup_quick_test_environment(
            config,
            use_quick_mode=True,
            max_train_tiles=max_train_tiles,
            max_val_tiles=max_val_tiles,
            max_test_tiles=max_test_tiles,
            epochs=custom_epochs
        )
    else:
        # Pour les autres modes, active_config est simplement config
        config = setup_model_paths(config)
        print_config_summary(config, f"Configuration du workflow ({mode})")

    # Mode évaluation uniquement
    if mode == 'evaluate':
        # [code existant pour l'évaluation]
        # ...
        return {
            'model': model,
            'test_metrics': test_metrics,
            'config': config
        }

    # Estimer le nombre optimal d'époques si demandé
    if mode == 'estimate' or mode == 'full_with_estimate':
        # [code existant pour l'estimation]
        # ...
        if mode == 'estimate':
            return {'recommendations': recommendations}

    # Continuer avec l'entraînement (test ou complet)
    print("\n=== EXÉCUTION DE L'ENTRAÎNEMENT " + ("RAPIDE" if mode == 'test' else "COMPLET") + " ===")

    # Configuration commune pour les modes test et full
    # Chargement des données et création des DataLoaders
    print("Configuration de l'environnement d'entraînement...")
    train_tile_info, val_tile_info, test_tile_info = load_or_create_dummy_data(config)

    # Réduire les datasets si en mode test
    if mode == 'test':
        train_tile_info = reduce_dataset_size(train_tile_info, max_size=max_train_tiles)
        val_tile_info = reduce_dataset_size(val_tile_info, max_size=max_val_tiles)
        test_tile_info = reduce_dataset_size(test_tile_info, max_size=max_test_tiles)

    # Créer les DataLoaders
    print("Création des DataLoaders...")
    train_loader, val_loader, test_loader = create_data_loaders(
        config, train_tile_info, val_tile_info, test_tile_info
    )

    # Créer le modèle
    print("Initialisation du modèle U-Net...")
    model = create_unet_model(config).to(DEVICE)

    # Définir la fonction de perte, l'optimiseur et le scheduler
    print("\n4. CONFIGURATION DE LA FONCTION DE PERTE ET DE L'OPTIMISATION")
    print("-----------------------------------------------------------")

    # Charger les ratios de trouées depuis le fichier s'il existe
    gap_ratios_path = os.path.join(config.PROCESSED_DIR, 'gap_ratios.json')
    threshold_stats = {}

    if os.path.exists(gap_ratios_path):
        try:
            with open(gap_ratios_path, 'r') as f:
                gap_ratios_data = json.load(f)
                threshold_stats = {int(k): float(v) for k, v in gap_ratios_data.items()}
            print(f"Ratios de trouées chargés: {threshold_stats}")
        except Exception as e:
            print(f"⚠️ Erreur lors du chargement des ratios de trouées: {str(e)}")
            # Utiliser les valeurs approximatives comme fallback
            threshold_stats = {}
            for threshold in config.THRESHOLDS:
                # Ces valeurs sont approximatives basées sur les données fournies
                if threshold == 10:
                    ratio_trouees = 0.15  # Environ 15% de trouées
                elif threshold == 15:
                    ratio_trouees = 0.30  # Environ 30% de trouées
                elif threshold == 20:
                    ratio_trouees = 0.50  # Environ 50% de trouées
                elif threshold == 25:
                    ratio_trouees = 0.70  # Environ 70% de trouées
                elif threshold == 30:
                    ratio_trouees = 0.85  # Environ 85% de trouées
                else:
                    ratio_trouees = 0.50  # Valeur par défaut
                threshold_stats[threshold] = ratio_trouees
    else:
        # Utiliser les valeurs approximatives si le fichier n'existe pas
        threshold_stats = {}
        for threshold in config.THRESHOLDS:
            # Ces valeurs sont approximatives basées sur les données fournies
            if threshold == 10:
                ratio_trouees = 0.15  # Environ 15% de trouées
            elif threshold == 15:
                ratio_trouees = 0.30  # Environ 30% de trouées
            elif threshold == 20:
                ratio_trouees = 0.50  # Environ 50% de trouées
            elif threshold == 25:
                ratio_trouees = 0.70  # Environ 70% de trouées
            elif threshold == 30:
                ratio_trouees = 0.85  # Environ 85% de trouées
            else:
                ratio_trouees = 0.50  # Valeur par défaut
            threshold_stats[threshold] = ratio_trouees
        print("Utilisation de ratios de trouées par défaut.")

    # Créer les poids pour chaque seuil
    threshold_weights = create_threshold_weights(config, threshold_stats)

    # Définir la fonction de perte combinée
    criterion = CombinedFocalDiceLoss(
        alpha=0.5,  # Équilibre entre BCE et Dice
        gamma=2.0,  # Paramètre focal standard
        threshold_weights=threshold_weights
    )

    # Définir l'optimiseur
    optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)

    # Définir le scheduler
    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)

    # Initialiser l'objet de métriques
    segmentation_metrics = SegmentationMetrics(DEVICE)

    # Si le modèle utilise DropPath, ajouter le scheduler de DropPath
    droppath_scheduler = None
    if config.MODEL_TYPE in ['droppath', 'all']:
        droppath_scheduler = DropPathScheduler(
            model,
            start_prob=0.0,
            final_prob=config.DROP_PATH_RATE,
            epochs=config.EPOCHS,
            strategy='linear',
            layer_wise=True,
            deeper_more_drop=True
        )

    print("Fonction de perte combinée (BCE-Focal + Dice) initialisée avec pondération adaptative aux seuils")
    print(f"Optimiseur: Adam avec lr={config.LEARNING_RATE}")
    print(f"Scheduler: ReduceLROnPlateau (factor=0.5, patience=5)")
    if droppath_scheduler:
        print(f"DropPath scheduler configuré: taux final={config.DROP_PATH_RATE}")

    # Configurer pour l'entraînement (adaptations spécifiques au mode test)
    if mode == 'test':
        # En mode test, utiliser une version simplifiée de train_model
        # qui ignore les checkpoints existants et limite certaines fonctionnalités
        is_test_mode = True
        callbacks = TestTrainingCallbacks()  # Définir cette classe si elle n'existe pas déjà
    else:
        is_test_mode = False
        callbacks = None

    # Entraîner le modèle (avec les paramètres adaptés au mode)
    print(f"Nombre d'époques pour l'entraînement: {config.EPOCHS}")
    model, tracker = train_model(
        model, train_loader, val_loader, criterion, optimizer, scheduler,
        config, DEVICE, callbacks=callbacks, is_test_mode=is_test_mode,
        droppath_scheduler=droppath_scheduler if 'droppath_scheduler' in locals() else None
    )

    # Test et évaluation (commun aux deux modes)
    test_metrics = test_model(
        model, test_loader, DEVICE, config,
        visualize=True
    )

    # Afficher les métriques de test
    print("\nMétriques finales sur l'ensemble de test:")
    for metric, value in test_metrics['metrics'].items():
        if isinstance(value, (int, float)):
            print(f"{metric}: {value:.4f}")

    return {
        'model': model,
        'tracker': tracker,
        'test_metrics': test_metrics,
        'config': config
    }

def run_workflow_colab(mode='full', custom_epochs=None, model_type='basic', batch_size=None,
                      max_train_tiles=20, max_val_tiles=5, max_test_tiles=5, model_path=None):
    """
    Fonction principale pour exécuter le workflow dans Colab avec différents modes.

    Args:
        mode: Mode d'exécution ('test', 'estimate', 'full', 'evaluate')
        custom_epochs: Nombre personnalisé d'époques (si None, utilise la valeur par défaut ou estimée)
        model_type: Type de modèle à utiliser ('basic', 'film', 'cbam', etc.)
        batch_size: Taille des batchs pour l'entraînement
        max_train_tiles: Nombre maximum de tuiles d'entraînement pour le mode test
        max_val_tiles: Nombre maximum de tuiles de validation pour le mode test
        max_test_tiles: Nombre maximum de tuiles de test pour le mode test
        model_path: Chemin vers un modèle à évaluer (pour le mode 'evaluate')

    Returns:
        Résultats de l'exécution (modèle, tracker, métriques)
    """
    import os
    import sys
    import pickle
    import numpy as np
    import torch
    import torch.optim as optim
    from torch.optim.lr_scheduler import ReduceLROnPlateau

    # Configuration initiale
    config = Config()

    # Définir le type de modèle
    config.MODEL_TYPE = model_type

    # Mettre à jour la taille des batchs si spécifiée
    if batch_size is not None:
        config.BATCH_SIZE = batch_size

    # Mettre à jour le nombre d'époques si spécifié
    if custom_epochs is not None:
        config.EPOCHS = custom_epochs

    # Si on est en mode test, créer une configuration active modifiée
    # N'affichons pas de configuration ici, elle sera affichée dans setup_quick_test_environment
    if mode == 'test':
        active_config = setup_quick_test_environment(
            config,
            use_quick_mode=True,
            max_train_tiles=max_train_tiles,
            max_val_tiles=max_val_tiles,
            max_test_tiles=max_test_tiles,
            epochs=custom_epochs  # Passer le nombre d'époques personnalisé
        )
    else:
        # Pour les autres modes, active_config est simplement config
        active_config = config
        # Affichons la configuration une seule fois ici
        print_config_summary(active_config, f"Configuration du workflow ({mode})")

    # Mode évaluation uniquement
    if mode == 'evaluate':
        print("\n=== ÉVALUATION DU MODÈLE ===")

        # Configurer les chemins selon le type de modèle
        config = setup_model_paths(config)

        # Charger les informations sur les tuiles
        train_info_path = os.path.join(config.TILES_DIR, 'train_tile_info.pkl')
        val_info_path = os.path.join(config.TILES_DIR, 'val_tile_info.pkl')
        test_info_path = os.path.join(config.TILES_DIR, 'test_tile_info.pkl')

        try:
            with open(train_info_path, 'rb') as f:
                train_tile_info = pickle.load(f)
            with open(val_info_path, 'rb') as f:
                val_tile_info = pickle.load(f)
            with open(test_info_path, 'rb') as f:
                test_tile_info = pickle.load(f)
        except Exception as e:
            print(f"Erreur lors du chargement des fichiers de tuiles: {str(e)}")
            return {"error": "Impossible de charger les données"}

        # Créer les dataloaders
        train_loader, val_loader, test_loader = create_data_loaders(
            config, train_tile_info, val_tile_info, test_tile_info
        )

        # Créer le modèle selon le type spécifié
        model = create_unet_model(config).to(DEVICE)

        # Déterminer le chemin du modèle à charger
        if model_path:
            # Convertir le chemin au format du système actuel
            # Gestion des chemins Windows
            if '\\' in model_path and not os.path.exists(model_path):
                # Convertir le chemin Windows en chemin compatible avec le système actuel
                model_path = os.path.normpath(model_path)

            checkpoint_path = model_path
            print(f"Utilisation du modèle spécifié: {checkpoint_path}")
        else:
            # Utiliser le meilleur modèle sauvegardé par défaut
            checkpoint_path = os.path.join(config.CHECKPOINTS_DIR, 'best_model.pth')
            print(f"Utilisation du dernier modèle enregistré: {checkpoint_path}")

        # Charger le modèle
        try:
            if os.path.exists(checkpoint_path):
                checkpoint = torch.load(checkpoint_path, map_location=DEVICE)
                if 'model_state_dict' in checkpoint:
                    model.load_state_dict(checkpoint['model_state_dict'])
                    print("Modèle chargé avec succès.")

                    # Afficher les métriques du modèle si disponibles
                    if 'val_metrics' in checkpoint:
                        print("\nMétriques du modèle lors de la sauvegarde:")
                        metrics = checkpoint['val_metrics']
                        for metric_name in ['iou', 'accuracy', 'precision', 'recall', 'f1_score']:
                            if metric_name in metrics:
                                print(f"  {metric_name}: {metrics[metric_name]:.4f}")
                else:
                    print("Format de checkpoint non reconnu, utilisation d'un modèle non initialisé.")
            else:
                print(f"Aucun modèle trouvé à {checkpoint_path}")
                print("Évaluation avec un modèle non entraîné.")
        except Exception as e:
            print(f"Erreur lors du chargement du modèle: {str(e)}")
            print("Évaluation avec un modèle non entraîné.")

        # Évaluer le modèle avec toutes les visualisations
        print("\nÉvaluation du modèle...")
        test_metrics = test_model(
            model,
            test_loader,
            DEVICE,
            config,
            visualize=True  # Activer toutes les visualisations
        )

        # Générer des visualisations supplémentaires pour chaque seuil
        print("\nGénération des visualisations par seuil...")
        for threshold in config.THRESHOLDS:
            visualize_predictions_with_actual(
                model,
                test_tile_info[:5],  # Utiliser seulement 5 exemples
                threshold,
                DEVICE,
                config,
                num_samples=3
            )

            # Visualisation comparative des seuils
            if threshold == config.THRESHOLDS[0]:  # Seulement pour le premier seuil
                visualize_threshold_comparison(
                    model,
                    test_loader,
                    DEVICE,
                    config,
                    sample_idx=0
                )

        return {
            'model': model,
            'test_metrics': test_metrics,
            'config': config
        }

    # Estimer le nombre optimal d'époques si demandé
    if mode == 'estimate' or mode == 'full_with_estimate':
        print("\n=== ESTIMATION DU NOMBRE OPTIMAL D'ÉPOQUES ===")
        recommendations = estimate_optimal_epochs(config)
        print(f"Estimation initiale: {recommendations['initial_estimate']} époques")
        print(f"Avec arrêt précoce: jusqu'à {recommendations['with_early_stopping']} époques")
        print("\nApproche progressive recommandée:")
        print(f"Phase 1: {recommendations['progressive_approach']['phase1']} époques")
        print(f"Phase 2: {recommendations['progressive_approach']['phase2']} époques")
        print(f"Phase 3: {recommendations['progressive_approach']['phase3']} époques")
        print("\nExplication:")
        print(recommendations['explanation'])

        # Mettre à jour le nombre d'époques
        if custom_epochs is not None:
            config.EPOCHS = custom_epochs
            print(f"\nNombre d'époques défini manuellement: {config.EPOCHS}")
        else:
            config.EPOCHS = recommendations['initial_estimate']
            print(f"\nNombre d'époques mis à jour selon l'estimation: {config.EPOCHS}")

        # Si seulement estimation, terminer ici
        if mode == 'estimate':
            return {'recommendations': recommendations}

    # Exécuter en mode test rapide si demandé
    if mode == 'test':
        print(f"Nombre d'époques pour le test: {custom_epochs}")
        results = run_workflow_test(
            use_quick_mode=True,
            custom_epochs=custom_epochs,
            max_train_tiles=max_train_tiles,
            max_val_tiles=max_val_tiles,
            max_test_tiles=max_test_tiles
        )
        return results

    # Continuer avec l'entraînement complet
    if mode in ['full', 'full_with_estimate']:
        config.USE_GRADIENT_CHECKPOINTING = True
        print("Gradient checkpointing activé pour économiser la mémoire GPU")

        print("\n=== EXÉCUTION DE L'ENTRAÎNEMENT COMPLET ===")

        print("Configuration de l'environnement d'entraînement...")

        train_info_path = os.path.join(config.TILES_DIR, 'train_tile_info.pkl')
        val_info_path = os.path.join(config.TILES_DIR, 'val_tile_info.pkl')
        test_info_path = os.path.join(config.TILES_DIR, 'test_tile_info.pkl')

        try:
            # Essayer de charger les fichiers d'information
            if os.path.exists(train_info_path):
                with open(train_info_path, 'rb') as f:
                    train_tile_info = pickle.load(f)
            else:
                raise FileNotFoundError(f"Fichier manquant: {train_info_path}")

            if os.path.exists(val_info_path):
                with open(val_info_path, 'rb') as f:
                    val_tile_info = pickle.load(f)
            else:
                raise FileNotFoundError(f"Fichier manquant: {val_info_path}")

            if os.path.exists(test_info_path):
                with open(test_info_path, 'rb') as f:
                    test_tile_info = pickle.load(f)
            else:
                raise FileNotFoundError(f"Fichier manquant: {test_info_path}")

        except (FileNotFoundError, pickle.UnpicklingError) as e:
            print(f"ERREUR lors du chargement des fichiers: {str(e)}")

            # Créer des données factices pour test
            print("Création de données factices pour développement...")

            def create_dummy_tile_info(num_tiles):
                dummy_info = []
                tile_size = config.TILE_SIZE

                for i in range(num_tiles):
                    dsm_path = f"/tmp/dummy_dsm_{i}.npy"
                    mask_paths = {t: f"/tmp/dummy_mask_{i}_{t}m.npy" for t in config.THRESHOLDS}

                    if not os.path.exists(dsm_path):
                        np.save(dsm_path, np.random.rand(tile_size, tile_size))

                    for t, path in mask_paths.items():
                        if not os.path.exists(path):
                            np.save(path, (np.random.rand(tile_size, tile_size) > 0.7).astype(np.uint8))

                    dummy_info.append({
                        'site': f'dummy_site_{i//10}',
                        'row_idx': i % 10,
                        'col_idx': i % 10,
                        'window': None,
                        'dsm_path': dsm_path,
                        'mask_paths': mask_paths
                    })
                return dummy_info

            # Créer des données factices
            train_tile_info = create_dummy_tile_info(100)
            val_tile_info = create_dummy_tile_info(20)
            test_tile_info = create_dummy_tile_info(20)

        # Créer les dataloaders
        print("Création des DataLoaders...")
        train_loader, val_loader, test_loader = create_data_loaders(
            config, train_tile_info, val_tile_info, test_tile_info
        )

        # Créer le modèle
        print("Initialisation du modèle U-Net...")
        model = create_unet_model(config).to(DEVICE)

        # Définir la fonction de perte et l'optimiseur
        # Calculer les poids pour chaque seuil
        threshold_stats = {}
        for threshold in config.THRESHOLDS:
            # Ces valeurs sont approximatives basées sur les données fournies
            if threshold == 10:
                ratio_trouees = 0.15  # Environ 15% de trouées
            elif threshold == 15:
                ratio_trouees = 0.30  # Environ 30% de trouées
            elif threshold == 20:
                ratio_trouees = 0.50  # Environ 50% de trouées
            elif threshold == 25:
                ratio_trouees = 0.70  # Environ 70% de trouées
            elif threshold == 30:
                ratio_trouees = 0.85  # Environ 85% de trouées
            else:
                ratio_trouees = 0.50  # Valeur par défaut

            threshold_stats[threshold] = ratio_trouees

        # Créer les poids pour chaque seuil
        threshold_weights = create_threshold_weights(config, threshold_stats)

        # Définir la fonction de perte combinée
        criterion = CombinedFocalDiceLoss(
            alpha=0.5,  # Équilibre entre BCE et Dice
            gamma=2.0,  # Paramètre focal standard
            threshold_weights=threshold_weights
        )

        optimizer = optim.Adam(model.parameters(), lr=active_config.LEARNING_RATE)
        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)

        print(f"Nombre d'époques pour l'entraînement complet: {config.EPOCHS}")

        # Créer le dictionnaire de setup
        setup_dict = {
            'model': model,
            'train_loader': train_loader,
            'val_loader': val_loader,
            'test_loader': test_loader,
            'criterion': criterion,
            'optimizer': optimizer,
            'scheduler': scheduler,
            'config': config,
            'device': DEVICE,
            'train_tile_info': train_tile_info,
            'val_tile_info': val_tile_info,
            'test_tile_info': test_tile_info
        }

        # Si le modèle utilise DropPath, ajouter le scheduler
        if model_type in ['droppath', 'all']:
            droppath_scheduler = DropPathScheduler(
                model,
                start_prob=0.0,
                final_prob=config.DROP_PATH_RATE,
                epochs=config.EPOCHS,
                strategy='linear',
                layer_wise=True,
                deeper_more_drop=True
            )
            setup_dict['droppath_scheduler'] = droppath_scheduler
        else:
            droppath_scheduler = None

        # Entraîner le modèle
        model, tracker = train_model(
            setup_dict['model'],
            setup_dict['train_loader'],
            setup_dict['val_loader'],
            setup_dict['criterion'],
            setup_dict['optimizer'],
            setup_dict['scheduler'],
            setup_dict['config'],
            setup_dict['device'],
            droppath_scheduler=droppath_scheduler
        )

        # Évaluer le modèle sur l'ensemble de test
        test_metrics = test_model(
            model,
            setup_dict['test_loader'],
            setup_dict['device'],
            setup_dict['config'],
            visualize=True  # Toujours activer les visualisations
        )

        # Afficher les métriques de test
        print("\nMétriques finales sur l'ensemble de test:")
        for metric, value in test_metrics['metrics'].items():
            if isinstance(value, (int, float)):
                print(f"{metric}: {value:.4f}")

        return {
            'model': model,
            'tracker': tracker,
            'test_metrics': test_metrics,
            'config': setup_dict['config']
        }

    # Mode non pris en charge
    return {"error": "Mode non pris en charge"}

def create_colab_interface():
    """
    Crée une interface interactive dans Google Colab avec des widgets.
    Cette fonction est appelée uniquement lorsque le code est exécuté dans Colab.
    """
    from ipywidgets import widgets
    from IPython.display import display, clear_output
    import traceback

    # Titre principal
    display(widgets.HTML('<h2>Configuration du workflow U-Net pour la détection des trouées forestières</h2>'))

    # Widget pour le type de modèle
    model_type_selector = widgets.Dropdown(
        options=[
            ('U-Net standard', 'basic'),
            ('U-Net avec FiLM', 'film'),
            ('U-Net avec CBAM', 'cbam'),
            ('U-Net avec DropPath', 'droppath'),
            ('U-Net avec FiLM+CBAM', 'film_cbam'),
            ('U-Net avec FiLM+CBAM+DropPath', 'all')
        ],
        value='basic',
        description='Type de modèle:',
        style={'description_width': 'initial'}
    )

    # Widget de sélection du mode
    mode_selector = widgets.Dropdown(
        options=[
            ('Test rapide', 'test'),
            ('Estimer le nombre optimal d\'époques', 'estimate'),
            ('Entraînement complet', 'full'),
            ('Évaluation uniquement', 'evaluate')
        ],
        value='test',
        description='Mode:',
        style={'description_width': 'initial'}
    )

    # Widget pour le chemin du modèle (pour le mode évaluation)
    model_path_input = widgets.Text(
        value='',
        placeholder='Chemin vers le modèle à évaluer (optionnel)',
        description='Chemin du modèle:',
        disabled=True,
        style={'description_width': 'initial'},
        layout=widgets.Layout(width='100%', display='none')
    )

    # Widget pour le nombre d'époques
    epochs_input = widgets.IntSlider(
        value=2,
        min=1,
        max=100,
        step=1,
        description='Nombre d\'époques:',
        disabled=False,
        continuous_update=False,
        orientation='horizontal',
        readout=True,
        readout_format='d',
        style={'description_width': 'initial'}
    )

    # Widget pour la taille des batchs
    batch_size_input = widgets.IntSlider(
        value=32,
        min=4,
        max=128,
        step=4,
        description='Taille des batchs:',
        disabled=False,
        continuous_update=False,
        orientation='horizontal',
        readout=True,
        readout_format='d',
        style={'description_width': 'initial'}
    )

    # Widgets pour le nombre de tuiles en mode test
    train_tiles_input = widgets.IntSlider(
        value=70,
        min=10,
        max=210,
        step=5,
        description='Tuiles entraînement:',
        disabled=False,
        continuous_update=False,
        readout=True,
        readout_format='d',
        style={'description_width': 'initial'}
    )

    val_tiles_input = widgets.IntSlider(
        value=15,
        min=5,
        max=100,
        step=5,
        description='Tuiles validation:',
        disabled=False,
        continuous_update=False,
        readout=True,
        readout_format='d',
        style={'description_width': 'initial'}
    )

    test_tiles_input = widgets.IntSlider(
        value=15,
        min=5,
        max=100,
        step=1,
        description='Tuiles test:',
        disabled=False,
        continuous_update=False,
        readout=True,
        readout_format='d',
        style={'description_width': 'initial'}
    )

    # Description des différents modes
    modes_description = widgets.HTML(
        """
        <div style="background-color: #f8f9fa; padding: 10px; border-radius: 5px; margin-top: 10px;">
            <h4>Description des modes:</h4>
            <ul>
                <li><strong>Test rapide</strong>: Exécute un workflow simplifié avec un petit sous-ensemble de données pour vérifier que tout fonctionne.</li>
                <li><strong>Estimer le nombre optimal d'époques</strong>: Calcule et recommande un nombre d'époques adapté à vos données.</li>
                <li><strong>Entraînement complet</strong>: Lance l'entraînement avec l'ensemble des données et le nombre d'époques spécifié.</li>
                <li><strong>Évaluation uniquement</strong>: Évalue un modèle déjà entraîné sans le réentraîner. Vous pouvez spécifier un chemin vers un modèle sauvegardé.</li>
            </ul>
        </div>
        """
    )

    # Information sur la progression
    status_info = widgets.HTML(
        value="<div style='color: #6c757d;'><i>Prêt à exécuter. Configurez les options puis cliquez sur 'Exécuter'.</i></div>"
    )

    # Bouton d'exécution
    run_button = widgets.Button(
        description='Exécuter',
        button_style='success',
        tooltip='Cliquez pour exécuter le workflow',
        icon='play',
        layout=widgets.Layout(width='200px', margin='10px 0px')
    )

    # Affichage des options
    display(widgets.VBox([
        mode_selector,
        model_type_selector,
        epochs_input,
        model_path_input,
        batch_size_input,
        widgets.HBox([train_tiles_input, val_tiles_input, test_tiles_input]),
        modes_description,
        status_info,
        run_button
    ]))

    # Zone de résultat
    output_area = widgets.Output()
    display(output_area)

    # Fonction appelée lors du clic sur le bouton d'exécution
    def on_run_button_clicked(b):
        # Désactiver le bouton pendant l'exécution
        run_button.disabled = True

        # Mettre à jour le statut
        status_info.value = "<div style='color: #007bff; font-weight: bold;'><i>Exécution en cours...</i></div>"

        # Récupérer les paramètres
        model_type = model_type_selector.value
        mode = mode_selector.value
        epochs = epochs_input.value
        batch_size = batch_size_input.value
        max_train_tiles = train_tiles_input.value
        max_val_tiles = val_tiles_input.value
        max_test_tiles = test_tiles_input.value
        model_path = model_path_input.value if mode == 'evaluate' else None

        with output_area:
            clear_output()
            print(f"Lancement du workflow en mode: {mode}")

            try:
                # Exécuter le workflow avec les paramètres choisis
                results = run_workflow_colab(
                    mode=mode,
                    custom_epochs=epochs,  # Passer directement le nombre d'époques demandé
                    model_type=model_type,
                    batch_size=batch_size,
                    max_train_tiles=max_train_tiles,
                    max_val_tiles=max_val_tiles,
                    max_test_tiles=max_test_tiles,
                    model_path=model_path
                )
                print("\nExécution terminée avec succès!")
            except Exception as e:
                print(f"\nErreur pendant l'exécution: {str(e)}")
                print(traceback.format_exc())

        # Réactiver le bouton
        run_button.disabled = False

        # Mettre à jour le statut
        status_info.value = "<div style='color: #28a745;'><i>Exécution terminée. Vous pouvez lancer une nouvelle exécution.</i></div>"

    # Associer la fonction au bouton
    run_button.on_click(on_run_button_clicked)

    # Fonction pour mettre à jour la visibilité des widgets selon le mode
    def on_mode_change(change):
        if change['type'] == 'change' and change['name'] == 'value':
            mode = change['new']

            # Ajuster la visibilité et les valeurs par défaut selon le mode
            if mode == 'test':
                epochs_input.value = 2
                epochs_input.disabled = False
                model_path_input.disabled = True
                model_path_input.layout.display = 'none'
                train_tiles_input.layout.display = 'block'
                val_tiles_input.layout.display = 'block'
                test_tiles_input.layout.display = 'block'
            elif mode == 'evaluate':
                epochs_input.disabled = True
                model_path_input.disabled = False
                model_path_input.layout.display = 'block'
                train_tiles_input.layout.display = 'none'
                val_tiles_input.layout.display = 'none'
                test_tiles_input.layout.display = 'none'
            else:
                epochs_input.value = 30
                epochs_input.disabled = False
                model_path_input.disabled = True
                model_path_input.layout.display = 'none'
                train_tiles_input.layout.display = 'none'
                val_tiles_input.layout.display = 'none'
                test_tiles_input.layout.display = 'none'

            # Mettre à jour l'indication du statut
            status_info.value = f"<div style='color: #6c757d;'><i>Mode '{mode}' sélectionné. Configurez les options puis cliquez sur 'Exécuter'.</i></div>"

    # Observer les changements de mode
    mode_selector.observe(on_mode_change, names='value')

    # Initialiser l'état des widgets selon le mode initial
    on_mode_change({'type': 'change', 'name': 'value', 'new': mode_selector.value})

"""# PARTIE : EXÉCUTION"""

# =====================================================================
# SECTION 11: FONCTION PRINCIPALE (MAIN)
# =====================================================================

if __name__ == "__main__":
    # Cette cellule peut être exécutée directement dans Colab
    if 'google.colab' in str(get_ipython()):
        # Utiliser l'interface Colab
        create_colab_interface()
    else:
        # Exécution traditionnelle (hors Colab)
        import argparse

        # Configurer les arguments de ligne de commande
        parser = argparse.ArgumentParser(description="Entraînement d'un modèle U-Net pour la détection des trouées forestières")
        parser.add_argument('--mode', type=str, choices=['test', 'estimate', 'full', 'evaluate'], default='full',
                          help="Mode d'exécution (test=test rapide, estimate=estimer époques, full=entraînement complet, evaluate=évaluation)")
        parser.add_argument('--epochs', type=int, default=30, help="Nombre d'époques pour l'entraînement")
        parser.add_argument('--batch-size', type=int, default=None, help="Taille des batchs (si non spécifié, utilise la valeur de config)")
        parser.add_argument('--model-type', type=str, default='basic',
                          choices=['basic', 'film', 'cbam', 'droppath', 'film_cbam', 'all'],
                          help="Type de modèle U-Net à utiliser")
        parser.add_argument('--train-tiles', type=int, default=20, help="Nombre de tuiles d'entraînement en mode test")
        parser.add_argument('--val-tiles', type=int, default=5, help="Nombre de tuiles de validation en mode test")
        parser.add_argument('--test-tiles', type=int, default=5, help="Nombre de tuiles de test en mode test")
        parser.add_argument('--model-path', type=str, default=None, help="Chemin vers un modèle à évaluer (mode evaluate)")
        parser.add_argument('--save-dir', type=str, default=None, help="Répertoire personnalisé pour sauvegarder les résultats")
        args = parser.parse_args()

        # Choix interactif si pas d'arguments spécifiés
        if len(sys.argv) == 1:
            print("=" * 80)
            print("DÉTECTION DES TROUÉES FORESTIÈRES - MODÈLE U-NET")
            print("=" * 80)
            print("\nAucun argument fourni. Utilisation du mode interactif.")

            mode_options = {
                '1': ('test', "Test rapide"),
                '2': ('estimate', "Estimer le nombre optimal d'époques"),
                '3': ('full', "Entraînement complet"),
                '4': ('evaluate', "Évaluation uniquement")  # Correction ici: full_with_estimate -> evaluate
            }

            model_options = {
                '1': ('basic', "U-Net standard"),
                '2': ('film', "U-Net avec FiLM"),
                '3': ('cbam', "U-Net avec CBAM"),
                '4': ('droppath', "U-Net avec DropPath"),
                '5': ('film_cbam', "U-Net avec FiLM+CBAM"),
                '6': ('all', "U-Net avec FiLM+CBAM+DropPath")
            }

            # Demander le mode
            print("\nChoisissez un mode:")
            for key, (_, desc) in mode_options.items():
                print(f"{key}. {desc}")

            mode_choice = input("Votre choix (1-4): ")
            while mode_choice not in mode_options:
                mode_choice = input("Choix invalide. Réessayez (1-4): ")

            mode = mode_options[mode_choice][0]

            # Demander le type de modèle
            print("\nChoisissez un type de modèle:")
            for key, (_, desc) in model_options.items():
                print(f"{key}. {desc}")

            model_choice = input("Votre choix (1-6): ")
            while model_choice not in model_options:
                model_choice = input("Choix invalide. Réessayez (1-6): ")

            model_type = model_options[model_choice][0]

            # Demander le nombre d'époques
            epochs = input("\nNombre d'époques (défaut: 2 pour test, 30 pour entraînement): ")
            epochs = int(epochs) if epochs.isdigit() else (2 if mode == 'test' else 30)

            # Demander la taille des batchs
            batch_size = input("\nTaille des batchs (défaut: 32): ")
            batch_size = int(batch_size) if batch_size.isdigit() else 32

            # Paramètres supplémentaires pour le mode test
            if mode == 'test':
                train_tiles = input("\nNombre de tuiles d'entraînement en mode test (défaut: 20): ")
                train_tiles = int(train_tiles) if train_tiles.isdigit() else 20

                val_tiles = input("Nombre de tuiles de validation en mode test (défaut: 5): ")
                val_tiles = int(val_tiles) if val_tiles.isdigit() else 5

                test_tiles = input("Nombre de tuiles de test en mode test (défaut: 5): ")
                test_tiles = int(test_tiles) if test_tiles.isdigit() else 5
            else:
                train_tiles, val_tiles, test_tiles = 20, 5, 5

            # Demander le chemin du modèle pour l'évaluation
            model_path = None
            if mode == 'evaluate':
                model_path = input("\nChemin vers le modèle à évaluer (laisser vide pour utiliser le meilleur modèle): ")
                model_path = model_path if model_path else None

            # Exécuter avec les paramètres choisis
            print("\nExécution avec les paramètres suivants:")
            print(f"Mode: {mode_options[mode_choice][1]}")
            print(f"Type de modèle: {model_options[model_choice][1]}")
            print(f"Nombre d'époques: {epochs}")
            print(f"Taille des batchs: {batch_size}")
            if mode == 'test':
                print(f"Nombre de tuiles d'entraînement: {train_tiles}")
                print(f"Nombre de tuiles de validation: {val_tiles}")
                print(f"Nombre de tuiles de test: {test_tiles}")
            if mode == 'evaluate' and model_path:
                print(f"Chemin du modèle: {model_path}")

            try:
                results = run_workflow_colab(
                    mode=mode,
                    custom_epochs=epochs,
                    model_type=model_type,
                    batch_size=batch_size,
                    max_train_tiles=train_tiles,
                    max_val_tiles=val_tiles,
                    max_test_tiles=test_tiles,
                    model_path=model_path
                )
                print("\nExécution terminée avec succès!")
            except Exception as e:
                print(f"\nErreur pendant l'exécution: {str(e)}")
                print(traceback.format_exc())
                sys.exit(1)

            sys.exit(0)

        try:
            print("=" * 80)
            print("DÉTECTION DES TROUÉES FORESTIÈRES - MODÈLE U-NET")
            print("=" * 80)

            # Exécuter avec les paramètres des arguments de ligne de commande
            results = run_workflow_colab(
                mode=args.mode,
                custom_epochs=args.epochs,
                model_type=args.model_type,
                batch_size=args.batch_size,
                max_train_tiles=args.train_tiles,
                max_val_tiles=args.val_tiles,
                max_test_tiles=args.test_tiles,
                model_path=args.model_path
            )
            print("\nExécution terminée avec succès!")

        except Exception as e:
            print("\n" + "!" * 80)
            print(f"ERREUR: {str(e)}")
            print(traceback.format_exc())
            print("!" * 80)
            sys.exit(1)