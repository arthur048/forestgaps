# âœ… Setup Benchmarking Complet - ForestGaps

**Date** : 3 dÃ©cembre 2024
**Statut** : PrÃªt pour utilisation

## ğŸ“‹ RÃ©sumÃ©

L'infrastructure de benchmarking pour ForestGaps est maintenant **complÃ¨tement configurÃ©e** selon les meilleures pratiques du deep learning. Tout est prÃªt pour lancer tes comparaisons de modÃ¨les !

## ğŸ¯ Ce qui a Ã©tÃ© mis en place

### 1. **Structure des rÃ©pertoires organisÃ©e**

```
forestgaps-dl/
â”œâ”€â”€ data/                          âœ… DonnÃ©es d'entraÃ®nement (16 plots UTM)
â”‚   â””â”€â”€ data_external_test/        âœ… DonnÃ©es externes (SODEFOR_Mini2)
â”œâ”€â”€ outputs/                       âœ… Tous les rÃ©sultats d'expÃ©riences
â”‚   â””â”€â”€ benchmarks/                âœ… Benchmarks organisÃ©s par timestamp
â”œâ”€â”€ logs/                          âœ… Logs TensorBoard
â”‚   â””â”€â”€ benchmarks/                âœ… Logs organisÃ©s par expÃ©rience
â”œâ”€â”€ models/                        âœ… ModÃ¨les sauvegardÃ©s
â”‚   â”œâ”€â”€ production/                âœ… ModÃ¨les en production
â”‚   â””â”€â”€ archive/                   âœ… Anciens modÃ¨les archivÃ©s
â”œâ”€â”€ scripts/                       âœ… Scripts de benchmarking
â”‚   â”œâ”€â”€ benchmark_quick_test.py    âœ… Test rapide (5-10 min)
â”‚   â””â”€â”€ benchmark_full.py          âœ… Benchmark complet (4-8h)
â”œâ”€â”€ docker/                        âœ… Configuration Docker
â”‚   â””â”€â”€ docker-compose.yml         âœ… TensorBoard + Jupyter + ForestGaps
â””â”€â”€ examples/                      âœ… Exemples d'utilisation
```

### 2. **Documentation complÃ¨te**

| Document | Description | Status |
|----------|-------------|--------|
| [QUICK_START_BENCHMARK.md](QUICK_START_BENCHMARK.md) | Guide de dÃ©marrage rapide | âœ… |
| [BENCHMARKING_GUIDE.md](BENCHMARKING_GUIDE.md) | Guide complet d'organisation | âœ… |
| [scripts/README.md](scripts/README.md) | Documentation des scripts | âœ… |
| [forestgaps/benchmarking/README.md](forestgaps/benchmarking/README.md) | API du module | âœ… |

### 3. **Scripts de benchmarking**

#### `benchmark_quick_test.py` âš¡
- Test rapide (5-10 minutes)
- 2 modÃ¨les par dÃ©faut
- 5 Ã©poques, 20 tuiles
- Parfait pour valider le setup

#### `benchmark_full.py` ğŸš€
- Benchmark complet (4-8 heures)
- Tous les modÃ¨les disponibles
- 50 Ã©poques par dÃ©faut
- Production-ready

### 4. **Infrastructure Docker**

```yaml
Services configurÃ©s :
âœ… forestgaps      : Container principal
âœ… tensorboard     : http://localhost:6006
âœ… jupyter         : http://localhost:8888
```

**Volumes montÃ©s :**
- `data/` â†’ `/app/data` (lecture/Ã©criture)
- `outputs/` â†’ `/app/outputs` (lecture/Ã©criture)
- `logs/` â†’ `/app/logs` (lecture/Ã©criture)
- `models/` â†’ `/app/models` (lecture/Ã©criture)

### 5. **SystÃ¨me de benchmarking**

**FonctionnalitÃ©s :**
- âœ… Comparaison automatique de modÃ¨les
- âœ… MÃ©triques complÃ¨tes (IoU, F1, Precision, Recall)
- âœ… Ã‰valuation multi-seuils (2m, 5m, 10m, 15m)
- âœ… Visualisations automatiques (PNG)
- âœ… Rapports dÃ©taillÃ©s (HTML, MD, TXT)
- âœ… Logs TensorBoard en temps rÃ©el
- âœ… Sauvegarde des meilleurs modÃ¨les
- âœ… Exemples de prÃ©dictions sauvegardÃ©s

**ModÃ¨les disponibles :**
1. U-Net Base
2. U-Net FiLM
3. DeepLabV3+ Base
4. DeepLabV3+ Threshold

## ğŸš€ Comment dÃ©marrer MAINTENANT

### Ã‰tape 1 : Lancer Docker + TensorBoard (1 minute)

```bash
cd "g:\Mon Drive\forestgaps-dl\docker"
docker-compose up -d tensorboard

# VÃ©rifier que c'est lancÃ©
docker-compose ps
```

âœ… Ouvrir TensorBoard : http://localhost:6006

### Ã‰tape 2 : Test rapide (5-10 minutes)

```bash
# Dans le mÃªme terminal
docker-compose run --rm forestgaps python scripts/benchmark_quick_test.py \
  --experiment-name "premier_test"
```

**Pendant l'exÃ©cution :**
- Surveiller les logs dans le terminal
- Voir les mÃ©triques en temps rÃ©el sur TensorBoard
- Le script affiche la progression

**Quand c'est terminÃ© :**
```bash
# Voir les rÃ©sultats
ls -lhtr outputs/benchmarks/

# Ouvrir le rapport HTML (remplacer <timestamp> par celui affichÃ©)
explorer.exe "outputs\benchmarks\<timestamp>_premier_test\reports\benchmark_report.html"
```

### Ã‰tape 3 : Analyser les rÃ©sultats

Le rapport HTML contient :
- ğŸ“Š Comparaison des mÃ©triques
- ğŸ“ˆ Courbes d'apprentissage
- ğŸ† Classement des modÃ¨les
- â±ï¸ Temps d'entraÃ®nement
- ğŸ“‰ Vitesse de convergence
- ğŸ¯ Performance par seuil

## ğŸ“Š Structure d'un rÃ©sultat de benchmark

```
outputs/benchmarks/20241203_105530_premier_test/
â”œâ”€â”€ benchmark_results.json          # RÃ©sultats complets (JSON)
â”œâ”€â”€ best_model.pt                   # Meilleur modÃ¨le global
â”œâ”€â”€ config.yaml                     # Configuration utilisÃ©e
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ UNet_Base/
â”‚   â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â”‚   â”œâ”€â”€ best.pt            â­ Meilleur checkpoint
â”‚   â”‚   â”‚   â””â”€â”€ last.pt
â”‚   â”‚   â”œâ”€â”€ metrics.json
â”‚   â”‚   â””â”€â”€ prediction_examples/
â”‚   â””â”€â”€ UNet_FiLM/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ visualizations/                 # Tous les graphiques PNG
â”‚   â”œâ”€â”€ metric_comparison_iou.png
â”‚   â”œâ”€â”€ training_curves_iou.png
â”‚   â””â”€â”€ radar_chart.png
â””â”€â”€ reports/
    â”œâ”€â”€ benchmark_report.html      ğŸ“„ OUVRIR EN PREMIER
    â”œâ”€â”€ benchmark_report.md
    â””â”€â”€ benchmark_report.txt
```

## ğŸ“ Workflow recommandÃ©

### Phase 1 : Validation (AUJOURD'HUI)
```bash
# 1. Test rapide (5-10 min)
docker-compose run --rm forestgaps python scripts/benchmark_quick_test.py \
  --experiment-name "test_$(date +%Y%m%d)"

# 2. VÃ©rifier que tout fonctionne
# 3. Analyser les rÃ©sultats dans le rapport HTML
```

### Phase 2 : Benchmark complet (DEMAIN)
```bash
# Lancer pendant la nuit ou le week-end
docker-compose run --rm forestgaps python scripts/benchmark_full.py \
  --experiment-name "comparison_all_models_v1" \
  --epochs 50 \
  --batch-size 8
```

### Phase 3 : Ã‰valuation externe
```bash
# Ã‰valuer le meilleur modÃ¨le sur donnÃ©es SODEFOR
python -m forestgaps.evaluation.external \
  --model outputs/benchmarks/<exp_id>/best_model.pt \
  --dsm data/data_external_test/SODEFOR_Mini2_DSM.tif \
  --chm data/data_external_test/SODEFOR_Mini2_CHM.tif \
  --output outputs/external_eval/<exp_id> \
  --visualize
```

### Phase 4 : Production
```bash
# Copier le meilleur modÃ¨le en production
cp outputs/benchmarks/<exp_id>/best_model.pt \
   models/production/unet_film_v1_$(date +%Y%m%d).pt

# CrÃ©er un fichier de mÃ©tadonnÃ©es
cat > models/production/metadata.json <<EOF
{
  "model": "UNet_FiLM",
  "experiment": "<exp_id>",
  "date": "$(date -I)",
  "metrics": {
    "iou": 0.XX,
    "f1": 0.XX
  },
  "training": {
    "epochs": 50,
    "data": "UTM plots"
  }
}
EOF
```

## ğŸ› ï¸ Commandes utiles

### Docker
```bash
# DÃ©marrer TensorBoard
docker-compose up -d tensorboard

# Voir les logs
docker-compose logs -f forestgaps

# Shell dans le container
docker-compose run --rm forestgaps bash

# ArrÃªter tout
docker-compose down

# VÃ©rifier GPU
docker-compose exec forestgaps nvidia-smi
```

### Benchmarking
```bash
# Lister les benchmarks
ls -lhtr outputs/benchmarks/

# Voir les rÃ©sultats d'un benchmark
cat outputs/benchmarks/<exp_id>/benchmark_results.json | jq '.summary'

# Comparer deux expÃ©riences
diff <(cat outputs/benchmarks/<exp1>/benchmark_results.json | jq '.summary') \
     <(cat outputs/benchmarks/<exp2>/benchmark_results.json | jq '.summary')

# Nettoyer les vieux logs (garder les 5 derniers)
cd logs/benchmarks && ls -t | tail -n +6 | xargs rm -rf
```

### Monitoring
```bash
# Utilisation GPU en temps rÃ©el
watch -n 1 'docker-compose exec forestgaps nvidia-smi'

# Utilisation mÃ©moire container
docker stats forestgaps-main

# Espace disque
du -sh outputs/ logs/ models/
```

## ğŸ“ˆ MÃ©triques Ã  surveiller

### TensorBoard (temps rÃ©el)
- **Train/Val IoU** : Doit converger vers 0.7-0.9
- **Train/Val Loss** : Doit dÃ©croÃ®tre rÃ©guliÃ¨rement
- **Learning Rate** : VÃ©rifier le schedule

### Rapport final
- **IoU moyen** : >0.75 = bon, >0.85 = excellent
- **F1-Score** : >0.80 = bon, >0.90 = excellent
- **Temps d'entraÃ®nement** : Comparer l'efficacitÃ©
- **Convergence** : Nombre d'Ã©poques pour atteindre 90% de perf max

## ğŸ› Troubleshooting rapide

| ProblÃ¨me | Solution |
|----------|----------|
| CUDA out of memory | `--batch-size 2` ou `4` |
| TensorBoard vide | Attendre 1-2 min, refresh |
| Container crash | `docker-compose logs forestgaps` |
| Pas de GPU | VÃ©rifier `nvidia-smi` |
| Import error | `pip install -e .` dans container |

## ğŸ“š Prochaines Ã©tapes

1. âœ… **Aujourd'hui** : Lancer le test rapide
2. ğŸ”„ **Demain** : Benchmark complet (4-8h)
3. ğŸ“Š **AprÃ¨s** : Analyser les rÃ©sultats
4. ğŸ¯ **Ensuite** : Ã‰valuation externe
5. ğŸš€ **Final** : ModÃ¨le en production

## ğŸ‰ Tu es prÃªt !

Tout est configurÃ© selon les **meilleures pratiques du deep learning** :
- âœ… ReproductibilitÃ© (seed + config sauvegardÃ©e)
- âœ… TraÃ§abilitÃ© (timestamps + logs complets)
- âœ… Monitoring (TensorBoard temps rÃ©el)
- âœ… Rapports automatiques (HTML + visualisations)
- âœ… Archivage organisÃ© (structure claire)
- âœ… Documentation complÃ¨te

**Lance ta premiÃ¨re commande maintenant** :
```bash
cd "g:\Mon Drive\forestgaps-dl\docker"
docker-compose up -d tensorboard && \
docker-compose run --rm forestgaps python scripts/benchmark_quick_test.py \
  --experiment-name "test_initial"
```

Bon benchmark ! ğŸš€ğŸŒ²

---

**Contact et support :**
- Documentation : Voir les fichiers README.md
- Issues : GitHub du projet
- TensorBoard : http://localhost:6006
