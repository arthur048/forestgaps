# ForestGaps Docker Environment Variables
# Copy this file to .env and customize as needed

# ====================
# CUDA/GPU Configuration
# ====================

# Which GPU to use (0 for first GPU, 1 for second, etc.)
NVIDIA_VISIBLE_DEVICES=0
CUDA_VISIBLE_DEVICES=0
CUDA_DEVICE_ORDER=PCI_BUS_ID

# PyTorch CUDA memory allocation strategy
# Helps prevent OOM errors with large models
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# ====================
# CPU Threading (for Batch Processing)
# ====================

# Number of threads for OpenMP (used by PyTorch)
OMP_NUM_THREADS=8

# Number of threads for MKL (Intel Math Kernel Library)
MKL_NUM_THREADS=8

# Number of threads for NumExpr
NUMEXPR_NUM_THREADS=8

# ====================
# Python Configuration
# ====================

# Ensure output is not buffered (useful for logging)
PYTHONUNBUFFERED=1

# Don't write .pyc files (reduces clutter in dev mode)
PYTHONDONTWRITEBYTECODE=1

# ====================
# Logging
# ====================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ====================
# ForestGaps Specific
# ====================

# Identify container environment
FORESTGAPS_ENV=docker
DOCKER_CONTAINER=1

# Base directory for data/models/outputs (default: /app)
# BASE_DIR=/app

# Data directory (default: /app/data)
# DATA_DIR=/app/data

# Models directory (default: /app/models)
# MODEL_DIR=/app/models

# Outputs directory (default: /app/outputs)
# OUTPUT_DIR=/app/outputs

# Logs directory (default: /app/logs)
# LOG_DIR=/app/logs

# ====================
# Training Configuration
# ====================

# Default batch size (can be overridden by CLI)
# BATCH_SIZE=32

# Number of DataLoader workers (default: auto-detect)
# NUM_WORKERS=8

# Use Automatic Mixed Precision training (requires GPU)
# USE_AMP=true

# Random seed for reproducibility
# RANDOM_SEED=42

# ====================
# TensorBoard
# ====================

# TensorBoard port
TENSORBOARD_PORT=6006

# TensorBoard log directory
# TENSORBOARD_LOGDIR=/app/logs

# ====================
# Jupyter (Development Only)
# ====================

# Jupyter port
JUPYTER_PORT=8888

# Jupyter authentication token
JUPYTER_TOKEN=forestgaps

# ====================
# Performance Tuning
# ====================

# cuDNN benchmark mode (auto-selects best algorithms)
# May make first epoch slower but improves subsequent epochs
# CUDNN_BENCHMARK=true

# cuDNN deterministic mode (reproducible results but slower)
# CUDNN_DETERMINISTIC=false

# PyTorch home directory (for cached models)
# TORCH_HOME=/app/.torch

# HuggingFace cache directory (if using transformers)
# HF_HOME=/app/.cache/huggingface

# ====================
# Docker Compose Overrides
# ====================

# Shared memory size for DataLoader workers
# Increase if you get "No space left on device" errors
# SHM_SIZE=8gb

# CPU limit
# CPUS=8

# Memory limit
# MEMORY=32G

# ====================
# Development Settings
# ====================

# Enable debug mode (more verbose logging)
# DEBUG=false

# Enable profiling (CPU/GPU profiling)
# PROFILE=false

# ====================
# Notes
# ====================
# - Lines starting with # are comments and ignored
# - Remove # to uncomment and activate a variable
# - Use docker-compose --env-file .env to load these variables
# - Or source this file in bash: source .env
