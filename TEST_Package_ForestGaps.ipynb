{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Package ForestGaps - Google Colab\n",
    "\n",
    "Notebook pour tester l'installation et le workflow complet de ForestGaps sur Google Colab.\n",
    "\n",
    "**Date:** 2025-12-03  \n",
    "**Status:** Prêt pour test Colab\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Installation du Package\n",
    "\n",
    "### Option A: Installation depuis GitHub\n",
    "```python\n",
    "!pip install git+https://github.com/ArthurCalvi/forestgaps-dl.git\n",
    "```\n",
    "\n",
    "### Option B: Installation en mode développement\n",
    "```python\n",
    "!git clone https://github.com/ArthurCalvi/forestgaps-dl.git\n",
    "%cd forestgaps-dl\n",
    "!pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation rapide\n",
    "!pip install git+https://github.com/ArthurCalvi/forestgaps-dl.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup Google Drive (Optionnel)\n",
    "\n",
    "Pour sauvegarder les résultats et charger des données depuis Google Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test des Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports de base\n",
    "import forestgaps\n",
    "from forestgaps.models import model_registry\n",
    "from forestgaps.inference import InferenceManager\n",
    "from forestgaps.evaluation import evaluate_model\n",
    "\n",
    "print(f\"✅ ForestGaps version: {forestgaps.__version__}\")\n",
    "print(f\"✅ Modèles disponibles: {model_registry.list_models()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test de Création de Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester la création de tous les modèles\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Test UNet\n",
    "model = model_registry.create('unet', in_channels=1, out_channels=1)\n",
    "model = model.to(device)\n",
    "print(f\"✅ UNet créé: {model.get_num_parameters()} paramètres\")\n",
    "\n",
    "# Test entrée dummy\n",
    "dummy_input = torch.randn(1, 1, 256, 256).to(device)\n",
    "output = model(dummy_input)\n",
    "print(f\"✅ Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Training Minimal\n",
    "\n",
    "Test avec des données synthétiques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Créer des données synthétiques\n",
    "n_samples = 20\n",
    "dsm_data = torch.randn(n_samples, 1, 256, 256)\n",
    "mask_data = torch.randint(0, 2, (n_samples, 1, 256, 256)).float()\n",
    "\n",
    "dataset = TensorDataset(dsm_data, mask_data)\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "print(f\"✅ Dataset créé: {len(dataset)} échantillons\")\n",
    "print(f\"✅ DataLoader prêt: {len(train_loader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training minimal\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(2):\n",
    "    epoch_loss = 0\n",
    "    for dsm, mask in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        dsm, mask = dsm.to(device), mask.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(dsm)\n",
    "        loss = criterion(output, mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} - Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"✅ Training test réussi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Sauvegarde/Chargement Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder\n",
    "model_path = \"/content/test_model.pt\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"✅ Modèle sauvegardé: {model_path}\")\n",
    "\n",
    "# Recharger\n",
    "new_model = model_registry.create('unet', in_channels=1, out_channels=1)\n",
    "new_model.load_state_dict(torch.load(model_path))\n",
    "new_model = new_model.to(device)\n",
    "print(\"✅ Modèle rechargé avec succès\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Tous les Modèles du Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester l'instantiation de tous les modèles\n",
    "all_models = model_registry.list_models()\n",
    "print(f\"Test de {len(all_models)} modèles...\\n\")\n",
    "\n",
    "results = {}\n",
    "for model_name in all_models:\n",
    "    try:\n",
    "        # Paramètres selon le type de modèle\n",
    "        if 'regression' in model_name:\n",
    "            params = {'in_channels': 1, 'out_channels': 1}\n",
    "        elif 'threshold' in model_name:\n",
    "            params = {'in_channels': 1, 'out_channels': 1, 'threshold_value': 5.0}\n",
    "        else:\n",
    "            params = {'in_channels': 1, 'out_channels': 1}\n",
    "        \n",
    "        # Créer le modèle\n",
    "        test_model = model_registry.create(model_name, **params)\n",
    "        n_params = test_model.get_num_parameters()\n",
    "        \n",
    "        # Test forward pass\n",
    "        test_model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_output = test_model(dummy_input.cpu())\n",
    "        \n",
    "        results[model_name] = {\n",
    "            'status': '✅ OK',\n",
    "            'params': f'{n_params:,}',\n",
    "            'output_shape': str(test_output.shape)\n",
    "        }\n",
    "        print(f\"✅ {model_name:30s} - {n_params:>10,} params\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        results[model_name] = {\n",
    "            'status': '❌ FAILED',\n",
    "            'error': str(e)\n",
    "        }\n",
    "        print(f\"❌ {model_name:30s} - FAILED: {str(e)}\")\n",
    "\n",
    "print(f\"\\n✅ Test complété: {sum(1 for r in results.values() if r['status'] == '✅ OK')}/{len(all_models)} modèles OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Résumé Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"RÉSUMÉ DES TESTS FORESTGAPS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"✅ Package installé et fonctionnel\")\n",
    "print(f\"✅ {len(all_models)} modèles disponibles\")\n",
    "print(f\"✅ Training/Inference testés\")\n",
    "print(f\"✅ Sauvegarde/Chargement OK\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
