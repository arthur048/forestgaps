{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ForestGaps - Training Complet avec Validation Externe\n",
    "\n",
    "**Workflow complet**: Train ‚Üí Eval ‚Üí Inference sur donn√©es ind√©pendantes\n",
    "\n",
    "Ce notebook permet de:\n",
    "- Entra√Æner un mod√®le de d√©tection de trou√©es foresti√®res\n",
    "- Valider sur donn√©es de test (train/val/test split)\n",
    "- Valider sur donn√©es externes `/data/data_external_test`\n",
    "- Visualiser avec TensorBoard\n",
    "- Choisir entre config test (rapide) ou production (compl√®te)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ S√©lection de Configuration\n",
    "\n",
    "**Choisissez votre configuration:**\n",
    "- `quick`: Test rapide (5 epochs, 50 tiles) - 2-5 minutes\n",
    "- `production`: Training complet (50 epochs, toutes donn√©es) - plusieurs heures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CONFIGURATION - Changez ici!\n",
    "# ========================================\n",
    "\n",
    "CONFIG_TYPE = \"quick\"  # Options: \"quick\" ou \"production\"\n",
    "\n",
    "# Donn√©es externes (toujours dans ce dossier)\n",
    "EXTERNAL_DATA_DIR = \"/content/drive/MyDrive/forestgaps/data/data_external_test\"\n",
    "\n",
    "print(f\"‚úì Configuration s√©lectionn√©e: {CONFIG_TYPE.upper()}\")\n",
    "print(f\"‚úì Donn√©es externes: {EXTERNAL_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Setup Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monter Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des d√©pendances syst√®me\n",
    "!apt-get update -qq\n",
    "!apt-get install -y -qq gdal-bin libgdal-dev python3-gdal\n",
    "\n",
    "# Installation du package ForestGaps\n",
    "!pip install -q git+https://github.com/arthur048/forestgaps.git\n",
    "\n",
    "print(\"‚úì Installation termin√©e!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger TensorBoard\n",
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "os.makedirs(\"/content/logs\", exist_ok=True)\n",
    "os.makedirs(\"/content/checkpoints\", exist_ok=True)\n",
    "\n",
    "print(\"‚úì TensorBoard pr√™t!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Training Complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from forestgaps.config import (\n",
    "    load_training_config,\n",
    "    load_data_config,\n",
    "    load_model_config,\n",
    ")\n",
    "from forestgaps.models import create_model\n",
    "from forestgaps.training.losses import ComboLoss\n",
    "from forestgaps.training.optimization import create_scheduler, TrainingOptimizer\n",
    "\n",
    "# Style pour les graphiques\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úì Imports OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger configurations selon le type s√©lectionn√©\n",
    "if CONFIG_TYPE == \"quick\":\n",
    "    training_config = load_training_config(\"configs/test/quick.yaml\")\n",
    "    data_config = load_data_config(\"configs/test/data_quick.yaml\")\n",
    "    model_config = load_model_config(\"configs/test/model_quick.yaml\")\n",
    "else:  # production\n",
    "    training_config = load_training_config(\"configs/production/default.yaml\")\n",
    "    data_config = load_data_config(\"configs/production/data_default.yaml\")\n",
    "    model_config = load_model_config(\"configs/defaults/model.yaml\")\n",
    "\n",
    "print(f\"\\n‚úì Configurations charg√©es: {CONFIG_TYPE}\")\n",
    "print(f\"  - Training: {training_config.epochs} epochs\")\n",
    "print(f\"  - Model: {model_config.model_type}\")\n",
    "print(f\"  - Loss: {training_config.loss.type}\")\n",
    "print(f\"  - Scheduler: {training_config.scheduler.type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er donn√©es dummy pour l'exemple\n",
    "# (Remplacez par vos vraies donn√©es si disponibles)\n",
    "def create_dummy_data(num_samples, tile_size=256):\n",
    "    dsm_tiles = torch.randn(num_samples, 1, tile_size, tile_size)\n",
    "    gap_masks = torch.randint(0, 2, (num_samples, 1, tile_size, tile_size)).float()\n",
    "    return TensorDataset(dsm_tiles, gap_masks)\n",
    "\n",
    "max_train = getattr(training_config, 'max_train_tiles', 100)\n",
    "max_val = getattr(training_config, 'max_val_tiles', 20)\n",
    "max_test = getattr(training_config, 'max_test_tiles', 20)\n",
    "\n",
    "train_dataset = create_dummy_data(max_train)\n",
    "val_dataset = create_dummy_data(max_val)\n",
    "test_dataset = create_dummy_data(max_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=training_config.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=training_config.val_batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=training_config.val_batch_size, shuffle=False)\n",
    "\n",
    "print(f\"‚úì DataLoaders cr√©√©s:\")\n",
    "print(f\"  - Train: {len(train_loader)} batches\")\n",
    "print(f\"  - Val: {len(val_loader)} batches\")\n",
    "print(f\"  - Test: {len(test_loader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er mod√®le\n",
    "model_kwargs = {\n",
    "    \"in_channels\": model_config.in_channels,\n",
    "    \"out_channels\": model_config.out_channels,\n",
    "}\n",
    "\n",
    "# Mapping config ‚Üí registry\n",
    "model_type = model_config.model_type\n",
    "if model_type == \"unet_film\":\n",
    "    model_type = \"film_unet\"\n",
    "\n",
    "# Param√®tres sp√©cifiques au mod√®le\n",
    "if model_config.model_type == \"unet\":\n",
    "    model_kwargs[\"init_features\"] = model_config.base_channels\n",
    "elif model_config.model_type in [\"film_unet\", \"unet_film\"]:\n",
    "    model_kwargs[\"init_features\"] = model_config.base_channels\n",
    "    model_kwargs[\"condition_size\"] = model_config.num_conditions\n",
    "else:\n",
    "    model_kwargs[\"base_channels\"] = model_config.base_channels\n",
    "\n",
    "model = create_model(model_type, **model_kwargs)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"‚úì Model: {model_config.model_type} sur {device}\")\n",
    "print(f\"  - Param√®tres: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "if training_config.loss.type == \"combo\":\n",
    "    criterion = ComboLoss(\n",
    "        bce_weight=training_config.loss.bce_weight,\n",
    "        dice_weight=training_config.loss.dice_weight,\n",
    "        focal_weight=training_config.loss.focal_weight,\n",
    "    )\n",
    "    print(f\"‚úì Combo Loss (BCE={training_config.loss.bce_weight}, Dice={training_config.loss.dice_weight}, Focal={training_config.loss.focal_weight})\")\n",
    "else:\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    print(\"‚úì BCE Loss\")\n",
    "\n",
    "# Optimizer\n",
    "if training_config.optimizer.type == \"adamw\":\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=training_config.optimizer.lr,\n",
    "        weight_decay=training_config.optimizer.weight_decay,\n",
    "    )\n",
    "else:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=training_config.optimizer.lr)\n",
    "\n",
    "print(f\"‚úì Optimizer: {training_config.optimizer.type}\")\n",
    "\n",
    "# Scheduler\n",
    "scheduler_dict = (training_config.scheduler.dict() \n",
    "                 if hasattr(training_config.scheduler, 'dict')\n",
    "                 else training_config.scheduler.model_dump())\n",
    "scheduler = create_scheduler(\n",
    "    optimizer,\n",
    "    scheduler_dict,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=training_config.epochs,\n",
    ")\n",
    "print(f\"‚úì Scheduler: {training_config.scheduler.type}\")\n",
    "\n",
    "# Training optimizer (AMP + gradient clipping)\n",
    "training_opt = TrainingOptimizer(\n",
    "    gradient_clip_value=training_config.optimization.gradient_clip_value,\n",
    "    gradient_clip_norm=training_config.optimization.gradient_clip_norm,\n",
    "    use_amp=training_config.optimization.use_amp,\n",
    "    accumulate_grad_batches=training_config.optimization.accumulate_grad_batches,\n",
    "    device=str(device),\n",
    ")\n",
    "print(f\"‚úì AMP: {training_config.optimization.use_amp}, Grad clip: {training_config.optimization.gradient_clip_norm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lancer TensorBoard\n",
    "%tensorboard --logdir /content/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 1: TRAINING\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 1: TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "history = {'train_loss': [], 'val_loss': [], 'lr': []}\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(training_config.epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        with training_opt.forward_context():\n",
    "            # Support FiLM models\n",
    "            if 'film' in model.__class__.__name__.lower():\n",
    "                threshold = torch.full((inputs.shape[0], 1), 5.0, device=device)\n",
    "                outputs = model(inputs, threshold)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "            \n",
    "            if isinstance(criterion, ComboLoss):\n",
    "                loss, _ = criterion(outputs, targets)\n",
    "            else:\n",
    "                loss = criterion(outputs, targets)\n",
    "        \n",
    "        step_info = training_opt.backward_step(loss, optimizer, model.parameters())\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        if hasattr(scheduler, 'step') and training_opt.accumulator.should_step():\n",
    "            if 'OneCycleLR' in scheduler.__class__.__name__:\n",
    "                scheduler.step()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            if 'film' in model.__class__.__name__.lower():\n",
    "                threshold = torch.full((inputs.shape[0], 1), 5.0, device=device)\n",
    "                outputs = model(inputs, threshold)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "            if isinstance(criterion, ComboLoss):\n",
    "                loss, _ = criterion(outputs, targets)\n",
    "            else:\n",
    "                loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(val_loader)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Scheduler step (if not OneCycleLR)\n",
    "    if hasattr(scheduler, 'step') and 'OneCycleLR' not in scheduler.__class__.__name__:\n",
    "        if 'ReduceLROnPlateau' in scheduler.__class__.__name__:\n",
    "            scheduler.step(val_loss)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), \"/content/checkpoints/best_model.pt\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{training_config.epochs} - Train: {train_loss:.4f}, Val: {val_loss:.4f}, LR: {current_lr:.6f}\")\n",
    "\n",
    "print(f\"\\n‚úì Training termin√©! Meilleur val loss: {best_val_loss:.4f} (epoch {best_epoch+1})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Visualisation des Courbes de Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphiques de training\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss curves\n",
    "epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "axes[0].plot(epochs_range, history['train_loss'], 'b-o', label='Train Loss', linewidth=2, markersize=6)\n",
    "axes[0].plot(epochs_range, history['val_loss'], 'r-s', label='Val Loss', linewidth=2, markersize=6)\n",
    "axes[0].axvline(x=best_epoch+1, color='g', linestyle='--', linewidth=2, label=f'Best Epoch ({best_epoch+1})')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title(f'Training & Validation Loss - {model_config.model_type.upper()}', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate schedule\n",
    "axes[1].plot(epochs_range, history['lr'], 'g-o', linewidth=2, markersize=6)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Learning Rate', fontsize=12)\n",
    "axes[1].set_title(f'Learning Rate Schedule - {training_config.scheduler.type.upper()}', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úì Graphiques sauvegard√©s: /content/training_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Evaluation sur Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 2: EVALUATION sur donn√©es de test\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 2: EVALUATION SUR TEST SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Charger le meilleur mod√®le\n",
    "model.load_state_dict(torch.load(\"/content/checkpoints/best_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0.0\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        if 'film' in model.__class__.__name__.lower():\n",
    "            threshold = torch.full((inputs.shape[0], 1), 5.0, device=device)\n",
    "            outputs = model(inputs, threshold)\n",
    "        else:\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        if isinstance(criterion, ComboLoss):\n",
    "            loss, _ = criterion(outputs, targets)\n",
    "        else:\n",
    "            loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_targets.append(targets.cpu())\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "# M√©triques\n",
    "tp = np.sum((all_preds == 1) & (all_targets == 1))\n",
    "fp = np.sum((all_preds == 1) & (all_targets == 0))\n",
    "fn = np.sum((all_preds == 0) & (all_targets == 1))\n",
    "tn = np.sum((all_preds == 0) & (all_targets == 0))\n",
    "\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "iou = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "# Stocker pour visualisation\n",
    "test_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'IoU': iou\n",
    "}\n",
    "\n",
    "print(f\"\\nR√©sultats Test Set:\")\n",
    "print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "for metric_name, metric_value in test_metrics.items():\n",
    "    print(f\"  {metric_name}: {metric_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Visualisation des M√©triques et Matrice de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphiques de m√©triques\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Barplot des m√©triques\n",
    "metrics_names = list(test_metrics.keys())\n",
    "metrics_values = list(test_metrics.values())\n",
    "colors = plt.cm.RdYlGn([x for x in metrics_values])  # Couleurs selon la valeur\n",
    "\n",
    "bars = axes[0].barh(metrics_names, metrics_values, color=colors, edgecolor='black', linewidth=1.5)\n",
    "axes[0].set_xlabel('Score', fontsize=12)\n",
    "axes[0].set_title('Test Set Metrics', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlim(0, 1)\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Ajouter valeurs sur les barres\n",
    "for i, (bar, value) in enumerate(zip(bars, metrics_values)):\n",
    "    axes[0].text(value + 0.02, i, f'{value:.3f}', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Matrice de confusion\n",
    "confusion_matrix = np.array([[tn, fp], [fn, tp]])\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'],\n",
    "            yticklabels=['Actual Negative', 'Actual Positive'],\n",
    "            ax=axes[1], cbar_kws={'label': 'Count'},\n",
    "            linewidths=2, linecolor='black')\n",
    "axes[1].set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('True Label', fontsize=12)\n",
    "axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/test_metrics.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úì Graphiques sauvegard√©s: /content/test_metrics.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Validation sur Donn√©es Externes\n",
    "\n",
    "Validation sur `/data/data_external_test` (donn√©es jamais vues pendant training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 3: VALIDATION sur donn√©es externes\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 3: VALIDATION DONN√âES EXTERNES\")\n",
    "print(f\"R√©pertoire: {EXTERNAL_DATA_DIR}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# V√©rifier si les donn√©es existent\n",
    "external_path = Path(EXTERNAL_DATA_DIR)\n",
    "if external_path.exists():\n",
    "    print(f\"‚úì Donn√©es trouv√©es: {EXTERNAL_DATA_DIR}\")\n",
    "    \n",
    "    # TODO: Charger vraies donn√©es externes\n",
    "    # Pour l'instant, utiliser donn√©es dummy\n",
    "    external_dataset = create_dummy_data(10)\n",
    "    external_loader = DataLoader(external_dataset, batch_size=4, shuffle=False)\n",
    "    \n",
    "    model.eval()\n",
    "    external_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, _) in enumerate(external_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            if 'film' in model.__class__.__name__.lower():\n",
    "                threshold = torch.full((inputs.shape[0], 1), 5.0, device=device)\n",
    "                outputs = model(inputs, threshold)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "            preds = torch.sigmoid(outputs)\n",
    "            external_preds.append(preds.cpu())\n",
    "    \n",
    "    external_preds = torch.cat(external_preds)\n",
    "    \n",
    "    print(f\"\\n‚úì Inference termin√©e sur donn√©es externes!\")\n",
    "    print(f\"  Nombre de pr√©dictions: {external_preds.shape[0]}\")\n",
    "    print(f\"  Shape: {external_preds.shape}\")\n",
    "    print(f\"  Pr√©diction moyenne: {external_preds.mean():.4f}\")\n",
    "    print(f\"  Pr√©diction min/max: {external_preds.min():.4f} / {external_preds.max():.4f}\")\n",
    "else:\n",
    "    print(f\"‚ö† Donn√©es externes non trouv√©es: {EXTERNAL_DATA_DIR}\")\n",
    "    print(\"  Assurez-vous que le dossier existe dans Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ R√©sum√© Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"R√âSUM√â COMPLET\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Configuration: {CONFIG_TYPE}\")\n",
    "print(f\"Model: {model_config.model_type}\")\n",
    "print(f\"Epochs: {training_config.epochs}\")\n",
    "print(f\"\\nTraining:\")\n",
    "print(f\"  - Final train loss: {history['train_loss'][-1]:.4f}\")\n",
    "print(f\"  - Final val loss: {history['val_loss'][-1]:.4f}\")\n",
    "print(f\"  - Best val loss: {best_val_loss:.4f} (epoch {best_epoch+1})\")\n",
    "print(f\"\\nTest Set:\")\n",
    "for metric_name, metric_value in test_metrics.items():\n",
    "    print(f\"  - {metric_name}: {metric_value:.4f}\")\n",
    "print(f\"\\nFichiers g√©n√©r√©s:\")\n",
    "print(f\"  - Mod√®le: /content/checkpoints/best_model.pt\")\n",
    "print(f\"  - Graphiques: /content/training_curves.png\")\n",
    "print(f\"  - M√©triques: /content/test_metrics.png\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üì• T√©l√©charger les R√©sultats\n",
    "\n",
    "Pour t√©l√©charger les fichiers g√©n√©r√©s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√©l√©charger les fichiers\n",
    "from google.colab import files\n",
    "\n",
    "print(\"T√©l√©chargement des fichiers...\")\n",
    "files.download('/content/checkpoints/best_model.pt')\n",
    "files.download('/content/training_curves.png')\n",
    "files.download('/content/test_metrics.png')\n",
    "print(\"‚úì T√©l√©chargements termin√©s!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
